{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "going_to _the_movies_11_April .ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "fGW1KuLZ8rNR"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/itayse10/GoingToMovies/blob/master/going_to__the_movies_11_April_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "k7Iu_xBDI8UH"
      },
      "cell_type": "markdown",
      "source": [
        "# Machine Learning 3253 - Project Assignment\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "zUH1vrPCJM3q"
      },
      "cell_type": "markdown",
      "source": [
        "## Team Members\n",
        "    \n",
        "* Craig Barbisan\n",
        "* Nisha Choondassery\n",
        "* Mark Hubbard\n",
        "* Itay Segal\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Q3yG1xBZJ7xB"
      },
      "cell_type": "markdown",
      "source": [
        "## Project Overview\n",
        "\n",
        "Using the \"Movies Dataset\"  from Kaggle, this project will create an optimal model for predicting a movie's rating."
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "JBSNMTlxOreZ"
      },
      "cell_type": "markdown",
      "source": [
        "## Notebook Overview\n",
        "\n",
        "This notebook will explore the data, evaluate some models and draw conclusions.\n",
        "\n",
        "It is divided into the following main sections:\n",
        "\n",
        "1. Setup - seting up the Notebook environment.\n",
        "2. Data - acquiring, exploring and processing the data.\n",
        "3. Model - training and testing various models.\n",
        "4. Analysis - analyzing the model results.\n",
        "5. Summary - summarizing the observations and conclusions."
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Q89LgYljPlTo"
      },
      "cell_type": "markdown",
      "source": [
        "# 1.0 Setup"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "qczYEbUbRSua"
      },
      "cell_type": "markdown",
      "source": [
        "## Libraries"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ZFH549zaQi91",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import the basic libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "import ast\n",
        "import tarfile\n",
        "\n",
        "# make this notebook's output stable across runs\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# ensure full display for dataframe content\n",
        "pd.set_option('display.max_rows', 100)\n",
        "pd.set_option('display.max_columns', 100)\n",
        "pd.set_option('precision', 5)\n",
        "pd.set_option('large_repr', 'truncate')\n",
        "pd.set_option('display.max_colwidth', -1)\n",
        "pd.set_option('colheader_justify', 'left')\n",
        "\n",
        "# enable basic plots with pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['axes.labelsize'] = 14\n",
        "plt.rcParams['xtick.labelsize'] = 12\n",
        "plt.rcParams['ytick.labelsize'] = 12\n",
        "\n",
        "# enable advanced plots\n",
        "import seaborn as sns\n",
        "sns.set(style='darkgrid')\n",
        "sns.set(font_scale=1.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "YTIbJh1TQrnD",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import sklearn libraries\n",
        "\n",
        "# pipeline processing\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import FeatureUnion\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "# data splitting\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# classifier models\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# model evaluation\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report \n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "HA5kDb2XQ52S",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# suppress warnings\n",
        "import warnings\n",
        "# warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "6GILa0qNRYsq"
      },
      "cell_type": "markdown",
      "source": [
        "## Common Functions"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "C1cY2mKHdFPk"
      },
      "cell_type": "markdown",
      "source": [
        "### Exploratory Data Analysis Functions"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "eEtN9bfMt_SB",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# function: basic schema analysis\n",
        "def quick_schema_analysis(df):\n",
        "    print(\"Basic Schema Analysis for dataframe=\" + df.name)\n",
        "    print(\"************************************************\")\n",
        "    \n",
        "    print(\"Rows and Columns:\")\n",
        "    print(df.shape)\n",
        "    print(df.info())\n",
        "    print(\"\\n\")\n",
        "    \n",
        "    print(\"Null Values - percentage:\")\n",
        "    print((1 - df.count()/len(df.index)) * 100)\n",
        "    print(\"\\n\")\n",
        "    \n",
        "    print(\"Null Values - count:\")\n",
        "    print(df.isnull().sum())\n",
        "    print(\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "uy_-xAjJ94_a",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# function: basic data analysus\n",
        "def quick_data_analysis(df):\n",
        "    print(\"Basic Data Analysis for dataframe=\" + df.name)\n",
        "    print(df.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "SnLeDwKAvkRZ"
      },
      "cell_type": "markdown",
      "source": [
        "### Exploratory Data Analysis Plots"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "5clSe_FZdcKO",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# function: plot a column vs column correlation map\n",
        "def plot_data_correlation(data):\n",
        "    sns.pairplot(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "QyCdlDPkdLpR",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# function: plot a complete histogram for all columns\n",
        "def plot_data_histograms(data):\n",
        "    plt.figure()\n",
        "    data.hist(bins=50, figsize=(20,15))\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "tT2XPnwHeBsx",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# function: plot percentage/count of categoric feature values per target value\n",
        "def plot_feature_vs_target(data, column_id, feature_name, target_name):\n",
        "\n",
        "    plt.figure()\n",
        "    plt.title(target_name + \" by \" + feature_name + \" (Percent)\")\n",
        "    plt.xlabel(feature_name)\n",
        "    ax = sns.barplot(x=column_id, y=column_id, data=data, estimator=lambda x: len(x) / len(data) * 100)\n",
        "    ax.set(ylabel=\"Percent\")\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure()\n",
        "    plt.title(target_name + \" by \" + feature_name + \" (Count)\")\n",
        "    sns.countplot(x=column_id, hue=target_name, data=data, palette='RdBu')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "cBzfHgwWPHLi",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# function: plot a correlation heatmap\n",
        "def plot_correlation(data):\n",
        "    X = data.iloc[:,0:20]  #independent columns\n",
        "    y = data.iloc[:,-1]    #target column i.e price range\n",
        "\n",
        "    #get correlations of each features in dataset\n",
        "    corrmat = data.corr()\n",
        "    top_corr_features = corrmat.index\n",
        "    plt.figure(figsize=(20,20))\n",
        "\n",
        "    #plot heat map\n",
        "    g=sns.heatmap(data[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Si3UrmVQXK8T"
      },
      "cell_type": "markdown",
      "source": [
        "### Model Evaluation Plots"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "jEQb-rW_oVbu"
      },
      "cell_type": "markdown",
      "source": [
        "#### Confusion Matrix Plots"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "f7r_0m4bigTn",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# function: generate a confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "\n",
        "def generate_confusion_matrix(classifier, X, y, cv):\n",
        "  \n",
        "    # calculate the predicted values\n",
        "    y_cvp = cross_val_predict(classifier, X, y, cv=cv)\n",
        "    \n",
        "    # calculate the confusion matrix\n",
        "    cm = confusion_matrix(y, y_cvp)\n",
        "\n",
        "    tn, fp, fn, tp = confusion_matrix(y, y_cvp).ravel()\n",
        "    print(\"True  Negatives: {}\".format(tn))\n",
        "    print(\"False Positives: {}\".format(fp))\n",
        "    print(\"False Negatives: {}\".format(fn))\n",
        "    print(\"True  Positives: {}\".format(tp))\n",
        "\n",
        "    # plot the confusion matrix\n",
        "    plot_confusion_matrix(cm, classes=[target_name_negative, \n",
        "                                       target_name_positive], \n",
        "                          normalize=False, title='Confusion Matrix')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "38bs4_A6RIKC",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# function: plot a confusion matrix\n",
        "import itertools\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(7, 7))\n",
        "    \n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print('Confusion Matrix (with normalization)')\n",
        "    else:\n",
        "        print('Confusion Matrix (without normalization)')\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "ehzmR5ajoEpG"
      },
      "cell_type": "markdown",
      "source": [
        "#### Precision Recall Plots"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "L8DR-FSUktgf",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# function: generate the Precision-Recall curves\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "def generate_precision_vs_recall(y, y_scores):\n",
        "\n",
        "    precisions, recalls, thresholds = precision_recall_curve(y, y_scores)\n",
        "\n",
        "    plot_precision_recall_vs_threshold(precisions, recalls, thresholds)\n",
        "\n",
        "    plot_precision_vs_recall(precisions, recalls)\n",
        "  \n",
        "    print(precision_score(y_train, clf_y_train_cvp))\n",
        "    print(recall_score(y_train, clf_y_train_cvp))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "jf_PwJ5Ln6ED",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# function: plot the precision-recall-threshold curve\n",
        "def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    plt.plot(thresholds, precisions[:-1], 'b--', label='Precision')\n",
        "    plt.plot(thresholds, recalls[:-1], 'g-', label='Recall')\n",
        "    plt.xlabel('Threshold')\n",
        "    plt.legend(loc='best')\n",
        "    plt.ylim([0, 1])\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "MSL-C3toWzQE",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# function: plot the precision vs recall curve\n",
        "def plot_precision_vs_recall(precisions, recalls):\n",
        "    plt.plot(recalls, precisions, 'b-', linewidth=2)\n",
        "    plt.xlabel('Recall', fontsize=16)\n",
        "    plt.ylabel('Precision', fontsize=16)\n",
        "    plt.axis([0, 1, 0, 1])\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"True  Negatives: {}\".format(tn))\n",
        "    print(\"False Positives: {}\".format(fp))\n",
        "    print(\"False Negatives: {}\".format(fn))\n",
        "    print(\"True  Positives: {}\".format(tp))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "VdpvDRE6oMxe"
      },
      "cell_type": "markdown",
      "source": [
        "#### ROC Plots"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "FNYz5SejXYkm",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# function: generate ROC curve\n",
        "def generate_roc_curve(classifier, X, y, cv):\n",
        "  \n",
        "    # calculate probabilities\n",
        "    y_probability_score = calculate_probability_score(classifier, X, y, cv)\n",
        "    \n",
        "    fpr, tpr, thresholds = roc_curve(y, y_probability_score)\n",
        "    \n",
        "    # plot the ROC curve\n",
        "    plt.title('ROC Curve')\n",
        "\n",
        "    plot_roc_curve(fpr, tpr,'Best Classifier')\n",
        "\n",
        "    plt.xlabel('False Positive Rate', fontsize=16)\n",
        "    plt.ylabel('True Positive Rate', fontsize=16)\n",
        "    plt.legend(loc='lower right', fontsize=16)\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"AUC Score: {}\".format(roc_auc_score(y, y_probability_score)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "_vWjFeAbl0Tg",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# function: plot the ROC curve\n",
        "def plot_roc_curve(fpr, tpr, label=None):\n",
        "    plt.plot(fpr, tpr, linewidth=2, label=label)\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    plt.axis([0, 1, 0, 1])   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "RPHQn2O7gUKX",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# calculate probability score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "\n",
        "def calculate_probability_score(classifier, X, y, cv):\n",
        "\n",
        "  clf_y_probas = cross_val_predict(classifier, X, y, cv=cv, \n",
        "                                         method=\"predict_proba\")\n",
        "\n",
        "  clf_y_scores = clf_y_probas[:, 1] # score = proba of positive class\n",
        "  \n",
        "  return clf_y_scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "i39fvQ17Rj7p"
      },
      "cell_type": "markdown",
      "source": [
        "### Model Scoring Functions"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "0MWZqA9w3sdS",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def display_scores(scores):\n",
        "    print(\"Scores:\", scores)\n",
        "    print(\"Mean:\", scores.mean())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "DOBZKi4OXRYG"
      },
      "cell_type": "markdown",
      "source": [
        "### Data Functions"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "cV5332XYWrz7",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# class: DataFrameSelector transform (scikit doesn't support DataFrames yet)\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, attribute_names):\n",
        "        self.attribute_names = attribute_names\n",
        "    def fit(self, X, y=None):\n",
        "        return self.fit(X, y)\n",
        "    def transform(self, X):\n",
        "        return X[self.attribute_names].copy()\n",
        "    def fit_transform(self, X, y=None):\n",
        "        return self.fit(X, y).transform(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "UGA2J-IVjiyx",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# function: download a file from Kaggle in chunks\n",
        "import requests\n",
        "\n",
        "USERNAME = 'username'\n",
        "PASSWORD = 'password'\n",
        "\n",
        "def download_from_Kaggle(remote_file, local_file):\n",
        "\n",
        "    kaggle_info = {'UserName': USERNAME, 'Password': PASSWORD}\n",
        "\n",
        "    r = requests.get(remote_file, auth=(USERNAME, PASSWORD))\n",
        "\n",
        "    # r = requests.post(r.url, data = kaggle_info)\n",
        "    \n",
        "    print('here...')\n",
        "    # read and write 512KB chunks at a time\n",
        "    f = open(local_file, 'wb')\n",
        "    for chunk in r.iter_content(chunk_size = 512 * 1024):\n",
        "        if chunk:\n",
        "            f.write(chunk)\n",
        "            print('chunk')\n",
        "\n",
        "    f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "V59rxze9ooxv",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# function: download an entire file from a public Web site\n",
        "from urllib.request import urlretrieve\n",
        "\n",
        "def download_from_Web(remote_file, local_file):\n",
        "    urlretrieve(remote_file, local_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "EEDkxRl-2Wx5",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# function: download files from the internet and optionally unzip them\n",
        "from zipfile import ZipFile\n",
        "\n",
        "def fetch_data(url, file, local_path, zip=False):\n",
        "    if not os.path.isdir(local_path):\n",
        "        os.makedirs(local_path)\n",
        "    \n",
        "    remote_file = url\n",
        "    local_file  = os.path.join(local_path, file)\n",
        "   \n",
        "    print(remote_file)\n",
        "    \n",
        "    if not os.path.isfile(local_file):\n",
        "        print('Downloading ' + file + '...')\n",
        "        \n",
        "        download_from_Web(remote_file, local_file)\n",
        "\n",
        "        print('Download complete.')\n",
        "        \n",
        "    else:\n",
        "        print('Already downloaded.')\n",
        "\n",
        "    if zip:\n",
        "       unzip_file(local_file)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "KKR7Uqb7HqPM",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# function: unzip a file\n",
        "\n",
        "def unzip_file(file):\n",
        " \n",
        "    zip_path = file[:-4]\n",
        "  \n",
        "    if (os.path.isdir(zip_path)):\n",
        "        print('Already extracted.')\n",
        "    else:\n",
        "        print('Extracting...')\n",
        "        zfile = ZipFile(file, 'r')\n",
        "        print(zfile.infolist())\n",
        "        zfile.extractall(zip_path)\n",
        "        zfile.close()\n",
        "        print('Extraction complete.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "hwA08cz-HttU",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# convert json to abstract syntax trees (ast)\n",
        "\n",
        "# use ast because json data has single quotes in the csvs\n",
        "# which is invalid for a json object (should be double quotes)\n",
        "\n",
        "def convert_json_to_ast(df, json_columns):\n",
        "  \n",
        "    for column in json_columns:\n",
        "        df[column] = df[column].apply(lambda x: np.nan if pd.isnull(x)\n",
        "                                                else ast.literal_eval(str(x)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "XuN6fNGvSoyp",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# convert the columns that contain the dictionary field with the name value in its ast \n",
        "def get_dict_val_from_ast(df,columns,field_name, fillna_str):\n",
        "    for column in columns:\n",
        "        df[column] = df[column].fillna(fillna_str) # first replace NaN with fillna_str\n",
        "        df[column] = df[column].apply(lambda x: x[field_name] if isinstance(x, dict) else [])  #.apply(ast.literal_eval)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "-mfYP2HSSoyr",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# convert the columns that contain the list field with the name value in its ast\n",
        "def get_list_val_from_ast(df,columns,field_name, fillna_str=None, new_col_dict=None):\n",
        "    for column in columns:\n",
        "        if(fillna_str):\n",
        "            df[column] = df[column].fillna(fillna_str) # first replace NaN with fillna_str\n",
        "        new_column = column\n",
        "        if(new_col_dict and column in new_col_dict):\n",
        "            new_column = new_col_dict[column]\n",
        "        df[new_column] = df[column].apply(lambda x: [i[field_name] for i in x] if isinstance(x, list) else [])  #.apply(ast.literal_eval)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "WN7czbTXSoys",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# convert to float\n",
        "def cast_to_float(df, columns,d_cast=None):\n",
        "    for column in columns:\n",
        "        if(d_cast):\n",
        "            df[column] = pd.to_numeric(df[column],errors='coerce',downcast=d_cast)\n",
        "        else:\n",
        "            df[column] = pd.to_numeric(df[column],errors='coerce')\n",
        "                "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "3gP8XlzmSoyu",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# fill in empty values with mean\n",
        "def replace_empty_with_mean(df, columns):\n",
        "    for column in columns:\n",
        "        df[column] = df[column].fillna(df[column].mean())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "mJm6sLV99rD9",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# review column results after data cleansing\n",
        "\n",
        "def assess_column(df, column, categories=False):\n",
        "    print(df[column].head(10))\n",
        "    print('Number of null entries: ', df[column].isnull().sum())\n",
        "    if categories:\n",
        "      print(df[column].unique())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "NJE9xZ55xW25",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# display column stats\n",
        "def column_stats(df,feature):\n",
        "    print('Total count is {}'.format(len(df[feature].value_counts())))\n",
        "    print(df[feature].value_counts())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "rVB8yc50Soyx",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from urllib.parse import urlparse\n",
        "\n",
        "# get domain from url\n",
        "def get_url_domain(url):\n",
        "    if(not pd.isnull(url)):\n",
        "        parsed_uri = urlparse(url )\n",
        "        return '{uri.netloc}'.format(uri=parsed_uri)\n",
        "    else:\n",
        "        return url"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "BddbfX-Wam8V",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# list all unique values in a categorical column"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "5hr9bLSIPpOV"
      },
      "cell_type": "markdown",
      "source": [
        "# 2.0 Data "
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "GqpyY9V6PzNt"
      },
      "cell_type": "markdown",
      "source": [
        "## Data Acquisition\n",
        "\n",
        "The dataset for this project is sourced from https://www.kaggle.com/rounakbanik/the-movies-dataset.\n",
        "\n",
        "Credit: Rounak Banik\n",
        "\n",
        "This dataset is an ensemble of data collected from TMDB and GroupLens.\n",
        "* The Movie Details (i.e. Metadata), Credits and Keywords have been collected from the TMDB Open API.\n",
        "* The Movie Links and Ratings have been obtained from the Official GroupLens website.\n",
        "\n",
        "The following spreadsheets are used by this project:\n",
        "\n",
        "* __movies_metadata.csv__: The main Movies Metadata file. Contains information on 45,000 movies featured in the Full MovieLens dataset. Features include posters, backdrops, budget, revenue, release dates, languages, production countries and companies.\n",
        "\n",
        "* __credits.csv__: Consists of Cast and Crew Information for all our movies. Available in the form of a stringified JSON Object.\n",
        "\n",
        "* __keywords.csv__:  Contains the movie plot keywords for our MovieLens movies. Available in the form of a stringified JSON Object.\n",
        "\n",
        "* __links.csv__: The file that contains the TMDB and IMDB IDs of all the movies featured in the Full MovieLens dataset.\n",
        "\n",
        "* __ratings_small.csv__: The subset of 100,000 ratings from 700 users on 9,000 movies.\n",
        "\n",
        "The Full MovieLens Dataset consisting of 26 million ratings and 750,000 tag applications from 270,000 users on all the 45,000 movies in this dataset can be accessed at https://grouplens.org/datasets/movielens/latest/\n",
        "\n",
        "The dataset for this project is stored as a public file on Dropbox:\n",
        "https://www.dropbox.com/s/89uv5kntgiolkno/the-movies-dataset.zip?dl=1\n",
        "\n",
        "(Kaggle requires multiple manual steps by the notebook user and Google Drive injects a virus detection warning  page for downloads of large files)."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "v0RFrfFuR8dj",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# specify file names and locations\n",
        "URL_DOMAIN    = 'https://www.dropbox.com'\n",
        "URL_PATH      = '/s/89uv5kntgiolkno/the-movies-dataset.zip?dl=1'\n",
        "\n",
        "G_URL_DOMAIN  = 'https://drive.google.com'\n",
        "G_URL_PATH    = '/uc?export=download&confirm=no_antivirus&id=16zqahjyBrcdJYKBMK-zo2NbRHyyNHVQJ'\n",
        "\n",
        "K_URL_DOMAIN2 = 'http://www.kaggle.com'\n",
        "K_URL_PATH    = '/rounakbanik/the-movies-dataset/downloads/'\n",
        "\n",
        "PROJECT_LOCAL_DIR  = 'movies/'\n",
        "PROJECT_OUTPUT_DIR = '/content/movies/output'\n",
        "PROJECT_FILE       = 'the-movies-dataset.zip'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "BMFcJ7l3hLJw",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# download the dataset file\n",
        "\n",
        "url = URL_DOMAIN + URL_PATH\n",
        "\n",
        "fetch_data(url, PROJECT_FILE, PROJECT_LOCAL_DIR, zip=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "iUJY04gYMyia",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# download the text parsing file\n",
        "\n",
        "url = URL_DOMAIN + '/s/svv8312fd9e7e9k/stopwords.txt?dl=1'\n",
        "\n",
        "fetch_data(url, 'stopwords.txt', 'movies/resources', zip=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "sYwTBIqdraJ6"
      },
      "cell_type": "markdown",
      "source": [
        "Create dataframes for each of the spreadsheets.\n",
        "\n",
        "As part of loading the dataframes, convert null values to NaN on the fly (via pd.read_csv).\n",
        "\n",
        "By default the following values are interpreted as NaN: ‘’, ‘#N/A’, ‘#N/A N/A’, ‘#NA’, ‘-1.#IND’, ‘-1.#QNAN’, ‘-NaN’, ‘-nan’, ‘1.#IND’, ‘1.#QNAN’, ‘N/A’, ‘NA’, ‘NULL’, ‘NaN’, ‘n/a’, ‘nan’, ‘null’."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "A9UWNgoKSMKH",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# initialize the dataframes (and convert null fields on the fly)\n",
        "\n",
        "zip_path = os.path.join(PROJECT_LOCAL_DIR, PROJECT_FILE[:-4])\n",
        "\n",
        "\n",
        "metadata_file = os.path.join(zip_path, 'movies_metadata.csv')\n",
        "credits_file  = os.path.join(zip_path, 'credits.csv')\n",
        "plot_file     = os.path.join(zip_path, 'keywords.csv')\n",
        "links_file    = os.path.join(zip_path, 'links.csv')\n",
        "ratings_file  = os.path.join(zip_path, 'ratings_small.csv')\n",
        "\n",
        "# load the metadata dataframe\n",
        "\n",
        "metadata = pd.read_csv(metadata_file,\n",
        "                     dtype = 'unicode',\n",
        "                     na_values = ['no info', '.']\n",
        "                    )\n",
        "\n",
        "# load the credits dataframe\n",
        "\n",
        "credits = pd.read_csv(credits_file,\n",
        "                      dtype = 'unicode',\n",
        "                      na_values = ['no info', '.']\n",
        "                     )\n",
        "\n",
        "# load the plot dataframe\n",
        "\n",
        "plot =  pd.read_csv(plot_file,\n",
        "                    dtype = 'unicode',\n",
        "                    na_values = ['no info', '.']\n",
        "                   )\n",
        "\n",
        "# load the links dataframe\n",
        "\n",
        "links =  pd.read_csv(links_file,\n",
        "                    dtype = 'unicode',\n",
        "                    na_values = ['no info', '.']\n",
        "                   )\n",
        "\n",
        "# load the ratings dataframe\n",
        "\n",
        "ratings = pd.read_csv(ratings_file,\n",
        "                      dtype = 'unicode',\n",
        "                      na_values = ['no info', '.']\n",
        "                     )\n",
        "\n",
        "dataframes = [metadata, credits, plot, links, ratings]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "lYhMcZ8TP8y0"
      },
      "cell_type": "markdown",
      "source": [
        "## Exploratory Data Analysis (EDA)"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Tj6BPUPkPbyk",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# make copies of data for EDA\n",
        "\n",
        "metadata_copy = metadata.copy()\n",
        "metadata_copy.name = 'metadata'\n",
        "\n",
        "credits_copy = credits.copy()\n",
        "credits_copy.name = 'credit'\n",
        "\n",
        "plot_copy = plot.copy()\n",
        "plot_copy.name = 'plot'\n",
        "\n",
        "links_copy = links.copy()\n",
        "links_copy.name = 'links'\n",
        "\n",
        "\n",
        "\n",
        "eda_dataframes = [metadata_copy,\n",
        "                  credits_copy,\n",
        "                  plot_copy,\n",
        "                  links_copy\n",
        "                  \n",
        "                 ]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "UQ_BRidmtRIw"
      },
      "cell_type": "markdown",
      "source": [
        "### Explore the \"metadata\" data"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "jUYZgagyFvTy"
      },
      "cell_type": "markdown",
      "source": [
        "__Features__\n",
        "\n",
        "* __adult__: Indicates if the movie is X-Rated or Adult.\n",
        "* __belongs_to_collection__: A stringified dictionary that gives information on the movie series the particular film belongs to.\n",
        "* __budget__: The budget of the movie in dollars.\n",
        "* __genres__: A stringified list of dictionaries that list out all the genres associated with the movie.\n",
        "* __homepage__: The Official Homepage of the move.\n",
        "* __id__: The ID of the movie.\n",
        "* __imdb_id__: The IMDB ID of the movie.\n",
        "* __original_language__: The language in which the movie was originally shot in.\n",
        "* __original_title__: The original title of the movie.\n",
        "* __overview__: A brief blurb of the movie.\n",
        "* __popularity__: The Popularity Score assigned by TMDB.\n",
        "* __poster_path__: The URL of the poster image.\n",
        "* __production_companies__: A stringified list of production companies involved with the making of the movie.\n",
        "* __production_countries__: A stringified list of countries where the movie was shot/produced in.\n",
        "* __release_date__: Theatrical Release Date of the movie.\n",
        "* __revenue__: The total revenue of the movie in dollars.\n",
        "* __runtime__: The runtime of the movie in minutes.\n",
        "* __spoken_languages__: A stringified list of spoken languages in the film.\n",
        "* __status__: The status of the movie (Released, To Be Released, Announced, etc.)\n",
        "* __tagline__: The tagline of the movie.\n",
        "* __title__: The Official Title of the movie.\n",
        "* __video__: Indicates if there is a video present of the movie with TMDB.\n",
        "* __vote_average__: The average rating of the movie.\n",
        "* __vote_count__: The number of votes by users, as counted by TMDB."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "fXgam2petJWx",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# quick review of the metadata data\n",
        "quick_schema_analysis(metadata_copy)\n",
        "quick_data_analysis(metadata_copy)\n",
        "\n",
        "metadata_copy.head(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "22jrHgZx2zhh",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# check if there are any duplicates\n",
        "\n",
        "print(metadata_copy.shape)\n",
        "print(metadata_copy.drop_duplicates().shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "RyVre__GhqOD",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# plot a heatmap of nulls\n",
        "sns.heatmap(metadata_copy.isnull(), yticklabels = False, cbar = False, cmap = 'viridis')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "aPsSVhxItXY8"
      },
      "cell_type": "markdown",
      "source": [
        "### Explore the \"credits\" data"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "d2ujMuGUt0kU",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# quick review of the credits data\n",
        "\n",
        "quick_schema_analysis(credits_copy)\n",
        "quick_data_analysis(credits_copy)\n",
        "\n",
        "credits_copy.head(3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "3NVx7bpYtrYE"
      },
      "cell_type": "markdown",
      "source": [
        "### Explore the \"plot\" data"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "7P1-lf4Dt3kt",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# quick review of the plot data\n",
        "\n",
        "quick_schema_analysis(plot_copy)\n",
        "quick_data_analysis(plot_copy)\n",
        "\n",
        "plot_copy.head(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "05Auh-v5D3qg"
      },
      "cell_type": "markdown",
      "source": [
        "### Explore the links data"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "u2B8MgZ7D9B3",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# quick review of the links data\n",
        "\n",
        "quick_schema_analysis(links_copy)\n",
        "quick_data_analysis(links_copy)\n",
        "\n",
        "links_copy.head(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "KU34MKOyho19"
      },
      "cell_type": "markdown",
      "source": [
        "## Data Cleansing"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "tZ5I_nU60oi0"
      },
      "cell_type": "markdown",
      "source": [
        "### Clean the metadata data"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "kq3phjpfJ0A0",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "metadata.head(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "dX1l_lOMk-sd",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "metadata['id'].isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "GM-AvCuhRnmJ"
      },
      "cell_type": "markdown",
      "source": [
        "Perform the following type conversions:\n",
        "* Convert __release_date__ to datetime\n",
        "* Convert __budget__ and __revenue__ to numerics\n",
        "* Convert all JSON fields to abstract syntax trees\n",
        "* Convert __vote_average__ to float\n",
        "* Convert __vote_count__ to integer"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "9JOu5y5cHk_a",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# convert each item of release_date to a datetime type entity\n",
        "\n",
        "metadata['release_date'] = pd.to_datetime(metadata['release_date'],\n",
        "                                          errors='coerce')\n",
        "\n",
        "# metadata['release_date'] = metadata['release_date'].fillna('?')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "sBWF5FNoCBLj",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "assess_column(metadata, 'release_date')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "IY-lkhP0OLpt",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# convert budget and revenue fields to be numeric\n",
        "# (...and convert 0 to a NaN to enable budget and revenue math)\n",
        "\n",
        "metadata['budget']  = pd.to_numeric(metadata['budget'],  errors='coerce')\n",
        "metadata['revenue'] = pd.to_numeric(metadata['revenue'], errors='coerce')\n",
        "\n",
        "metadata['budget']  = metadata['budget'].replace(0, np.nan)\n",
        "metadata['revenue'] = metadata['revenue'].replace(0, np.nan)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "R5dAIh7rEkWp",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "assess_column(metadata, 'budget')\n",
        "assess_column(metadata, 'revenue')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Ply5l1QY2JOy",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# convert json columns to abstract syntax trees\n",
        "\n",
        "json_columns = ['belongs_to_collection',\n",
        "                'genres',\n",
        "                'production_companies',\n",
        "                'production_countries',\n",
        "                'spoken_languages'\n",
        "               ]\n",
        "\n",
        "convert_json_to_ast(metadata, json_columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "zJ7tOyzhSozq",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# def get_val_from_ast(df,columns,field_name)\n",
        "get_dict_val_from_ast(metadata, ['belongs_to_collection'],'name','')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "60YRtKZMxW5U",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "assess_column(metadata, 'belongs_to_collection')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "v2ZoeRvDSozu",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "get_list_val_from_ast(metadata, ['genres'],'name','Other')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "QjGdzg_o73EV",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "assess_column(metadata, 'genres')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "REdSoD-YSoz0",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "get_list_val_from_ast(metadata, ['production_companies'],'name','')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "WEkpv2IJ8U8m",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "assess_column(metadata, 'production_companies')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "a1gqpnKPSoz7",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "get_list_val_from_ast(metadata, ['production_countries'],'iso_3166_1','Other')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "t3oTLO2A8wOC",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "assess_column(metadata, 'production_countries')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "dk8xkk-2Soz_",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cast_to_float(metadata, ['runtime'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "fHdJKubWRU9H",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# replaced by the previous cell\n",
        "# convert runtime to float\n",
        "\n",
        "metadata['runtime'] = pd.to_numeric(metadata['runtime'],\n",
        "                                       errors='coerce'\n",
        "                                      )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "AB03CVtnRil0",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "assess_column(metadata, 'runtime')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "1Cb5dTUBSo0G",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "get_list_val_from_ast(metadata, ['spoken_languages'],'name','Other')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "2YhlyU5kGE7e",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "assess_column(metadata, 'spoken_languages')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "dZubOCZ-So0M",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cast_to_float(metadata, ['vote_average'])\n",
        "\n",
        "replace_empty_with_mean(metadata, ['vote_average'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Q__IfDgoF32z",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "assess_column(metadata, 'vote_average')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "TqkwHvG8So0T",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cast_to_float(metadata, ['vote_count'],'integer')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "65szUdQmSo0T",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "metadata['vote_count'] = metadata['vote_count'].fillna(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "RtJ6soVTHFkC",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "assess_column(metadata, 'vote_count')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "nGtzUBNo0u5n"
      },
      "cell_type": "markdown",
      "source": [
        "### Clean the credits data"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "kB_ZAIVAIr91",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "credits.head(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "xr2asP2uG6jP",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# convert json columns to abstract syntax trees\n",
        "\n",
        "json_columns = ['cast', 'crew']\n",
        "    \n",
        "convert_json_to_ast(credits, json_columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "bR6i2T8Yfcp9",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# populate cast and crew with string extractions from their current ast\n",
        "\n",
        "credits['cast'] = (credits['cast'].fillna('')\n",
        "#                                 .apply(ast.literal_eval)\n",
        "                  )\n",
        " \n",
        "credits['crew'] = (credits['crew'].fillna('')\n",
        "#                                 .apply(ast.literal_eval)\n",
        "                  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "bfeG_66YHlQU",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "assess_column(credits, 'cast')\n",
        "assess_column(credits, 'crew')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "j3xi4O8304LI"
      },
      "cell_type": "markdown",
      "source": [
        "### Clean the plot data"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "A6pmEelSJGtj",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plot.head(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "OnRUQdT8G_a1",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# convert json columns to abstract syntax trees\n",
        "\n",
        "json_columns = ['keywords']\n",
        "\n",
        "convert_json_to_ast(plot, json_columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "beLYh-CaSo0i",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "get_list_val_from_ast(plot, ['keywords'],'name','')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "LmAD9Z8VMBju",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "assess_column(plot, 'keywords')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "mW-6nqMceD5s"
      },
      "cell_type": "markdown",
      "source": [
        "## Data Merge"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "5NJy65f-6xP9",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# compare the shapes of all the dataframes\n",
        "\n",
        "print(metadata.shape)\n",
        "print(credits.shape)\n",
        "print(plot.shape)\n",
        "print(links.shape)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "BxtkPnsmnrY6",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# initialize the merged dataframe \"movies\"\n",
        "movies = metadata.copy()\n",
        "print(movies.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "sNdL8vQkoVDj"
      },
      "cell_type": "markdown",
      "source": [
        "### Merge metadata and credit "
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "f0mD7qwsnpRM",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# perform a left join of credits to movies (adds 4 columns)\n",
        "movies = movies.merge(credits, on=[\"id\"])\n",
        "print(movies.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "dmO97hfRSo0z",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "movies.drop(['crew','cast'],axis=1).head(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "8er7BUVW2DkK"
      },
      "cell_type": "markdown",
      "source": [
        "### Merge plot"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "pZTcxJyN2JOk",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "movies = movies.merge(plot, on=['id'])\n",
        "print(movies.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "kYt-tyJUSo08",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "movies.drop(['crew','cast'],axis=1).head(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "trbKM15h2NQX"
      },
      "cell_type": "markdown",
      "source": [
        "### Review movies Dataframe"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "IuY3s_uU2Vkn",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# explore new movies dataframe\n",
        "\n",
        "movies.name = 'movies'\n",
        "\n",
        "quick_schema_analysis(movies)\n",
        "quick_data_analysis(movies)\n",
        "\n",
        "movies.head(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "cMJkzhxaQCvH"
      },
      "cell_type": "markdown",
      "source": [
        "# 3.0 Features\n",
        "\n",
        "__Feature Engineering__ - create new features to improve the model\n",
        "* __Feature Extractions__ - derive new features from a single existing feature\n",
        "* __Feature Aggregations__ - derive new features by combining multiple features (columns) or spanning samples (rows)\n",
        "* __Feature Transformations__ - improve the form of existing features  to improve the model\n",
        "\n",
        "__Feature Selection__ - prune features to optimize the model"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "oLVDcD_djBPh"
      },
      "cell_type": "markdown",
      "source": [
        "## Feature Engineering"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "WA5K3TJQcwxZ"
      },
      "cell_type": "markdown",
      "source": [
        "### Feature Extractions\n",
        "\n",
        "Derive new features from a single existing feature.\n",
        "1. actors - from cast\n",
        "2. director - from cast\n",
        "3. cast_size - from cast\n",
        "4. crew_size - from crew\n",
        "5. franchise - from belongs_to_collection\n",
        "6. season - from release_date"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "wL0NfhX067p3"
      },
      "cell_type": "markdown",
      "source": [
        "#### New Feature: actors"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "2TQivqVrSo1a",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create actors columns based on cast\n",
        "get_list_val_from_ast(df=movies, columns=['cast'],field_name='name',new_col_dict = {'cast' : 'actors'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "rCSTTUzzuOKc",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "assess_column(movies, 'actors')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "hB6prnMClXfc"
      },
      "cell_type": "markdown",
      "source": [
        "#### New Feature: director"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "pFvAStuO_r9u",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "movies['cast']=movies['cast'].fillna('')\n",
        "movies['crew']=movies['crew'].fillna('')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "NdjOMDxwlMoe",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# extract the director from the crew field\n",
        "\n",
        "def get_director(x):\n",
        "    for i in x:\n",
        "        if i['job'] == 'Director':\n",
        "            return i['name']\n",
        "    return 'Unknown'\n",
        "  \n",
        "movies['director'] = movies['crew'].apply(get_director)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "AAL7GyzBUjBk",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "assess_column(movies, 'director')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "gRka7wWwjrjl"
      },
      "cell_type": "markdown",
      "source": [
        "#### New Features: cast_size and crew_size"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "bRmGTpuidvEd",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# popoulate cast and crew size based on # of items in the cast and crew fields\n",
        "\n",
        "movies['cast_size'] = movies['cast'].apply(lambda x: len(x))\n",
        "movies['crew_size'] = movies['crew'].apply(lambda x: len(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "aYyeGQ1XUsuM",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "assess_column(movies, 'cast_size')\n",
        "assess_column(movies, 'crew_size')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "WwoLIG1OlHFL"
      },
      "cell_type": "markdown",
      "source": [
        "#### New Feature: franchise"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "M8CP-Ir3lIEN",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# populate as a boolean depending on whether belongs_to_collection is empty\n",
        "\n",
        "movies['belongs_to_collection'] = movies['belongs_to_collection'].fillna('')\n",
        "\n",
        "movies['franchise'] = (movies['belongs_to_collection']\n",
        "                       .apply(lambda x: len(x)>0)\n",
        "                      )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "wmyUhEH8VRI0",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "assess_column(movies, 'franchise')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "457hdoi6npoe"
      },
      "cell_type": "markdown",
      "source": [
        "#### New Feature: season"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "9OxMtcXtn7YJ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# calculate the season of the release (spring, summer, fall, winter)\n",
        "def season_of_date(date):\n",
        "    \n",
        "    if pd.isnull(date):\n",
        "      return 'unknown'\n",
        "    \n",
        "    year = str(date.year)\n",
        "    seasons = {'spring': pd.date_range(start='21/03/'+year, end='20/06/'+year),\n",
        "               'summer': pd.date_range(start='21/06/'+year, end='22/09/'+year),\n",
        "               'autumn': pd.date_range(start='23/09/'+year, end='20/12/'+year)}\n",
        "    if date in seasons['spring']:\n",
        "        return 'spring'\n",
        "    if date in seasons['summer']:\n",
        "        return 'summer'\n",
        "    if date in seasons['autumn']:\n",
        "        return 'autumn'\n",
        "    else:\n",
        "        return 'winter'\n",
        "\n",
        "# create a new column    \n",
        "movies['season'] = (movies['release_date']\n",
        "                          .fillna(pd.NaT)\n",
        "                          .apply(lambda x: season_of_date(x))\n",
        "                   )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "rA_M0JqEVE_B",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "assess_column(movies, 'season')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "yKF00MAyxW7t",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# get the year the movie was released\n",
        "def year_of_date(date):\n",
        "    if pd.isnull(date):\n",
        "      return -1\n",
        "    year = date.year\n",
        "    return year\n",
        "\n",
        "# create a new column    \n",
        "movies['release_year'] = (movies['release_date']\n",
        "                          .fillna(pd.NaT)\n",
        "                          .apply(lambda x: year_of_date(x))\n",
        "                   )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "YpSBFKWoSo1u"
      },
      "cell_type": "markdown",
      "source": [
        "#### New Feature: homepage domain"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "orWaMOVKSo1u",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# extract the domain from the homepage url\n",
        "movies['homepage_domain'] = movies['homepage'].apply(get_url_domain)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "IRQq4dg7YZup"
      },
      "cell_type": "markdown",
      "source": [
        "### Feature Aggregations\n",
        "\n",
        "Derive new features by combining existing features.\n",
        "1. weighted_rating\n",
        "2. revenue_to_budget_ratio"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "0w5HhSGFP6Mk"
      },
      "cell_type": "markdown",
      "source": [
        "#### New Feature: weighted_rating\n",
        "\n",
        "Weighted Rating (WR) = (vv+m.R)+(mv+m.C)(vv+m.R)+(mv+m.C) where,\n",
        "\n",
        "* v is the number of votes for the movie\n",
        "* m is the minimum votes required to be listed in the chart\n",
        "* R is the average rating of the movie C is the mean vote across the whole report.\n",
        "\n",
        "Source: https://www.kaggle.com/rounakbanik/movie-recommender-systems"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "3fLoevZDPH6j",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# add a weighted rating feature\n",
        "\n",
        "vote_averages = (movies[movies['vote_average']\n",
        "                 .notnull()]['vote_average'].astype('int')\n",
        "                )\n",
        "\n",
        "vote_counts = (movies[movies['vote_count']\n",
        "               .notnull()]['vote_count'].astype('int')\n",
        "              )\n",
        "\n",
        "\n",
        "C = vote_averages.mean()\n",
        "\n",
        "m = vote_counts.quantile(0.75)\n",
        "\n",
        "def weighted_rating(x):\n",
        "    v = x['vote_count']+1\n",
        "    R = x['vote_average']\n",
        "    return (v/(v+m) * R) + (m/(m+v) * C)\n",
        "\n",
        "movies['weighted_rating'] = movies.apply(weighted_rating, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "n0HFYoEEWE0c",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "assess_column(movies, 'weighted_rating')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "U2nI7sz0Qj1Q"
      },
      "cell_type": "markdown",
      "source": [
        "#### New Feature: revenue_to_budget_ratio"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "-Zony784Qcnt",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# this new feature can indicate \"success\" or \"failure\"\n",
        "# (depending on whether ration is < 0 or > 0)\n",
        "\n",
        "movies['revenue_to_budget_ratio'] = movies['revenue'] / movies['budget']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "hP_zZ9-xWPtL",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "assess_column(movies, 'revenue_to_budget_ratio')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "2LsZW81vjG5J"
      },
      "cell_type": "markdown",
      "source": [
        "### Feature Transformations\n",
        "\n",
        "Change existing features such that they can contribute more effeciently and effectively during machine learning.\n",
        "* one hot encoding transformation of categoric features\n",
        "* scaling transformation of numeric features\n",
        "* vectorizing paragraphs\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "62qJQKpCSo17",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# examine the movies data set without the \"large\" textual features\n",
        "movies.drop(['cast','crew','actors','overview'],axis=1).head(20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ydKzwGBhSo18",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# examine the movies data set for the \"large\" textual features\n",
        "movies[['cast','crew','actors','overview']].head(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "8ciT9C_JSo19",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# check the numeric columns\n",
        "movies.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "cqB7Jb2ExW8I"
      },
      "cell_type": "markdown",
      "source": [
        "#### Textual and categorical features"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "-b03Z0isxW8I",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import NMF"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "2DmH8r_txW8J",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## load stop words file\n",
        "\n",
        "def get_stop_words(stop_file_path):\n",
        "    \"\"\"load stop words \"\"\"\n",
        "    \n",
        "    with open(stop_file_path, 'r', encoding=\"utf-8\") as f:\n",
        "        stopwords = f.readlines()\n",
        "        stop_set = set(m.strip() for m in stopwords)\n",
        "        return frozenset(stop_set)\n",
        "\n",
        "#load a set of stop words\n",
        "stopwords=get_stop_words(\"movies/resources/stopwords.txt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "VTv5GHewxW8K",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# title\n",
        "# Vectorizing the titles - using word counts\n",
        "count_vectorizer = CountVectorizer(max_features=1000, binary=True, max_df=0.8,stop_words=stopwords) \n",
        "titles = movies[\"title\"].replace(np.nan,'')\n",
        "titles_transformed = count_vectorizer.fit_transform(titles)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "4qyx9hsvxW8N",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Examine the vectorized titles\n",
        "idx_to_word = np.array(count_vectorizer.get_feature_names())\n",
        "print(idx_to_word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "fjZb7_rFxW8P",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "title_titles = ['title_' + title for title in idx_to_word]\n",
        "titles_df = pd.DataFrame(titles_transformed.toarray(),columns=title_titles)\n",
        "titles_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "G0GVr1BxxW8Q",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## reduce the encoded features using a threshold\n",
        "def reduce_sparse_encoding(df,threshold):\n",
        "    headers_list = list(df.columns.values)\n",
        "    num_samples = df.shape[0]\n",
        "\n",
        "    for header in headers_list:\n",
        "        col_true_count = len(df[df[header] == 1])\n",
        "        if col_true_count/num_samples < threshold:\n",
        "            df = df.drop(header, axis=1)\n",
        "    \n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "JW-TBtrOxW8R",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# reduce the features using 0.1% of 1\n",
        "titles_df = reduce_sparse_encoding(titles_df,0.001)\n",
        "titles_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ZwDp8fYlxW8U",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# belongs_to_collection\n",
        "# Replace empty lists with an empty string\n",
        "collections = [''.join(collection).lower().replace('collection','').replace('series','') \n",
        "               for collection in movies['belongs_to_collection'].values]\n",
        "# Vectorizing the collection names - using word counts\n",
        "count_vectorizer = CountVectorizer(max_features=100, stop_words=stopwords) \n",
        "collections_transformed = count_vectorizer.fit_transform(collections)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "-tMpV7UBxW8V",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Examine the vectorized collections\n",
        "idx_to_word = np.array(count_vectorizer.get_feature_names())\n",
        "print(idx_to_word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "0gqUGlaJxW8Y",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create a DataFrame\n",
        "collection_titles = ['coll_' + title for title in idx_to_word]\n",
        "collections_df = pd.DataFrame(collections_transformed.toarray(),columns=collection_titles)\n",
        "collections_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "0_JbV7XPxW8b",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# reduce the features using 0.1% of 1\n",
        "collections_df = reduce_sparse_encoding(collections_df,0.001)\n",
        "collections_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ZhO7yqLUxW8e",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# keywords\n",
        "# Vectorizing keywords - re-use the vectorizer used for collections\n",
        "keywords = [''.join(keyword).lower() \n",
        "               for keyword in movies['keywords'].values]\n",
        "\n",
        "# Vectorizing the keywords - using word counts\n",
        "count_vectorizer = CountVectorizer(max_features=100, stop_words=stopwords) \n",
        "keywords_transformed = count_vectorizer.fit_transform(keywords)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "lhkjhSlExW8i",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Examine the vectorized keywords\n",
        "idx_to_word = np.array(count_vectorizer.get_feature_names())\n",
        "print(idx_to_word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "PYJ283wHxW8n",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create a DataFrame\n",
        "keyword_titles = ['key_' + title for title in idx_to_word]\n",
        "keywords_df = pd.DataFrame(keywords_transformed.toarray(),columns=keyword_titles)\n",
        "keywords_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "zraAsDQFxW8r",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# reduce the features using 0.1% of 1\n",
        "keywords_df = reduce_sparse_encoding(keywords_df,0.001)\n",
        "keywords_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "isUeEt8KxW8t",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# tagline\n",
        "# Vectorizing tagline - using tf-idf weighted term-document matrix\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=1000, max_df=0.8,stop_words=stopwords) \n",
        "taglines = movies['tagline'].replace(np.nan,'')\n",
        "taglines_transformed = tfidf_vectorizer.fit_transform(taglines)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "xsowU3xPxW8u",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Examine the vectorized taglines\n",
        "idx_to_word = np.array(tfidf_vectorizer.get_feature_names())\n",
        "print(idx_to_word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Nm9GTLOjxW8y",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# apply NMF\n",
        "nmf = NMF(n_components=100, solver=\"mu\")\n",
        "taglines_nmf = nmf.fit_transform(taglines_transformed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "6j_NUHywxW8y",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create a DataFrame for tagline\n",
        "tagline_titles = nmf.components_\n",
        "tagline_titles = ['tagline_' + '_'.join(idx_to_word[title.argsort()[-10:]]) for title in tagline_titles]\n",
        "tagline_df = pd.DataFrame(taglines_nmf,columns=tagline_titles)\n",
        "tagline_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "9CLalmkhxW80",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## reduce the weighted features using a threshold\n",
        "def reduce_sparse_weights(df,threshold):\n",
        "    headers_list = list(df.columns.values)\n",
        "\n",
        "    for header in headers_list:\n",
        "        col_weight_sum = df[header].sum()\n",
        "        if col_weight_sum < threshold:\n",
        "            df = df.drop(header, axis=1)\n",
        "    \n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "aE0g9zFuxW81",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# reduce the features using sum weights of 1\n",
        "tagline_df = reduce_sparse_weights(tagline_df,1)\n",
        "tagline_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "yQQkCAWsxW83",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# overview\n",
        "# Vectorizing overview - using tf-idf weighted term-document matrix \n",
        "overviews = movies['overview'].replace(np.nan,'')\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=1000, max_df=0.8,stop_words=stopwords) \n",
        "overviews_transformed = tfidf_vectorizer.fit_transform(overviews)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "IQZMPVpGxW84",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Examine the vectorized overviews\n",
        "idx_to_word = np.array(tfidf_vectorizer.get_feature_names())\n",
        "print(idx_to_word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "b1Z2MuMExW86",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# apply NMF : re-use the nmf component \n",
        "overviews_nmf = nmf.fit_transform(overviews_transformed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "nxZ1HZbsxW88",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create a DataFrame for overview\n",
        "overview_titles = nmf.components_\n",
        "overview_titles = ['overview_' + '_'.join(idx_to_word[title.argsort()[-10:]]) for title in overview_titles]\n",
        "overview_df = pd.DataFrame(overviews_nmf,columns=overview_titles)\n",
        "overview_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "j6VpsBQKxW8_",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# reduce the features using sum weights of 1\n",
        "overview_df = reduce_sparse_weights(overview_df,1)\n",
        "overview_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "MpZEuh92xW9A",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# spoken_languages\n",
        "# Vectorizing spoken languages - re-use the vectorizer used for collections\n",
        "count_vectorizer = CountVectorizer()\n",
        "spoken_laguages = [','.join(lang).lower() \n",
        "               for lang in movies['spoken_languages'].values]\n",
        "spoken_laguages_transformed = count_vectorizer.fit_transform(spoken_laguages)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "hCJRwORExW9B",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Examine the vectorized spoken languages\n",
        "idx_to_word = np.array(count_vectorizer.get_feature_names())\n",
        "print(idx_to_word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "5xuhsE2NxW9E",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create a DataFrame\n",
        "spoken_languages_titles = ['s_lang_' + lang for lang in idx_to_word]\n",
        "spoken_languages_df = pd.DataFrame(spoken_laguages_transformed.toarray(),columns=spoken_languages_titles)\n",
        "spoken_languages_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "-wi7kHYexW9G",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# reduce the features using 0.1% of 1\n",
        "spoken_languages_df = reduce_sparse_encoding(spoken_languages_df,0.001)\n",
        "spoken_languages_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "UN0EyU_zxW9I",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# original_language\n",
        "# Vectorizing original language - re-use the vectorizer used for collections\n",
        "count_vectorizer = CountVectorizer()\n",
        "original_languages = movies['original_language'].replace(np.nan,'')\n",
        "original_languages_transformed = count_vectorizer.fit_transform(original_languages)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "e7Le4-5kxW9K",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Examine the vectorized original languages\n",
        "idx_to_word = np.array(count_vectorizer.get_feature_names())\n",
        "print(idx_to_word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "EjvjCioHxW9O",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create a DataFrame\n",
        "original_languages_titles = ['o_lang_' + lang for lang in idx_to_word]\n",
        "original_languages_df = pd.DataFrame(original_languages_transformed.toarray(),columns=original_languages_titles)\n",
        "original_languages_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "mSL0vt3kxW9Q",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# reduce the features using 0.1% of 1\n",
        "original_languages_df = reduce_sparse_encoding(original_languages_df,0.001)\n",
        "original_languages_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ZVlyUoCqxW9R",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# homepage_domain\n",
        "# Vectorizing original language - using ngram vectorizing (to select all 3 parts of the url)\n",
        "ngram_vectorizer = CountVectorizer(max_features=100, binary=True, max_df=0.8,stop_words=stopwords,ngram_range=(3, 3)) \n",
        "homepage_domains = movies['homepage_domain'].replace(np.nan,'')\n",
        "homepage_domains_transformed = ngram_vectorizer.fit_transform(homepage_domains)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "9C9l_f59xW9T",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Examine the vectorized original languages\n",
        "idx_to_word = np.array(ngram_vectorizer.get_feature_names())\n",
        "print(idx_to_word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "tri2J6fFxW9U",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create a DataFrame\n",
        "homepage_domain_titles = ['home_'+ url.replace(' ','.') for url in idx_to_word]\n",
        "homepage_domains_df = pd.DataFrame(homepage_domains_transformed.toarray(),columns=homepage_domain_titles)\n",
        "homepage_domains_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "jDo4UabYxW9V",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# reduce the features using 0.1% of 1\n",
        "homepage_domains_df = reduce_sparse_encoding(homepage_domains_df,0.001)\n",
        "homepage_domains_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "hdWL_STyxW9X",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# genres\n",
        "# Prepare the data in the column\n",
        "genres = [','.join(gen) for gen in movies['genres'].values]\n",
        "\n",
        "# Vectorizing genres \n",
        "count_vectorizer = CountVectorizer()\n",
        "genres_transformed = count_vectorizer.fit_transform(genres)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "78l6yNjKxW9Y",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Examine the vectorized production genres\n",
        "idx_to_word = np.array(count_vectorizer.get_feature_names())\n",
        "print(idx_to_word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "gT4-OLm7xW9Z",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Set titles and define new DataFrame\n",
        "genre_titles = ['gen_' + gen for gen in idx_to_word]\n",
        "genres_df = pd.DataFrame(genres_transformed.toarray(),columns=genre_titles)\n",
        "genres_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "PX7pqv8lxW9a",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# reduce the features using 0.1% of 1\n",
        "genres_df = reduce_sparse_encoding(genres_df,0.001)\n",
        "genres_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "57FifhS6xW9c",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# production_companies\n",
        "\n",
        "# Prepare the data in the column\n",
        "production_companies = [','.join(prod).strip().replace(' ','_') \n",
        "               for prod in movies['production_companies'].values]\n",
        "\n",
        "# Vectorizing production companies \n",
        "count_vectorizer = CountVectorizer(max_features=1000)\n",
        "production_companies_transformed = count_vectorizer.fit_transform(production_companies)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "fG0no9VSxW9d",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Examine the vectorized production companies\n",
        "idx_to_word = np.array(count_vectorizer.get_feature_names())\n",
        "print(idx_to_word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "CXkIExRwxW9h",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Set titles and define new DataFrame\n",
        "production_companies_titles = ['prod_' + prod for prod in idx_to_word]\n",
        "production_companies_df = pd.DataFrame(production_companies_transformed.toarray(),columns=production_companies_titles)\n",
        "production_companies_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ClOl2kPLxW9l",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# reduce the features using 0.1% of 1\n",
        "production_companies_df = reduce_sparse_encoding(production_companies_df,0.001)\n",
        "production_companies_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "hVANG5rLxW9n",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# production_countries\n",
        "\n",
        "# Vectorizing production countries \n",
        "count_vectorizer = CountVectorizer() \n",
        "production_countries = [','.join(country).lower() \n",
        "               for country in movies['production_countries'].values]\n",
        "production_countries_transformed = count_vectorizer.fit_transform(production_countries)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "PnJBBV2exW9o",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Examine the vectorized production countries\n",
        "idx_to_word = np.array(count_vectorizer.get_feature_names())\n",
        "print(idx_to_word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Eebyz2Y5xW9p",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create a DataFrame\n",
        "production_countries_titles = ['country_' + country for country in idx_to_word]\n",
        "production_countries_df = pd.DataFrame(production_countries_transformed.toarray(),columns=production_countries_titles)\n",
        "production_countries_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "qctQo13axW9r",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# reduce the features using 0.1% of 1\n",
        "production_countries_df = reduce_sparse_encoding(production_countries_df,0.001)\n",
        "production_countries_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Ch9Ag7MsxW9s",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# director\n",
        "# Prepare the data in the column\n",
        "directors = [director.strip().replace(' ','_') \n",
        "               for director in movies['director'].values]\n",
        "\n",
        "# Vectorizing production companies\n",
        "count_vectorizer = CountVectorizer(max_features=100) \n",
        "directors_transformed = count_vectorizer.fit_transform(directors)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "DR-w_hWAxW9t",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Examine the vectorized directors\n",
        "idx_to_word = np.array(count_vectorizer.get_feature_names())\n",
        "print(idx_to_word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "i-eD1RYuxW9u",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Set titles and define new DataFrame\n",
        "director_titles = ['director_' + director for director in idx_to_word]\n",
        "directors_df = pd.DataFrame(directors_transformed.toarray(),columns=director_titles)\n",
        "directors_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "vOGjwRbtxW9w",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# reduce the features using 0.1% of 1\n",
        "directors_df = reduce_sparse_encoding(directors_df,0.001)\n",
        "directors_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "4sgMb7JGxW9x",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# actors\n",
        "\n",
        "# Prepare the data in the column\n",
        "actors = [','.join(actor).strip().replace(' ','_') \n",
        "               for actor in movies['actors'].values]\n",
        "\n",
        "# Vectorizing actors\n",
        "count_vectorizer = CountVectorizer(max_features=1000) \n",
        "actors_transformed = count_vectorizer.fit_transform(actors)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "1hF9OI4RxW9z",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Examine the vectorized actors\n",
        "idx_to_word = np.array(count_vectorizer.get_feature_names())\n",
        "print(idx_to_word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "bc5zFxDxxW91",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Set titles and define new DataFrame\n",
        "actor_titles = ['actor_' + actor for actor in idx_to_word]\n",
        "actors_df = pd.DataFrame(actors_transformed.toarray(),columns=actor_titles)\n",
        "actors_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "RL8SGcFdxW92",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# reduce the features using 0.1% of 1\n",
        "actors_df = reduce_sparse_encoding(actors_df,0.001)\n",
        "actors_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "MkWhQJfExW93",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# one-hot encoding for categorical features\n",
        "\n",
        "# season\n",
        "season_df = pd.get_dummies(movies[['season']],prefix='season')\n",
        "season_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "3TkfBWeQxW94",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# reduce the features using 0.1% of 1\n",
        "season_df = reduce_sparse_encoding(season_df,0.001)\n",
        "season_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "tTYXZgYfxW98",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# status\n",
        "status_df = pd.get_dummies(movies[['status']],prefix='status')\n",
        "status_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "lFIdGZW5xW-A",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# reduce the features using 0.1% of 1\n",
        "status_df = reduce_sparse_encoding(status_df,0.001)\n",
        "status_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "-sZPmNKlxW-C",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# franchise\n",
        "franchise_df = pd.get_dummies(movies[['franchise']],prefix='fran')\n",
        "franchise_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "5Gvb5X53xW-G",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# check the stats - no need to remove encoded features\n",
        "column_stats(movies,'franchise')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m2YFHY2kqYF8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "movies.columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "DAd5t_fqjaU4"
      },
      "cell_type": "markdown",
      "source": [
        "## Feature Selection\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "QH4grCTatdqY",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create a copy of original movies data frame\n",
        "movies_reduced = movies.copy() \n",
        "# drop columns with no added value to the problem space\n",
        "movies_reduced = movies_reduced.drop(columns = 'poster_path')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "SrDj4L-MTVL7",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# case for dropping external IMDB identifiers\n",
        "\n",
        "print('MOVIES: missing imdb ids in main data:',\n",
        "      movies_reduced['imdb_id'].isnull().sum())\n",
        "\n",
        "# print('LINKS: data missing Imdb ids:',\n",
        "#       movies_reduced[\"imdb_id\"].isnull().sum())\n",
        "\n",
        "# What's tmdbId?\n",
        "#print('LINKS: data missing Tmdb ids:'\n",
        "#      ,movies_reduced[\"tmdbId\"].isnull().sum())\n",
        "\n",
        "# print('# of records where movies.id and links.movieId match:', \n",
        "#       movies_reduced.drop(['imdb_id'], axis=1)\n",
        "#             .merge(links, left_on='id', right_on='movieId', how='inner').shape\n",
        "#      )\n",
        "\n",
        "# print('# of records where movies.imdb_id and links.imdbId match:', \n",
        "#       movies_reduced.merge(links, left_on='imdb_id',\n",
        "#                           right_on='imdb_id',\n",
        "#                           how='inner').shape\n",
        "#      )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "S6OuWrimt14Z",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# drop id columns (since integrity of these fields is poor)\n",
        "movies_reduced = movies_reduced.drop(columns = 'imdb_id')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "6VVj6N1lxW-R",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# check adult feature\n",
        "column_stats(movies_reduced,'adult')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ItwwK42vxW-S",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# check video feature\n",
        "column_stats(movies_reduced,'video')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "uH8p2EEzSo2S",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# drop additional columns\n",
        "movies_reduced = movies_reduced.drop(columns = 'adult')  # as it has only 9 true values\n",
        "movies_reduced = movies_reduced.drop(columns = 'homepage')  #replaced by homepage_domain\n",
        "movies_reduced = movies_reduced.drop(columns = 'video')  # as it has only 95 true values\n",
        "movies_reduced = movies_reduced.drop(columns = 'cast')  # parsed into actors\n",
        "movies_reduced = movies_reduced.drop(columns = 'crew')  # partially expressed in director feature\n",
        "movies_reduced = movies_reduced.drop(columns = 'release_date')  # can be replaced with season and release_year"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "PFxQCnCfoFj5",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "movies_reduced.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "qvwl4EnNSc2y",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# case for dropping original_title\n",
        "compare = ['title', 'original_title']\n",
        "movies_reduced[movies_reduced['original_title'] != movies_reduced['title']][['title', 'original_title']].head(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "NJ4pBCbcSukv",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# drop original_title (it appears to be the untranslated version of the title)\n",
        "movies_reduced = movies_reduced.drop(columns='original_title')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "itnV-0ZXxW-Z",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# remove vectorized and encoded features (to be merged later)\n",
        "movies_reduced = movies_reduced.drop(columns = 'belongs_to_collection') # to be replaced with collections_df\n",
        "movies_reduced = movies_reduced.drop(columns = 'genres') # to be replaced with genres_df\n",
        "movies_reduced = movies_reduced.drop(columns = 'title') # to be replaced with titles_df\n",
        "movies_reduced = movies_reduced.drop(columns = 'keywords') # to be replaced with keywords_df\n",
        "movies_reduced = movies_reduced.drop(columns = 'tagline') # to be replaced with tagline_df\n",
        "movies_reduced = movies_reduced.drop(columns = 'overview') # to be replaced with overview_df\n",
        "movies_reduced = movies_reduced.drop(columns = 'spoken_languages') # to be replaced with spoken_languages_df\n",
        "movies_reduced = movies_reduced.drop(columns = 'original_language') # to be replaced with original_languages_df\n",
        "movies_reduced = movies_reduced.drop(columns = 'homepage_domain') # to be replaced with homepage_domains_df\n",
        "movies_reduced = movies_reduced.drop(columns = 'production_companies') # to be replaced with production_companies_df\n",
        "movies_reduced = movies_reduced.drop(columns = 'production_countries') # to be replaced with production_countries_df\n",
        "movies_reduced = movies_reduced.drop(columns = 'director') # to be replaced by directors_df\n",
        "movies_reduced = movies_reduced.drop(columns = 'actors') # to be replaced with actors_df\n",
        "movies_reduced = movies_reduced.drop(columns = 'season') # to be replaced with season_df\n",
        "movies_reduced = movies_reduced.drop(columns = 'status') # to bre replaced with status_df\n",
        "movies_reduced = movies_reduced.drop(columns = 'franchise') # to be replaced with franchise_df\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "yT2HFJJmxW-Z",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "movies_reduced.head(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "UVyWvkuCSo2Z"
      },
      "cell_type": "markdown",
      "source": [
        "#### Analyze Correlation"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "EB6JL_xtSo2Z",
        "scrolled": true,
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Examine rating vs numerical features\n",
        "\n",
        "from pandas.plotting import scatter_matrix\n",
        "\n",
        "attributes = [\"budget\", \"popularity\",\"revenue\",\"runtime\",\"vote_average\",\"vote_count\",\"cast_size\",\"crew_size\",\"revenue_to_budget_ratio\",\"release_year\",\"weighted_rating\"]\n",
        "scatter_matrix(movies_reduced[attributes], figsize=(15, 15))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Dz4Wg70vSo2a"
      },
      "cell_type": "markdown",
      "source": [
        "* Most of the features are correlated to some extent\n",
        "* revenue_to_budget_ratio and release_year don't seem to be correlated with anything - probably can be removed"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "XuDwI8vKxW-f",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# remove features that don't have meaningful correlation with the revenue\n",
        "movies_reduced = movies_reduced.drop(columns = 'release_year') \n",
        "movies_reduced = movies_reduced.drop(columns = 'revenue_to_budget_ratio') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "TMFFe7_TxW-g",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "movies_reduced.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "t5wW5X_YxW-i"
      },
      "cell_type": "markdown",
      "source": [
        "#### Adding the encoded data sets"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "fNDknEdbxW-i",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "movies_full = movies_reduced.copy()\n",
        "movies_full.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "5mNPfhbTxW-j",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "movies_full = movies_full.join(titles_df)\n",
        "movies_full.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "RidlH5I1xW-k",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "movies_full = movies_full.join(collections_df)\n",
        "movies_full.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "pX9AjnZIxW-o",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "movies_full = movies_full.join(keywords_df)\n",
        "movies_full.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ND9AtukTxW-q",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "movies_full = movies_full.join(tagline_df)\n",
        "movies_full.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Tu_YTNUxxW-r",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "movies_full = movies_full.join(overview_df)\n",
        "movies_full.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "bBlMyV9fxW-t",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "movies_full = movies_full.join(spoken_languages_df)\n",
        "movies_full.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "jIXOAERBxW-v",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "movies_full = movies_full.join(original_languages_df)\n",
        "movies_full.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "JAJ8Vpf7xW-w",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "movies_full = movies_full.join(homepage_domains_df)\n",
        "movies_full.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "oHaNsQ3WxW-y",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "movies_full = movies_full.join(production_companies_df)\n",
        "movies_full.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "xtXghtBYxW-2",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "movies_full = movies_full.join(production_countries_df)\n",
        "movies_full.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "lWbZDiSRxW-4",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "movies_full = movies_full.join(directors_df)\n",
        "movies_full.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "LRJd6i5dxW-5",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "movies_full = movies_full.join(actors_df)\n",
        "movies_full.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "LYWJlER8xW-7",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "movies_full = movies_full.join(season_df)\n",
        "movies_full.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Y4dUNZSnxW-8",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "movies_full = movies_full.join(status_df)\n",
        "movies_full.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "0jyl-WoMxW--",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "movies_full = movies_full.join(franchise_df)\n",
        "movies_full.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "7G4w6O5zxW--",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "movies_full = movies_full.join(genres_df)\n",
        "movies_full.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "dxtO4SKRxW_B",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "movies_full.head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "pSjNQfcCt_Xj"
      },
      "cell_type": "markdown",
      "source": [
        "#### Final cleansing"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "FOn4rCdst_Xj",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# remove empty target values\n",
        "movies_full_filtered = movies_full[movies_full['revenue'].notnull()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "bdmrnGyct_Xk",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# identify which columns have empty values\n",
        "print('Empty values for budget: {}'.format(movies_full_filtered['budget'].isnull().values.any()))\n",
        "print('Empty values for popularity: {}'.format(movies_full_filtered['popularity'].isnull().values.any()))\n",
        "print('Empty values for runtime: {}'.format(movies_full_filtered['runtime'].isnull().values.any()))\n",
        "print('Empty values for vote_average: {}'.format(movies_full_filtered['vote_average'].isnull().values.any()))\n",
        "print('Empty values for vote_count: {}'.format(movies_full_filtered['vote_count'].isnull().values.any()))\n",
        "print('Empty values for cast_size: {}'.format(movies_full_filtered['cast_size'].isnull().values.any()))\n",
        "print('Empty values for crew_size: {}'.format(movies_full_filtered['crew_size'].isnull().values.any()))\n",
        "print('Empty values for weighted_rating: {}'.format(movies_full_filtered['weighted_rating'].isnull().values.any()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "bG33tl6Jt_Xk",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# replace NaN with mean\n",
        "movies_full_filtered['budget'].fillna((movies_full_filtered['budget'].mean()), inplace=True)\n",
        "movies_full_filtered['runtime'].fillna((movies_full_filtered['runtime'].mean()), inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "npIXW8Bvt_Xk",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# get data set info\n",
        "movies_full_filtered.info()\n",
        "movies_full_filtered.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "I95WD6GCqIUo"
      },
      "cell_type": "markdown",
      "source": [
        "#### Review and Save Enhanced Dataset"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "N_tSr4y78C3n",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# copy the final feature set to movies\n",
        "movies = movies_full_filtered.copy()\n",
        "\n",
        "# verify the schema and data end results\n",
        "\n",
        "movies.name = 'movies'\n",
        "quick_schema_analysis(movies)\n",
        "quick_data_analysis(movies)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "YeuEpDuTqN7m",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# save movies dataframe to a csv\n",
        "                    \n",
        "movies_final_file = os.path.join(PROJECT_LOCAL_DIR, 'movies_final.csv')\n",
        "\n",
        "print('Saving final model to ' + movies_final_file + '...')\n",
        "\n",
        "movies.to_csv(movies_final_file,\n",
        "              encoding='utf-8',\n",
        "              index=False\n",
        "              )\n",
        "\n",
        "print('Model saved.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "PbkMOtcut_Xn"
      },
      "cell_type": "markdown",
      "source": [
        "## Feature selction and reduction - continued"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "snUtR1PKt_Xn",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "movies_model = movies_full_filtered.copy().drop('id',axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "JqU2RpGgt_Xn",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# define target value and features\n",
        "target = 'revenue'\n",
        "features = list(movies_model.columns)\n",
        "features = [f for f in features if f!=target]\n",
        "\n",
        "feature_set = movies_model[features]\n",
        "target_col = movies_model[target]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Rr07lsOct_Xp"
      },
      "cell_type": "markdown",
      "source": [
        "#### prepare the train and test data sets"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "BuMl4gTKt_Xp",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_set, test_set = train_test_split(movies_model, test_size=0.3)\n",
        "\n",
        "X_tr = train_set[features]\n",
        "y_tr = train_set[[target]]\n",
        "\n",
        "X_te = test_set[features]\n",
        "y_te = test_set[[target]]\n",
        "\n",
        "#add a new target variable for classification \n",
        "\n",
        "y_tr_cl = np.ravel(y_tr)/np.ravel(train_set.budget)>2.50\n",
        "y_te_cl = np.ravel(y_te)/np.ravel(test_set.budget)>2.50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Q8oagDhUt_Xq"
      },
      "cell_type": "markdown",
      "source": [
        "#### SelectKBest with chi square"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Pssu4zqpt_Xq",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Import the necessary libraries first\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "-yGLxfLkt_Xr",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# define the select K best model - using chi square\n",
        "select_best = SelectKBest(score_func=chi2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "phpI4x85t_Xs",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# identify the best hyper parameter\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "k_arr = [10, 20, 30, 40 ,50, 75, 100]\n",
        "\n",
        "for k in k_arr:\n",
        "    select_best.k = k\n",
        "    select_best.fit(np.asarray(X_tr),np.asarray(y_tr, dtype=\"|S100\"))\n",
        "    X_tr_new = select_best.transform(X_tr)\n",
        "    X_te_new = select_best.transform(X_te)\n",
        "    print(\"\\n\")\n",
        "    print(\"Performance for k={}\".format(k))\n",
        "    print(\"Trainng set:\")\n",
        "    lin_scores = cross_val_score(LinearRegression(), X_tr_new, y_tr, scoring=\"neg_mean_squared_error\", cv=4)\n",
        "    lin_rmse_scores = np.sqrt(-lin_scores)\n",
        "    display_scores(lin_rmse_scores)\n",
        "    print(\"Test set:\")\n",
        "    lin_scores = cross_val_score(LinearRegression(), X_te_new, y_te, scoring=\"neg_mean_squared_error\", cv=4)\n",
        "    lin_rmse_scores = np.sqrt(-lin_scores)\n",
        "    display_scores(lin_rmse_scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "dgK0R8C6t_Xt",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# pick the best : for k=40\n",
        "select_best.k = 40\n",
        "select_best.fit(np.asarray(X_tr),np.asarray(y_tr, dtype=\"|S100\"))\n",
        "X_tr = select_best.transform(X_tr)\n",
        "X_te = select_best.transform(X_te)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "pkeqYTRSt_Xu"
      },
      "cell_type": "markdown",
      "source": [
        "#### Scaling"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "k1PodPs9t_Xu",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_tr)\n",
        "X_tr = scaler.transform(X_tr)\n",
        "X_te = scaler.transform(X_te)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "RsXgc8jmt_Xw"
      },
      "cell_type": "markdown",
      "source": [
        "#### Feature tuning pipeline (using linear regression)"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "-bP2Y4B7t_Xw",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Linear regression and pipeline (to evaluate feature selection and reduction)\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "steps = [('regression',LinearRegression())]\n",
        "pipeline = Pipeline(steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "BtYXGJ2st_Xy"
      },
      "cell_type": "markdown",
      "source": [
        "#### PCA"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "GXrfxgL2t_Xy",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "# Make an instance of the Model\n",
        "pca = PCA()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "eV33FKy1t_Xz",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# add to the steps collection\n",
        "pipeline.steps.insert(0,('pca',pca))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "eUrQvK0Ut_X0",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# GridSearchCV\n",
        "parameters = {}\n",
        "grid_search = GridSearchCV(pipeline,parameters, cv=4, scoring='neg_mean_squared_error')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "UsM5F0uUt_X0",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# add corresponding parameters\n",
        "grid_search.param_grid['pca__n_components'] = [0.9,0.91,0.92,0.93,0.94,0.95,0.96,0.97,0.98,0.99,0.999,1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "BN3VbX6Nt_X1",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# fit the model\n",
        "grid_search.fit(X_tr,y_tr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ADCvXK78t_X1",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# training scores\n",
        "print(\"Best pca parameter is {}\".format(grid_search.best_params_))\n",
        "lin_scores = grid_search.best_score_\n",
        "lin_rmse_scores = np.sqrt(-lin_scores)\n",
        "display_scores(lin_rmse_scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "a5ToKdORt_X2",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# run best model with test data\n",
        "grid_search_final = grid_search.best_estimator_ \n",
        "grid_search_final.fit(X_te,y_te)\n",
        "lin_scores = cross_val_score(grid_search_final, X_te, y_te, scoring=\"neg_mean_squared_error\", cv=4)\n",
        "lin_rmse_scores = np.sqrt(-lin_scores)\n",
        "display_scores(lin_rmse_scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "KKntgKOTt_X2",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# apply tranformaiton to the features\n",
        "pca.n_components = 0.999\n",
        "pca.fit(X_tr)\n",
        "X_tr = pca.transform(X_tr)\n",
        "X_te = pca.transform(X_te)\n",
        "\n",
        "# check the number of principal components\n",
        "print(pca.n_components_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "vp-2O9dMt_X3",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# tidy up - remove the pca step from the pipeline\n",
        "del pipeline.steps[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "qvQ0t1ept_X3"
      },
      "cell_type": "markdown",
      "source": [
        "#### Clustering - K-means"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "7Yrhxo9wt_X4",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "kmeans = KMeans()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "KDwjhOqct_X4",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# add to the steps collection\n",
        "pipeline.steps.insert(0,('kmeans',kmeans))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "K2gVi91_t_X5",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# GridSearchCV\n",
        "parameters = {}\n",
        "grid_search = GridSearchCV(pipeline,parameters, cv=4, scoring='neg_mean_squared_error')\n",
        "\n",
        "# add corresponding parameters\n",
        "grid_search.param_grid['kmeans__n_clusters'] = [2,4,6,8,10,15,20,30,40]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "b6KuLBzBt_X5",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# fit the model\n",
        "grid_search.fit(X_tr,y_tr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ED5gGBY7t_X5",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# training set scores\n",
        "print(\"Best k-means parameter is {}\".format(grid_search.best_params_))\n",
        "lin_scores = grid_search.best_score_\n",
        "lin_rmse_scores = np.sqrt(-lin_scores)\n",
        "display_scores(lin_rmse_scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "p64cWV5zt_X6",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# try with test data\n",
        "grid_search_final = grid_search.best_estimator_ \n",
        "grid_search_final.fit(X_te,y_te)\n",
        "lin_scores = cross_val_score(grid_search_final, X_te, y_te, scoring=\"neg_mean_squared_error\", cv=4)\n",
        "lin_rmse_scores = np.sqrt(-lin_scores)\n",
        "display_scores(lin_rmse_scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "wzBOrKVTt_X7"
      },
      "cell_type": "markdown",
      "source": [
        "**Conclusion** : results don't improve. Skip clustering"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "ScnQpevOVCxI"
      },
      "cell_type": "markdown",
      "source": [
        "# 4.0 Model "
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "r5V-A-VKIzlX"
      },
      "cell_type": "markdown",
      "source": [
        "## Reasons for considering a classification model in addition to the regression model.\n",
        "\n",
        "Box Office profits are a function of production budgets, ticket prices & Marketing/ Distribution costs based on their year of release.\n",
        "\n",
        "\n",
        "Hence, while evaluating historical values, profit calculations without accounting for inflation doesnt always provide the big picture (pun intended). A recommended option is arriving at a revenue to budget ratio (R/B), which offers better insights compared to revenue recognition alone. \n",
        "\n",
        "Further, this ratio is also useful in determining the relative success of a theatrical release. The total cost of movie production is not limited to production budgets but should take into account the distribution and marketing costs which is increasingly becoming important. Accordingly, movie producers and industry watchers now believe that a movie needs to make in excess of 2.5 times its production budget even to be considered a moderate success.\n",
        "\n",
        "Hence, the classifier feature matrix can drop the 'revenue' and 'revenue to budget ratio' as new unseen data ( data on movies that are yet to be released which we want to know whether will be a success or failure) will not have a revenue column. The attempt here is to predict film success using features like genre, production company, month/season of release, cast/crew size, country of production, whether part of a franchise, weighted rating etc. These are parameters that are already known before the movie's release.\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "pWon2633VCxs"
      },
      "cell_type": "markdown",
      "source": [
        "## Classification"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "YxNJ9NvrIzlt"
      },
      "cell_type": "markdown",
      "source": [
        "### 1. Logistic Regression"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "6GQv-nVPVCxw",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "logreg=LogisticRegression()\n",
        "params_logreg={'C':np.logspace(-5, 8, 15)}\n",
        "logreg_cv = GridSearchCV(logreg,params_logreg,cv=4)\n",
        "logreg_cv.fit(X_tr,y_tr_cl)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "pijIaT2XIzlv",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print('Accuracy: ',logreg_cv.best_score_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "mxSlW1qbIzlw"
      },
      "cell_type": "markdown",
      "source": [
        "### 2. Random Forest"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "gtbtQhLbIzlw",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "forest=RandomForestClassifier(random_state=42)\n",
        "params_forest = {'n_estimators': [3, 4, 6, 7, 10, 20, 50, 100]}\n",
        "forest_cv=GridSearchCV(forest, params_forest,cv=4)\n",
        "forest_cv.fit(X_tr,y_tr_cl)\n",
        "print('Accuracy: ',forest_cv.best_score_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "FY-m4jl_Izly"
      },
      "cell_type": "markdown",
      "source": [
        "### 3. KNN"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "sNlyk8vTIzly",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "knn=KNeighborsClassifier()\n",
        "params_knn = {'n_neighbors': [3, 5, 10, 20]}\n",
        "knn_cv=GridSearchCV(knn, params_knn,cv=4,n_jobs=-1)\n",
        "knn_cv.fit(X_tr,y_tr_cl)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "6gR6T2apIzl0",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print('Accuracy:',knn_cv.best_score_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "DR5XbYZxIzl2"
      },
      "cell_type": "markdown",
      "source": [
        "### 4. Decision tree"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "sLXJ_rftIzl3",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "tree = DecisionTreeClassifier()\n",
        "params_tree = {\"criterion\": [\"gini\", \"entropy\"],\"min_samples_split\": [2, 10, 20],\"max_depth\": [None, 2, 5, 10],\n",
        "              \"min_samples_leaf\": [1, 5, 10],\"max_leaf_nodes\": [None, 5, 10, 20]\n",
        "              }\n",
        "tree_cv=GridSearchCV(tree, params_tree,cv=4,n_jobs=-1)\n",
        "tree_cv.fit(X_tr,y_tr_cl)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "JIKwu5sQIzl5",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print('Accuracy:',tree_cv.best_score_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "5Wd2twg9Izl8"
      },
      "cell_type": "markdown",
      "source": [
        "### 5. AdaBoostClassifier with DecisionTree as base estimator"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "8jpWDiu_Izl8",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "ABC= AdaBoostClassifier(base_estimator=tree_cv.best_estimator_,n_estimators=100)\n",
        "np.mean(cross_val_score(ABC, X_tr, y_tr_cl, cv=3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-Kr8GEhVqYHV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 6. Voting Classifier "
      ]
    },
    {
      "metadata": {
        "id": "vo7I52OcqYHW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "classifiers = [('Logistic Regression', logreg_cv.best_estimator_),('K Nearest Neighbours', knn_cv.best_estimator_),\n",
        "               ('RandomForestClassifier', forest_cv.best_estimator_),('DecisionTreeClassifier',tree_cv.best_estimator_)]\n",
        "\n",
        "vc = VotingClassifier(estimators=classifiers)\n",
        "\n",
        "print('Accuracy: ',np.mean(cross_val_score(vc, X_tr, y_tr_cl, cv=3)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "yFmGoNCzIzmA"
      },
      "cell_type": "markdown",
      "source": [
        "## Regression"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "fUr0eeQOIzmA"
      },
      "cell_type": "markdown",
      "source": [
        "### 1. Linear Regression"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "CgjERLxMIzmA",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "lin_reg=LinearRegression()\n",
        "lin_scores = cross_val_score(lin_reg,X_tr,y_tr, scoring=\"neg_mean_squared_error\", cv=4)\n",
        "lin_rmse_scores = np.sqrt(-lin_scores)\n",
        "display_scores(lin_rmse_scores)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "S7ukoTlMIzmC"
      },
      "cell_type": "markdown",
      "source": [
        "### 2. Ridge Regression"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "apvTj2NSIzmC",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "param_grid = [{'alpha': [0.001,0.01,0.1,1,10,100,1000,1000]}]\n",
        "rr_cv = GridSearchCV(Ridge(), param_grid, cv=4, scoring='neg_mean_squared_error')\n",
        "rr_cv.fit(X_tr, y_tr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "fkfT_c9TIzmD",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(np.sqrt(-rr_cv.best_score_))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "8zluksJHIzmF"
      },
      "cell_type": "markdown",
      "source": [
        "### 3. Lasso Regression"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "6h9ArYORIzmF",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "param_grid = [{'alpha': [0.001,0.01,0.1,1,10,100,1000,1000]}]\n",
        "lr_cv = GridSearchCV(Lasso(), param_grid, cv=3, scoring='neg_mean_squared_error')\n",
        "lr_cv.fit(X_tr, y_tr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "dAG63v3pIzmH",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(np.sqrt(-lr_cv.best_score_))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "HwVxEkCGVCyP"
      },
      "cell_type": "markdown",
      "source": [
        "## Test"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "grZRH4y-IzmI"
      },
      "cell_type": "markdown",
      "source": [
        "#### Classification"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "86j75BZeIzmI",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "final_cl_model = logreg_cv.best_estimator_  \n",
        "y_pred_cl = final_cl_model.predict(X_te)\n",
        "\n",
        "print('Accuracy score: ',accuracy_score(y_te_cl,y_pred_cl))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gQC0Z9VwqYHa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Logistic Regression has a train accuracy of 0.769 and a test accuracy of 0.782**"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "FzIfU_5qIzmK"
      },
      "cell_type": "markdown",
      "source": [
        "#### Regression"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Rm0HayWmIzmK",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "final_reg_model = lin_reg\n",
        "final_reg_model.fit(X_tr,y_tr)\n",
        "\n",
        "y_pred_reg = final_reg_model.predict(X_te)\n",
        "\n",
        "final_mse = mean_squared_error(y_te, y_pred_reg)\n",
        "final_rmse = np.sqrt(final_mse)\n",
        "print(final_rmse)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "1PP5hqOZIzmM"
      },
      "cell_type": "markdown",
      "source": [
        "## Model Evaluation "
      ]
    },
    {
      "metadata": {
        "id": "teGe6twXqYHc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Best model - Logistic Regression"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "lnlz-iZgIzmM"
      },
      "cell_type": "markdown",
      "source": [
        "#### Confusion Matrix"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "GgxSsIUGIzmM",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def cm_heatmap(y_test,y_pred):\n",
        "    cm=confusion_matrix(y_test,y_pred)\n",
        "    conf_matrix=pd.DataFrame(data=cm,columns=['Predicted:0','Predicted:1'],index=['Actual:0','Actual:1'])\n",
        "    plt.figure(figsize = (8,5))\n",
        "    sns.heatmap(conf_matrix, annot=True,fmt='d',cmap=\"YlGnBu\")\n",
        "\n",
        "    \n",
        "cm_heatmap(y_te_cl,y_pred_cl)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SfsAdQspqYHe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Classification report"
      ]
    },
    {
      "metadata": {
        "id": "ZQ6ITpL1qYHe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(classification_report(y_te_cl, y_pred_cl))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y0yNnm3oqYHf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### ROC Curve and AUC"
      ]
    },
    {
      "metadata": {
        "id": "1JAehnK-qYHf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fpr, tpr, thresholds = roc_curve(y_te_cl, final_cl_model.predict_proba(X_te)[:,1])\n",
        "plt.plot(fpr,tpr)\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.0])\n",
        "plt.title('ROC curve for RandomForest classifier')\n",
        "plt.xlabel('False positive rate (1-Specificity)')\n",
        "plt.ylabel('Recall')\n",
        "plt.grid(True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ynqjv5emqYHf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print (\"Area under the curve is \", roc_auc_score(y_te_cl,final_cl_model.predict_proba(X_te)[:,1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mQPWjg9IqYHg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Evaluation of second best model"
      ]
    },
    {
      "metadata": {
        "id": "5NOtWwKyqYHj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Test\n",
        "y_pred_forest = forest_cv.predict(X_te)\n",
        "print('Accuracy score: ',accuracy_score(y_te_cl,y_pred_forest))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J2A-3MJAqYHk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Confusion matrix\n",
        "cm_heatmap(y_te_cl,y_pred_forest)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ulWHACikqYHk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(classification_report(y_te_cl, y_pred_forest))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SWE1iVVVqYHl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fpr, tpr, thresholds = roc_curve(y_te_cl, forest_cv.predict_proba(X_te)[:,1])\n",
        "plt.plot(fpr,tpr)\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.0])\n",
        "plt.title('ROC curve for RandomForest classifier')\n",
        "plt.xlabel('False positive rate (1-Specificity)')\n",
        "plt.ylabel('Recall')\n",
        "plt.grid(True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "morlVPWoqYHl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print (\"Area under the curve is \", roc_auc_score(y_te_cl,forest_cv.predict_proba(X_te)[:,1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "82ZuGj3pqYHn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Comparision of Accuracy, Precision and Recall between Logistic Regression and Random Forest classifiers"
      ]
    },
    {
      "metadata": {
        "id": "5D3_L1H8qYHn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In the case of movie box office prediction, a **high recall** translates to missing to identify a film that will be successful and  **high precision** ensures the majority of positively predicted films will be successful. \n",
        "\n",
        "As the average cost involved in producing a major studio film is extremely high and the number of films produced by a production house is relatively low, it is important that the classifier's positive predictions are going to be successful. Failing that will result in huge loss for the production house.  Hence a model that has high precision rather than high recall is preferred. "
      ]
    },
    {
      "metadata": {
        "id": "0pLc7bDFqYHn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def metrics_comp(y_te_cl,y_pred_cl,y_pred_forest):\n",
        "    metrics=pd.DataFrame(index=['Accuracy','Precision','Recall'],columns=['Logistic Regression','Random Forest'])\n",
        "    metrics.loc['Accuracy','Logistic Regression']=accuracy_score(y_te_cl,y_pred_cl)\n",
        "    metrics.loc['Precision','Logistic Regression']=precision_score(y_te_cl,y_pred_cl)\n",
        "    metrics.loc['Recall','Logistic Regression']=recall_score(y_te_cl,y_pred_cl)\n",
        "    metrics.loc['Accuracy','Random Forest']=accuracy_score(y_te_cl,y_pred_forest)\n",
        "    metrics.loc['Precision','Random Forest']=precision_score(y_te_cl,y_pred_forest)\n",
        "    metrics.loc['Recall','Random Forest']=recall_score(y_te_cl,y_pred_forest)\n",
        "    return(metrics)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0-nNzDDtqYHo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "metrics_comp(y_te_cl,y_pred_cl,y_pred_forest)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "323_wua_qYHo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fig,ax=plt.subplots(figsize=(8,6))\n",
        "metrics_comp(y_te_cl,y_pred_cl,y_pred_forest).plot(kind='bar',ax=ax)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d2dNnO93qYHp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Accuracy levels are consistant between both models. However, Logistic regression has higher precision than Random forest."
      ]
    },
    {
      "metadata": {
        "id": "CkCe_3RoqYHp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Tradeoff between precision and recall at different thresholds."
      ]
    },
    {
      "metadata": {
        "id": "u-n8foCBqYHp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "precision_logreg, recall_logreg, thresholds_logreg=precision_recall_curve(y_te_cl,final_cl_model.predict_proba(X_te)[:,1])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VgHWpHNzqYHq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def p_r_threshold(thresholds,precision,recall):\n",
        "\n",
        "    fig,ax=plt.subplots(figsize=(8,5))\n",
        "    ax.plot(thresholds_logreg,precision_logreg[1:],label='Precision')\n",
        "    ax.plot(thresholds_logreg,recall_logreg[1:],label='Recall')\n",
        "    ax.set_xlabel('Classification threshold')\n",
        "    ax.set_ylabel('precision,Recall')\n",
        "    ax.set_title('Logistic Regression: Precison Recall')\n",
        "    ax.legend()\n",
        "    ax.grid();\n",
        "p_r_threshold(thresholds_logreg,precision_logreg,recall_logreg)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0YIOdMz0qYHr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "At threshold 0.5 the recall is 0.4 with a very high precision (0.7). Moving the threshold to 0.6 results in a much higher precision (0.8) without a significant drop in recall."
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "ZayJ1-wH-F9W"
      },
      "cell_type": "markdown",
      "source": [
        "# 5.0 Analysis"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "B01IzjoN-Qec"
      },
      "cell_type": "markdown",
      "source": [
        "## Plots"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "-jQPo70--YCw"
      },
      "cell_type": "markdown",
      "source": [
        "## Scoring"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "kGcG5EgNv4rN"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "gXujQBEmQWqa"
      },
      "cell_type": "markdown",
      "source": [
        "# 6.0 Summary"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "gUnVjqqfWxvV"
      },
      "cell_type": "markdown",
      "source": [
        "## Observations"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "GhuG7d1wWqp0"
      },
      "cell_type": "markdown",
      "source": [
        "## Conclusions"
      ]
    }
  ]
}