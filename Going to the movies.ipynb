{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning 3253 - Project Assignment - \"Going to the Movies\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Members\n",
    "    \n",
    "* Craig Barbisan\n",
    "* Nisha Choondassery\n",
    "* Mark Hubbard\n",
    "* Itay Segal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Overview\n",
    "\n",
    "Using the \"Movies Dataset\"  from Kaggle, this project will create an optimal model for predicting a movie's rating (*__TO_REVIEW__*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The movies dataset\n",
    "The dataset for this project is originally sourced from https://www.kaggle.com/rounakbanik/the-movies-dataset.\n",
    "\n",
    "Credit: Rounak Banik\n",
    "\n",
    "This dataset is an ensemble of data collected from TMDB and GroupLens.\n",
    "* The Movie Details (i.e. Metadata), Credits and Keywords have been collected from the TMDB Open API.\n",
    "* The Movie Links and Ratings have been obtained from the Official GroupLens website.\n",
    "\n",
    "The following spreadsheets are used by this project:\n",
    "\n",
    "* __movies_metadata.csv__: The main Movies Metadata file. Contains information on 45,000 movies featured in the Full MovieLens dataset. Features include posters, backdrops, budget, revenue, release dates, languages, production countries and companies.\n",
    "\n",
    "* __credits.csv__: Consists of Cast and Crew Information for all our movies. Available in the form of a stringified JSON Object.\n",
    "\n",
    "* __keywords.csv__:  Contains the movie plot keywords for our MovieLens movies. Available in the form of a stringified JSON Object.\n",
    "\n",
    "The Full MovieLens dataset consisting of 26 million ratings and 750,000 tag applications from 270,000 users on all the 45,000 movies in this dataset can be accessed at https://grouplens.org/datasets/movielens/latest/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Frame the Problem and Look at the Big Picture (*TO_REVIEW*)\n",
    "Define the objective in business terms.\n",
    "\n",
    "How will your solution be used?\n",
    "\n",
    "What are the current solutions/workarounds (if any)?\n",
    "\n",
    "How should you frame this problem (supervised/unsupervised, online/offline, etc.)?\n",
    "\n",
    "How should performance be measured?\n",
    "\n",
    "Is the performance measure aligned with the business objective?\n",
    "\n",
    "What would be the minimum performance needed to reach the business objective?\n",
    "\n",
    "What are comparable problems? Can you reuse experience or tools?\n",
    "\n",
    "Is human expertise available?\n",
    "\n",
    "How would you solve the problem manually?\n",
    "\n",
    "List the assumptions you (or others) have made so far.\n",
    "\n",
    "Verify assumptions if possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Contents\n",
    "\n",
    "This notebook will explore the data, evaluate some models and draw conclusions. It is divided into the following main sections:\n",
    "\n",
    "0. Setup the environment - seting up the notebook environment.\n",
    "1. Get the data - loading the data set into the notebook.\n",
    "2. Explore the data - exploring the raw movies data.\n",
    "3. Prepare the data - data cleansing, feature selection\\reduction\\engineering and standardization\n",
    "\n",
    "2. Model - training and testing various models.\n",
    "3. Analysis - analyzing the model results.\n",
    "4. Summary - summarizing the observations and conclusions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the basic libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import ast\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter matrix plotting\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "# enable advanced plots\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for reading and writing ZIP files\n",
    "from zipfile import ZipFile\n",
    "# to retrieve from a url\n",
    "from urllib.request import urlretrieve\n",
    "# to parse URLs into components\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sklearn libraries\n",
    "\n",
    "# feature extraction and decomposition\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "# feature selection and reduction\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.decomposition import PCA\n",
    "# feature clustering\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# pipeline processing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# data splitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# classifier models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# regression models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# model evaluation\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report \n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make this notebook's output stable across runs\n",
    "SEED = 42\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure full display for dataframe content\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('precision', 5)\n",
    "pd.set_option('large_repr', 'truncate')\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "pd.set_option('colheader_justify', 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enable basic plots with pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# advanced plots settings\n",
    "sns.set(style='darkgrid')\n",
    "sns.set(font_scale=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify file names and locations\n",
    "URL_DROP_DOMAIN    = 'https://www.dropbox.com'  # data is stored on dropbox due to size limitations of GitHub\n",
    "URL_DROP_PATH      = '/s/89uv5kntgiolkno/the-movies-dataset.zip?dl=1'\n",
    "\n",
    "URL_GIT_DOMAIN    = 'https://raw.githubusercontent.com'  # GitHub domain\n",
    "URL_GIT_PROJECT_PATH      = '/itayse10/GoingToMovies/master'  # GitHub project path\n",
    "\n",
    "PROJECT_LOCAL_ROOT_DIR = 'movies'\n",
    "PROJECT_LOCAL_DATA_DIR  = os.path.join(PROJECT_LOCAL_ROOT_DIR,'datasets')\n",
    "PROJECT_LOCAL_RESOURCE_DIR  = os.path.join(PROJECT_LOCAL_ROOT_DIR,'resources')\n",
    "PROJECT_LOCAL_CHECKPOINT_DIR  = os.path.join(PROJECT_LOCAL_ROOT_DIR,'checkpoints')\n",
    "\n",
    "PROJECT_OUTPUT_DIR = '/content/movies/output'\n",
    "PROJECT_FILE       = 'the-movies-dataset.zip'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data retrieval and storage functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function: download files from the internet and optionally unzip them\n",
    "def fetch_data(url, file, local_path, zip=False):\n",
    "    if not os.path.isdir(local_path):\n",
    "        os.makedirs(local_path)\n",
    "    \n",
    "    remote_file = url\n",
    "    local_file  = os.path.join(local_path, file)\n",
    "   \n",
    "    print(remote_file)\n",
    "    \n",
    "    if not os.path.isfile(local_file):\n",
    "        print('Downloading ' + file + '...')\n",
    "        \n",
    "        download_from_Web(remote_file, local_file)\n",
    "\n",
    "        print('Download complete.')\n",
    "        \n",
    "    else:\n",
    "        print('Already downloaded.')\n",
    "\n",
    "    if zip:\n",
    "       unzip_file(local_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip a file\n",
    "def unzip_file(file):\n",
    " \n",
    "    zip_path = file[:-4]\n",
    "  \n",
    "    if (os.path.isdir(zip_path)):\n",
    "        print('Already extracted.')\n",
    "    else:\n",
    "        print('Extracting...')\n",
    "        zfile = ZipFile(file, 'r')\n",
    "        print(zfile.infolist())\n",
    "        zfile.extractall(zip_path)\n",
    "        zfile.close()\n",
    "        print('Extraction complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download an entire file from a public Web site\n",
    "def download_from_Web(remote_file, local_file):\n",
    "    urlretrieve(remote_file, local_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save a checkpoint for a dataset locally\n",
    "def save_checkpoint(df, df_name, checkpoint_identifier):\n",
    "    current_checkpoint = 'checkpoint_' + checkpoint_identifier\n",
    "    directory_path = os.path.join(PROJECT_LOCAL_CHECKPOINT_DIR,current_checkpoint)\n",
    "    if not os.path.isdir(directory_path):\n",
    "        os.makedirs(directory_path)\n",
    "        print('Creating new directory: {}'.format(directory_path))\n",
    "    target_file = df_name + '.csv'\n",
    "    file_path = os.path.join(directory_path, target_file)\n",
    "    df.to_csv(file_path, encoding='utf-8', index=False )\n",
    "    print('File {} saved in {}'.format(target_file, directory_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore a checkpoint into a dataframe object\n",
    "def restore_checkpoint(df_name,checkpoint_identifier):\n",
    "    current_checkpoint = 'checkpoint_' + checkpoint_identifier\n",
    "    directory_path = os.path.join(PROJECT_LOCAL_CHECKPOINT_DIR,current_checkpoint)\n",
    "    if not os.path.isdir(directory_path):\n",
    "        print('Directory for checkpoint does not exist: {}'.format(directory_path))\n",
    "        exit()\n",
    "    target_file = df_name + '.csv'\n",
    "    file_path = os.path.join(directory_path, target_file)\n",
    "    if not os.path.isfile(file_path):\n",
    "        print('File for checkpoint does not exist: {}'.format(file_path))\n",
    "        exit()\n",
    "    df = pd.read_csv(file_path,   encoding='utf-8'   )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data retrieval - load the data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the dataset file\n",
    "url = URL_DROP_DOMAIN + URL_DROP_PATH\n",
    "fetch_data(url, PROJECT_FILE, PROJECT_LOCAL_DATA_DIR, zip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create initial data frames\n",
    "Create dataframes for each of the spreadsheets.\n",
    "\n",
    "As part of loading the dataframes, convert null values to NaN on the fly (via pd.read_csv).\n",
    "\n",
    "By default the following values are interpreted as NaN: ‘’, ‘#N/A’, ‘#N/A N/A’, ‘#NA’, ‘-1.#IND’, ‘-1.#QNAN’, ‘-NaN’, ‘-nan’, ‘1.#IND’, ‘1.#QNAN’, ‘N/A’, ‘NA’, ‘NULL’, ‘NaN’, ‘n/a’, ‘nan’, ‘null’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the dataframes (and convert null fields on the fly)\n",
    "zip_path = os.path.join(PROJECT_LOCAL_DATA_DIR, PROJECT_FILE[:-4])\n",
    "\n",
    "metadata_file = os.path.join(zip_path, 'movies_metadata.csv')\n",
    "credits_file  = os.path.join(zip_path, 'credits.csv')\n",
    "plot_file     = os.path.join(zip_path, 'keywords.csv')\n",
    "\n",
    "# load the metadata dataframe\n",
    "metadata = pd.read_csv(metadata_file,\n",
    "                     dtype = 'unicode',\n",
    "                     na_values = ['no info', '.']\n",
    "                    )\n",
    "\n",
    "# load the credits dataframe\n",
    "credits = pd.read_csv(credits_file,\n",
    "                      dtype = 'unicode',\n",
    "                      na_values = ['no info', '.']\n",
    "                     )\n",
    "\n",
    "# load the plot dataframe\n",
    "plot =  pd.read_csv(plot_file,\n",
    "                    dtype = 'unicode',\n",
    "                    na_values = ['no info', '.']\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make copies of data for EDA\n",
    "metadata_copy = metadata.copy()\n",
    "metadata_copy.name = 'metadata'\n",
    "\n",
    "credits_copy = credits.copy()\n",
    "credits_copy.name = 'credit'\n",
    "\n",
    "plot_copy = plot.copy()\n",
    "plot_copy.name = 'plot'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data exploration functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic schema analysis\n",
    "def quick_schema_analysis(df):\n",
    "    if not hasattr(df, 'name'):\n",
    "        df.name = '' # set an empty name\n",
    "    print(\"Basic Schema Analysis for dataframe=\" + df.name)\n",
    "    print(\"************************************************\")\n",
    "    \n",
    "    print(\"Rows and Columns:\")\n",
    "    print(df.shape)\n",
    "    print(df.info())\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    print(\"Null Values - percentage:\")\n",
    "    print((1 - df.count()/len(df.index)) * 100)\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    print(\"Null Values - count:\")\n",
    "    print(df.isnull().sum())\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic data analysis\n",
    "def quick_data_analysis(df):\n",
    "    if not hasattr(df, 'name'):\n",
    "        df.name = '' # set an empty name\n",
    "    print(\"Basic Data Analysis for dataframe=\" + df.name)\n",
    "    print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review column results\n",
    "def assess_columns(df, columns, categories=False):\n",
    "    for column in columns:\n",
    "        print('Info for column: {}'.format(column))\n",
    "        num_empty = df[column].isnull().sum()\n",
    "        print('Number of null entries: {}'.format(num_empty))\n",
    "        if categories:\n",
    "            num_unique = df[column].unique()\n",
    "            print('Unique values: {}'.format(num_unique))\n",
    "    print(df[columns].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the \"metadata\" data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Potential features\n",
    "\n",
    "* __adult__: Indicates if the movie is X-Rated or Adult.\n",
    "* __belongs_to_collection__: A stringified dictionary that gives information on the movie series the particular film belongs to.\n",
    "* __budget__: The budget of the movie in dollars.\n",
    "* __genres__: A stringified list of dictionaries that list out all the genres associated with the movie.\n",
    "* __homepage__: The Official Homepage of the move.\n",
    "* __id__: The ID of the movie.\n",
    "* __imdb_id__: The IMDB ID of the movie.\n",
    "* __original_language__: The language in which the movie was originally shot in.\n",
    "* __original_title__: The original title of the movie.\n",
    "* __overview__: A brief blurb of the movie.\n",
    "* __popularity__: The Popularity Score assigned by TMDB.\n",
    "* __poster_path__: The URL of the poster image.\n",
    "* __production_companies__: A stringified list of production companies involved with the making of the movie.\n",
    "* __production_countries__: A stringified list of countries where the movie was shot/produced in.\n",
    "* __release_date__: Theatrical Release Date of the movie.\n",
    "* __revenue__: The total revenue of the movie in dollars.\n",
    "* __runtime__: The runtime of the movie in minutes.\n",
    "* __spoken_languages__: A stringified list of spoken languages in the film.\n",
    "* __status__: The status of the movie (Released, To Be Released, Announced, etc.)\n",
    "* __tagline__: The tagline of the movie.\n",
    "* __title__: The Official Title of the movie.\n",
    "* __video__: Indicates if there is a video present of the movie with TMDB.\n",
    "* __vote_average__: The average rating of the movie.\n",
    "* __vote_count__: The number of votes by users, as counted by TMDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick review of the metadata data\n",
    "quick_schema_analysis(metadata_copy)\n",
    "quick_data_analysis(metadata_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the first 10 rows\n",
    "metadata_copy.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional column info - counts, unique values, etc\n",
    "metadata_copy.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assess columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assess_columns(metadata_copy, ['release_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assess_columns(metadata_copy, ['budget','revenue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# asses json columns\n",
    "assess_columns(metadata_copy, ['belongs_to_collection','genres','production_companies','production_countries','spoken_languages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assess numerical columns\n",
    "assess_columns(metadata_copy, ['runtime','vote_average','vote_count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the \"credits\" data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick review of the credits data\n",
    "quick_schema_analysis(credits_copy)\n",
    "quick_data_analysis(credits_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the first 10 rows\n",
    "credits_copy.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assess columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assess_columns(credits_copy, ['cast', 'crew'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the \"plot\" data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick review of the plot data\n",
    "quick_schema_analysis(plot_copy)\n",
    "quick_data_analysis(plot_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the first 10 rows\n",
    "plot_copy.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assess columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assess_columns(plot_copy,['keywords'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge the 3 raw data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the shapes of all the dataframes\n",
    "print(metadata.shape)\n",
    "print(credits.shape)\n",
    "print(plot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the merged dataframe \"movies\"\n",
    "movies = metadata.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the other data frames\n",
    "movies = movies.merge(credits, on=[\"id\"])\n",
    "movies = movies.merge(plot, on=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the new data shape\n",
    "print(movies.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore the movies data\n",
    "movies.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data checkpoint - checkpoint_1\n",
    "Seperate data sets at their raw state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save checkpoint of the dataframes\n",
    "save_checkpoint(metadata, 'metadata', '1')\n",
    "save_checkpoint(credits, 'credits', '1')\n",
    "save_checkpoint(plot, 'plot', '1')\n",
    "save_checkpoint(movies, 'movies', '1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore data into datasets - in case you need to cotinue the code from this point (disable previous cell)\n",
    "# metadata = restore_checkpoint('metadata','1')\n",
    "# credits = restore_checkpoint('credits','1')\n",
    "# plot = restore_checkpoint('plot','1')\n",
    "# movies = restore_checkpoint('movies','1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data conversion functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert json to abstract syntax trees (ast)\n",
    "# use ast because json data has single quotes in the csvs\n",
    "# which is invalid for a json object (should be double quotes)\n",
    "def convert_json_to_ast(df, json_columns):\n",
    "    for column in json_columns:\n",
    "        df[column] = df[column].apply(lambda x: np.nan if pd.isnull(x)\n",
    "                                                else ast.literal_eval(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the columns that contain the dictionary field with the name value in its ast \n",
    "def get_dict_val_from_ast(df,columns,field_name, fillna_str):\n",
    "    for column in columns:\n",
    "        df[column] = df[column].fillna(fillna_str) # first replace NaN with fillna_str\n",
    "        df[column] = df[column].apply(lambda x: x[field_name] if isinstance(x, dict) else [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the columns that contain the list field with the name value in its ast\n",
    "def get_list_val_from_ast(df,columns,field_name, fillna_str=None, new_col_dict=None):\n",
    "    for column in columns:\n",
    "        if(fillna_str):\n",
    "            df[column] = df[column].fillna(fillna_str) # first replace NaN with fillna_str\n",
    "        new_column = column\n",
    "        if(new_col_dict and column in new_col_dict):\n",
    "            new_column = new_col_dict[column]\n",
    "        df[new_column] = df[column].apply(lambda x: [i[field_name] for i in x] if isinstance(x, list) else []) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to float\n",
    "def cast_to_float(df, columns,d_cast=None):\n",
    "    for column in columns:\n",
    "        if(d_cast):\n",
    "            df[column] = pd.to_numeric(df[column],errors='coerce',downcast=d_cast)\n",
    "        else:\n",
    "            df[column] = pd.to_numeric(df[column],errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data conversions \n",
    "Perform the following type conversions:\n",
    "* Convert __release_date__ to datetime\n",
    "* Convert __budget__ and __revenue__ to numerics\n",
    "* Convert __runtime__ to float\n",
    "* Convert __vote_average__ to float\n",
    "* Convert __vote_count__ to integer\n",
    "* Convert all JSON fields to abstract syntax trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert movies columns to numeric\n",
    "def data_convert(movies_df):\n",
    "    if 'release_date' in movies_df.columns:\n",
    "        movies_df['release_date'] = pd.to_datetime(movies_df['release_date'], errors='coerce')\n",
    "    if 'budget' in movies_df.columns:\n",
    "        movies_df['budget']  = pd.to_numeric(movies_df['budget'],  errors='coerce')\n",
    "        movies_df['budget']  = movies_df['budget'].replace(0, np.nan)\n",
    "    if 'revenue' in movies_df.columns:\n",
    "        movies_df['revenue']  = pd.to_numeric(movies_df['revenue'],  errors='coerce')\n",
    "        movies_df['revenue']  = movies_df['revenue'].replace(0, np.nan)\n",
    "    if 'runtime' in movies_df.columns:\n",
    "        cast_to_float(movies_df,['runtime'])\n",
    "    if 'vote_average' in movies_df.columns:\n",
    "        cast_to_float(movies_df,['vote_average'])\n",
    "    if 'vote_count' in movies_df.columns:\n",
    "        cast_to_float(movies_df,['vote_count'])\n",
    "    if 'popularity' in movies_df.columns:\n",
    "        cast_to_float(movies_df,['popularity'])\n",
    "  \n",
    "    return movies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = data_convert(movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__json columns__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert json columns to abstract syntax trees\n",
    "json_columns = ['belongs_to_collection',\n",
    "                'genres',\n",
    "                'production_companies',\n",
    "                'production_countries',\n",
    "                'spoken_languages',\n",
    "                'cast',\n",
    "                'crew',\n",
    "                'keywords']\n",
    "\n",
    "convert_json_to_ast(movies, json_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the columns that contain the dictionary field with the name value\n",
    "get_dict_val_from_ast(movies, ['belongs_to_collection'],'name','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the columns that contain the list field with the name value\n",
    "get_list_val_from_ast(movies, ['genres','spoken_languages'],'name','Other')\n",
    "get_list_val_from_ast(movies, ['production_companies','keywords'],'name','')\n",
    "get_list_val_from_ast(movies, ['production_countries'],'iso_3166_1','Other')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data checkpoint - checkpoint_2\n",
    "Afer data conversion, before cleaning up empty values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_checkpoint(movies, 'movies', '2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a name\n",
    "movies.name = 'movies'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case it's needed - restore the checkpoint\n",
    "# movies = restore_checkpoint('movies','2')\n",
    "# movies = data_convert(movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle empty values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__revenue__\n",
    "* As revenue is the target value in the model, we have to clear all rows with empty revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check shape before\n",
    "print(movies.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove empty target values\n",
    "movies = movies[movies['revenue'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check shape after\n",
    "print(movies.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running a quick schema and data analysis after reducing empty revenue items:\n",
    "quick_schema_analysis(movies)\n",
    "quick_data_analysis(movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__budget, runtime__  - replace nan with mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['budget'].fillna((movies['budget'].mean()), inplace=True)\n",
    "movies['runtime'].fillna((movies['runtime'].mean()), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__homepage, overview, poster_path, status, tagline__ - replace nan with empty string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['homepage'].fillna('',inplace=True)\n",
    "movies['overview'].fillna('',inplace=True)\n",
    "movies['poster_path'].fillna('',inplace=True)\n",
    "movies['status'].fillna('',inplace=True)\n",
    "movies['tagline'].fillna('',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine distribution and correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the collection of numeric columns\n",
    "num_columns = ['budget','popularity','runtime','vote_average','vote_count','revenue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot histograms\n",
    "movies[num_columns].hist(bins=50, figsize=(11,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine correlaiton of numerical columns\n",
    "scatter_matrix(movies[num_columns], figsize=(15, 15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*__TO_REVIEW__* \n",
    "* outlier detection and removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data checkpoint - checkpoint_3\n",
    "Before removing unnecessary features and adding new features to movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_checkpoint(movies, 'movies', '3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case it's needed - restore the checkpoint\n",
    "# movies = restore_checkpoint('movies','3')\n",
    "# movies = data_convert(movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature removal\n",
    "Drop features that don't provide any added value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.drop(columns = 'poster_path',inplace=True) # textual column with low added value\n",
    "movies.drop(columns = 'imdb_id',inplace=True) # not used in this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assess categorial columns\n",
    "assess_columns(movies,['adult','video'],True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop video and adult as their distinct value is False\n",
    "movies.drop(columns = ['adult','video'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# case for dropping original_title\n",
    "compare = ['title', 'original_title']\n",
    "movies[movies['original_title'] != movies['title']][['title', 'original_title']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop original_title (it appears to be the untranslated version of the title)\n",
    "movies.drop(columns='original_title',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New feature - actors (from cast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create actors columns based on cast\n",
    "get_list_val_from_ast(df=movies, columns=['cast'],field_name='name',new_col_dict = {'cast' : 'actors'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assess_columns(movies, ['actors'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New feature - director (from crew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the director from the crew field\n",
    "def get_director(x):\n",
    "    for i in x:\n",
    "        if i['job'] == 'Director':\n",
    "            return i['name']\n",
    "    return 'Unknown'\n",
    "  \n",
    "movies['director'] = movies['crew'].apply(get_director)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assess_columns(movies, ['director'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New features - cast_size and crew_size (from cast and crew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['cast_size'] = movies['cast'].apply(lambda x: len(x))\n",
    "movies['crew_size'] = movies['crew'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assess_columns(movies, ['cast_size','crew_size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New feature - franchise (from belongs_to_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['franchise'] = (movies['belongs_to_collection']\n",
    "                       .apply(lambda x: len(x)>0)\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assess_columns(movies, ['franchise'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New features - season and release_year (from release_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the season of the release (spring, summer, fall, winter)\n",
    "def season_of_date(date):\n",
    "    if pd.isnull(date):\n",
    "        return 'unknown'\n",
    "    year = str(date.year)\n",
    "    seasons = {'spring': pd.date_range(start='21/03/'+year, end='20/06/'+year),\n",
    "               'summer': pd.date_range(start='21/06/'+year, end='22/09/'+year),\n",
    "               'autumn': pd.date_range(start='23/09/'+year, end='20/12/'+year)}\n",
    "    if date in seasons['spring']:\n",
    "        return 'spring'\n",
    "    if date in seasons['summer']:\n",
    "        return 'summer'\n",
    "    if date in seasons['autumn']:\n",
    "        return 'autumn'\n",
    "    else:\n",
    "        return 'winter'\n",
    "\n",
    "# create a new column    \n",
    "movies['season'] = (movies['release_date']\n",
    "                          .fillna(pd.NaT)\n",
    "                          .apply(lambda x: season_of_date(x))\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the year the movie was released\n",
    "def year_of_date(date):\n",
    "    if pd.isnull(date):\n",
    "      return -1\n",
    "    year = date.year\n",
    "    return year\n",
    "\n",
    "# create a new column    \n",
    "movies['release_year'] = (movies['release_date']\n",
    "                          .fillna(pd.NaT)\n",
    "                          .apply(lambda x: year_of_date(x))\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assess_columns(movies, ['season','release_year'],True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New feature -  home_pagedomain (from homepage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get domain from url\n",
    "def get_url_domain(url):\n",
    "    if(not pd.isnull(url)):\n",
    "        parsed_uri = urlparse(url )\n",
    "        return '{uri.netloc}'.format(uri=parsed_uri)\n",
    "    else:\n",
    "        return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the domain from the homepage url\n",
    "movies['homepage_domain'] = movies['homepage'].apply(get_url_domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assess_columns(movies, ['homepage_domain'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New feature - weighted_rating (from vote_average and vote_count)\n",
    "Weighted Rating (WR) = (vv+m.R)+(mv+m.C)(vv+m.R)+(mv+m.C) where,\n",
    "\n",
    "v is the number of votes for the movie\n",
    "m is the minimum votes required to be listed in the chart\n",
    "R is the average rating of the movie C is the mean vote across the whole report.\n",
    "Source: https://www.kaggle.com/rounakbanik/movie-recommender-systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a weighted rating feature\n",
    "vote_averages = (movies[movies['vote_average']\n",
    "                 .notnull()]['vote_average'].astype('int')\n",
    "                )\n",
    "\n",
    "vote_counts = (movies[movies['vote_count']\n",
    "               .notnull()]['vote_count'].astype('int')\n",
    "              )\n",
    "\n",
    "C = vote_averages.mean()\n",
    "m = vote_counts.quantile(0.75)\n",
    "\n",
    "def weighted_rating(x):\n",
    "    v = x['vote_count']+1\n",
    "    R = x['vote_average']\n",
    "    return (v/(v+m) * R) + (m/(m+v) * C)\n",
    "\n",
    "movies['weighted_rating'] = movies.apply(weighted_rating, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assess_columns(movies, ['weighted_rating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New feature - revenue_to_budget_ratio (from revenue and budget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this new feature can indicate \"success\" or \"failure\"\n",
    "# (depending on whether ration is < 0 or > 0)\n",
    "movies['revenue_to_budget_ratio'] = movies['revenue'] / movies['budget']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assess_columns(movies, ['revenue_to_budget_ratio'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop columns that are no longer needed\n",
    "Drop columns that were already engineered to generate other columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop additional columns\n",
    "movies.drop(columns = 'homepage',inplace=True)  #replaced by homepage_domain\n",
    "movies.drop(columns = 'cast',inplace=True)  # parsed into actors\n",
    "movies.drop(columns = 'crew',inplace=True)  # partially expressed in director feature\n",
    "movies.drop(columns = 'release_date',inplace=True)  # can be replaced with season and release_year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine distribution and correlations - of new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the collection of new numeric columns\n",
    "new_num_columns = ['cast_size','crew_size','release_year','weighted_rating','revenue_to_budget_ratio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot histograms\n",
    "movies[new_num_columns].hist(bins=50, figsize=(11,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine correlaiton of numerical columns\n",
    "if not 'revenue' in new_num_columns:\n",
    "    new_num_columns.append('revenue')\n",
    "scatter_matrix(movies[new_num_columns], figsize=(15, 15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove columns that don't have any correlation with revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns that are not correlated with revenue\n",
    "movies.drop(columns = ['revenue_to_budget_ratio','release_year'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Asses movies data set to apply final data cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.name = 'movies'\n",
    "quick_schema_analysis(movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data checkpoint - checkpoint_4\n",
    "After feature engineering and some feature removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_checkpoint(movies, 'movies', '4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case it's needed - restore the checkpoint\n",
    "# movies = restore_checkpoint('movies','4')\n",
    "# movies = data_convert(movies)\n",
    "# movies['overview'].fillna('',inplace=True)\n",
    "# movies['status'].fillna('',inplace=True)\n",
    "# movies['tagline'].fillna('',inplace=True)\n",
    "# movies['homepage_domain'].fillna('',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.name = 'name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_schema_analysis(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a backup data set\n",
    "movies_new = movies.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = movies_new.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle textual and categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the stopwords file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify file names and locations\n",
    "stop_file_url = URL_GIT_DOMAIN + URL_GIT_PROJECT_PATH + '/stopwords.txt'\n",
    "\n",
    "fetch_data(stop_file_url, 'stopwords.txt', PROJECT_LOCAL_RESOURCE_DIR, zip=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load stop words file\n",
    "def get_stop_words(stop_file_path):\n",
    "    \"\"\"load stop words \"\"\"\n",
    "    \n",
    "    with open(stop_file_path, 'r', encoding=\"utf-8\") as f:\n",
    "        stopwords = f.readlines()\n",
    "        stop_set = set(m.strip() for m in stopwords)\n",
    "        return frozenset(stop_set)\n",
    "\n",
    "#load a set of stop words\n",
    "stopwords=get_stop_words(os.path.join(PROJECT_LOCAL_RESOURCE_DIR,'stopwords.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoded and vectorized feature reduction functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce the encoded features using a threshold\n",
    "def reduce_sparse_encoding(df,threshold):\n",
    "    headers_list = list(df.columns.values)\n",
    "    num_samples = df.shape[0]\n",
    "\n",
    "    for header in headers_list:\n",
    "        col_true_count = len(df[df[header] == 1])\n",
    "        if col_true_count/num_samples < threshold:\n",
    "            df = df.drop(header, axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce the weighted features using a threshold\n",
    "def reduce_sparse_weights(df,threshold):\n",
    "    headers_list = list(df.columns.values)\n",
    "\n",
    "    for header in headers_list:\n",
    "        col_weight_sum = df[header].sum()\n",
    "        if col_weight_sum < threshold:\n",
    "            df = df.drop(header, axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizing the titles - using word counts\n",
    "count_vectorizer = CountVectorizer(max_features=1000, binary=True, max_df=0.8,stop_words=stopwords) \n",
    "titles = movies[\"title\"] \n",
    "titles_transformed = count_vectorizer.fit_transform(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the vectorized titles\n",
    "idx_to_word = np.array(count_vectorizer.get_feature_names())\n",
    "print(idx_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_titles = ['title_' + title for title in idx_to_word]\n",
    "titles_df = pd.DataFrame(titles_transformed.toarray(),columns=title_titles)\n",
    "titles_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce the features using 0.1% of 1\n",
    "titles_df = reduce_sparse_encoding(titles_df,0.001)\n",
    "titles_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### belongs_to_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace empty lists with an empty string\n",
    "collections = [''.join(collection).lower().replace('collection','').replace('series','') \n",
    "               for collection in movies['belongs_to_collection'].values]\n",
    "# Vectorizing the collection names - using word counts\n",
    "count_vectorizer = CountVectorizer(max_features=100, stop_words=stopwords) \n",
    "collections_transformed = count_vectorizer.fit_transform(collections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the vectorized collections\n",
    "idx_to_word = np.array(count_vectorizer.get_feature_names())\n",
    "print(idx_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DataFrame\n",
    "collection_titles = ['coll_' + title for title in idx_to_word]\n",
    "collections_df = pd.DataFrame(collections_transformed.toarray(),columns=collection_titles)\n",
    "collections_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce the features using 0.1% of 1\n",
    "collections_df = reduce_sparse_encoding(collections_df,0.001)\n",
    "collections_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizing keywords - re-use the vectorizer used for collections\n",
    "keywords = [''.join(keyword).lower() \n",
    "               for keyword in movies['keywords'].values]\n",
    "\n",
    "# Vectorizing the keywords - using word counts\n",
    "count_vectorizer = CountVectorizer(max_features=100, stop_words=stopwords) \n",
    "keywords_transformed = count_vectorizer.fit_transform(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the vectorized keywords\n",
    "idx_to_word = np.array(count_vectorizer.get_feature_names())\n",
    "print(idx_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DataFrame\n",
    "keyword_titles = ['key_' + title for title in idx_to_word]\n",
    "keywords_df = pd.DataFrame(keywords_transformed.toarray(),columns=keyword_titles)\n",
    "keywords_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce the features using 0.1% of 1\n",
    "keywords_df = reduce_sparse_encoding(keywords_df,0.001)\n",
    "keywords_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tagline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizing tagline - using tf-idf weighted term-document matrix\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000, max_df=0.8,stop_words=stopwords) \n",
    "taglines = movies['tagline'].replace(np.nan,'')\n",
    "taglines_transformed = tfidf_vectorizer.fit_transform(taglines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the vectorized taglines\n",
    "idx_to_word = np.array(tfidf_vectorizer.get_feature_names())\n",
    "print(idx_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply NMF\n",
    "nmf = NMF(n_components=100, solver=\"mu\")\n",
    "taglines_nmf = nmf.fit_transform(taglines_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DataFrame for tagline\n",
    "tagline_titles = nmf.components_\n",
    "tagline_titles = ['tagline_' + '_'.join(idx_to_word[title.argsort()[-10:]]) for title in tagline_titles]\n",
    "tagline_df = pd.DataFrame(taglines_nmf,columns=tagline_titles)\n",
    "tagline_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce the features using sum weights of 1\n",
    "tagline_df = reduce_sparse_weights(tagline_df,1)\n",
    "tagline_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizing overview - using tf-idf weighted term-document matrix \n",
    "overviews = movies['overview'].replace(np.nan,'')\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000, max_df=0.8,stop_words=stopwords) \n",
    "overviews_transformed = tfidf_vectorizer.fit_transform(overviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the vectorized overviews\n",
    "idx_to_word = np.array(tfidf_vectorizer.get_feature_names())\n",
    "print(idx_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply NMF : re-use the nmf component \n",
    "overviews_nmf = nmf.fit_transform(overviews_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DataFrame for overview\n",
    "overview_titles = nmf.components_\n",
    "overview_titles = ['overview_' + '_'.join(idx_to_word[title.argsort()[-10:]]) for title in overview_titles]\n",
    "overview_df = pd.DataFrame(overviews_nmf,columns=overview_titles)\n",
    "overview_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce the features using sum weights of 1\n",
    "overview_df = reduce_sparse_weights(overview_df,1)\n",
    "overview_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### spoken_languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizing spoken languages - re-use the vectorizer used for collections\n",
    "count_vectorizer = CountVectorizer()\n",
    "spoken_laguages = [','.join(lang).lower() \n",
    "               for lang in movies['spoken_languages'].values]\n",
    "spoken_laguages_transformed = count_vectorizer.fit_transform(spoken_laguages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the vectorized spoken languages\n",
    "idx_to_word = np.array(count_vectorizer.get_feature_names())\n",
    "print(idx_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DataFrame\n",
    "spoken_languages_titles = ['s_lang_' + lang for lang in idx_to_word]\n",
    "spoken_languages_df = pd.DataFrame(spoken_laguages_transformed.toarray(),columns=spoken_languages_titles)\n",
    "spoken_languages_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce the features using 0.1% of 1\n",
    "spoken_languages_df = reduce_sparse_encoding(spoken_languages_df,0.001)\n",
    "spoken_languages_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### original_language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizing original language - re-use the vectorizer used for collections\n",
    "count_vectorizer = CountVectorizer()\n",
    "original_languages = movies['original_language'].replace(np.nan,'')\n",
    "original_languages_transformed = count_vectorizer.fit_transform(original_languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the vectorized original languages\n",
    "idx_to_word = np.array(count_vectorizer.get_feature_names())\n",
    "print(idx_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DataFrame\n",
    "original_languages_titles = ['o_lang_' + lang for lang in idx_to_word]\n",
    "original_languages_df = pd.DataFrame(original_languages_transformed.toarray(),columns=original_languages_titles)\n",
    "original_languages_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce the features using 0.1% of 1\n",
    "original_languages_df = reduce_sparse_encoding(original_languages_df,0.001)\n",
    "original_languages_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### homepage_domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizing original language - using ngram vectorizing (to select all 3 parts of the url)\n",
    "ngram_vectorizer = CountVectorizer(max_features=100, binary=True, max_df=0.8,stop_words=stopwords,ngram_range=(3, 3)) \n",
    "homepage_domains = movies['homepage_domain'].replace(np.nan,'')\n",
    "homepage_domains_transformed = ngram_vectorizer.fit_transform(homepage_domains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the vectorized original languages\n",
    "idx_to_word = np.array(ngram_vectorizer.get_feature_names())\n",
    "print(idx_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DataFrame\n",
    "homepage_domain_titles = ['home_'+ url.replace(' ','.') for url in idx_to_word]\n",
    "homepage_domains_df = pd.DataFrame(homepage_domains_transformed.toarray(),columns=homepage_domain_titles)\n",
    "homepage_domains_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce the features using 0.1% of 1\n",
    "homepage_domains_df = reduce_sparse_encoding(homepage_domains_df,0.001)\n",
    "homepage_domains_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data in the column\n",
    "genres = [','.join(gen) for gen in movies['genres'].values]\n",
    "\n",
    "# Vectorizing genres \n",
    "count_vectorizer = CountVectorizer()\n",
    "genres_transformed = count_vectorizer.fit_transform(genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the vectorized production genres\n",
    "idx_to_word = np.array(count_vectorizer.get_feature_names())\n",
    "print(idx_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set titles and define new DataFrame\n",
    "genre_titles = ['gen_' + gen for gen in idx_to_word]\n",
    "genres_df = pd.DataFrame(genres_transformed.toarray(),columns=genre_titles)\n",
    "genres_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce the features using 0.1% of 1\n",
    "genres_df = reduce_sparse_encoding(genres_df,0.001)\n",
    "genres_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### production_companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the data in the column\n",
    "production_companies = [','.join(prod).strip().replace(' ','_') \n",
    "               for prod in movies['production_companies'].values]\n",
    "\n",
    "# Vectorizing production companies \n",
    "count_vectorizer = CountVectorizer(max_features=1000)\n",
    "production_companies_transformed = count_vectorizer.fit_transform(production_companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the vectorized production companies\n",
    "idx_to_word = np.array(count_vectorizer.get_feature_names())\n",
    "print(idx_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set titles and define new DataFrame\n",
    "production_companies_titles = ['prod_' + prod for prod in idx_to_word]\n",
    "production_companies_df = pd.DataFrame(production_companies_transformed.toarray(),columns=production_companies_titles)\n",
    "production_companies_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce the features using 0.1% of 1\n",
    "production_companies_df = reduce_sparse_encoding(production_companies_df,0.001)\n",
    "production_companies_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### production_countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizing production countries \n",
    "count_vectorizer = CountVectorizer() \n",
    "production_countries = [','.join(country).lower() \n",
    "               for country in movies['production_countries'].values]\n",
    "production_countries_transformed = count_vectorizer.fit_transform(production_countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the vectorized production countries\n",
    "idx_to_word = np.array(count_vectorizer.get_feature_names())\n",
    "print(idx_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DataFrame\n",
    "production_countries_titles = ['country_' + country for country in idx_to_word]\n",
    "production_countries_df = pd.DataFrame(production_countries_transformed.toarray(),columns=production_countries_titles)\n",
    "production_countries_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce the features using 0.1% of 1\n",
    "production_countries_df = reduce_sparse_encoding(production_countries_df,0.001)\n",
    "production_countries_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### director"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the data in the column\n",
    "directors = [director.strip().replace(' ','_') \n",
    "               for director in movies['director'].values]\n",
    "\n",
    "# Vectorizing production companies\n",
    "count_vectorizer = CountVectorizer(max_features=100) \n",
    "directors_transformed = count_vectorizer.fit_transform(directors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the vectorized directors\n",
    "idx_to_word = np.array(count_vectorizer.get_feature_names())\n",
    "print(idx_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set titles and define new DataFrame\n",
    "director_titles = ['director_' + director for director in idx_to_word]\n",
    "directors_df = pd.DataFrame(directors_transformed.toarray(),columns=director_titles)\n",
    "directors_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce the features using 0.1% of 1\n",
    "directors_df = reduce_sparse_encoding(directors_df,0.001)\n",
    "directors_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the data in the column\n",
    "actors = [','.join(actor).strip().replace(' ','_') \n",
    "               for actor in movies['actors'].values]\n",
    "\n",
    "# Vectorizing actors\n",
    "count_vectorizer = CountVectorizer(max_features=1000) \n",
    "actors_transformed = count_vectorizer.fit_transform(actors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the vectorized actors\n",
    "idx_to_word = np.array(count_vectorizer.get_feature_names())\n",
    "print(idx_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set titles and define new DataFrame\n",
    "actor_titles = ['actor_' + actor for actor in idx_to_word]\n",
    "actors_df = pd.DataFrame(actors_transformed.toarray(),columns=actor_titles)\n",
    "actors_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce the features using 0.1% of 1\n",
    "actors_df = reduce_sparse_encoding(actors_df,0.001)\n",
    "actors_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### one-hot encoding for categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_df = pd.get_dummies(movies[['season']],prefix='season')\n",
    "season_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce the features using 0.1% of 1\n",
    "season_df = reduce_sparse_encoding(season_df,0.001)\n",
    "season_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_df = pd.get_dummies(movies[['status']],prefix='status')\n",
    "status_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce the features using 0.1% of 1\n",
    "status_df = reduce_sparse_encoding(status_df,0.001)\n",
    "status_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### franchise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "franchise_df = pd.get_dummies(movies[['franchise']],prefix='fran')\n",
    "franchise_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge encoded and vectorized sets into movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_columns = ['revenue','title', 'belongs_to_collection', 'keywords', 'tagline', 'overview', 'spoken_languages',\n",
    "                  'original_language', 'homepage_domain', 'genres', 'production_companies', 'production_countries', \n",
    "                  'director', 'actors', 'season', 'status', 'franchise']\n",
    "\n",
    "# create the final data set\n",
    "movies_final_arr = np.concatenate((movies[['revenue']].values,movies.drop(remove_columns,axis=1).values,\n",
    "                                 titles_df.values,collections_df.values,\n",
    "                                 keywords_df.values,tagline_df.values,overview_df.values,\n",
    "                                 spoken_languages_df.values,original_languages_df.values,\n",
    "                                 homepage_domains_df.values,genres_df.values,\n",
    "                                 production_companies_df.values,production_countries_df.values,\n",
    "                                 directors_df.values,actors_df.values,season_df.values,\n",
    "                                 status_df.values,franchise_df.values),  axis=1)\n",
    "\n",
    "# set column headers\n",
    "movies_headers_arr = np.concatenate((movies[['revenue']].columns.values,movies.drop(remove_columns,axis=1).columns.values,\n",
    "                                 titles_df.columns.values,collections_df.columns.values,\n",
    "                                 keywords_df.columns.values,tagline_df.columns.values,overview_df.columns.values,\n",
    "                                 spoken_languages_df.columns.values,original_languages_df.columns.values,\n",
    "                                 homepage_domains_df.columns.values,genres_df.columns.values,\n",
    "                                 production_companies_df.columns.values,production_countries_df.columns.values,\n",
    "                                 directors_df.columns.values,actors_df.columns.values,season_df.columns.values,\n",
    "                                 status_df.columns.values,franchise_df.columns.values))\n",
    "\n",
    "# create a DataFrame object\n",
    "movies_final = pd.DataFrame(movies_final_arr,columns=movies_headers_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the new schema\n",
    "quick_schema_analysis(movies_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign back to movies\n",
    "movies = movies_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data checkpoint - checkpoint_5\n",
    "After creating the full set of the features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_checkpoint(movies, 'movies', '5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case it's needed - restore the checkpoint\n",
    "# movies = restore_checkpoint('movies','5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selction and reduction - continued\n",
    "Once the full feature set has been assembled, we use feature selection and reduction algorithms to come up with a subset of the features\n",
    "\n",
    "The algorithms below is optimized for regression (specifically linear regression). Regardless, further algorithms we'll be used in the model creation section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define target value and features\n",
    "target = 'revenue'\n",
    "features = list(movies.columns)\n",
    "features = [f for f in features if f!=target]\n",
    "\n",
    "# create data \n",
    "feature_set = movies[features]\n",
    "target_set = movies[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add a new target variable for classification - revenue was over 2.5 times the budget\n",
    "target_new = np.ravel(target_set)/np.ravel(feature_set['budget'])>2.50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train and test sets\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(feature_set, target_set, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add a new target variable for classification \n",
    "# based on revenue to budget ratio (set to true if > 2.5)\n",
    "y_tr_cl, y_te_cl = train_test_split(target_new, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the score\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SelectKBest with chi square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the select K best model - using chi square\n",
    "select_best = SelectKBest(score_func=chi2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify the best hyper parameter\n",
    "k_arr = [20, 30, 40 ,50, 75, 100, 200]\n",
    "\n",
    "for k in k_arr:\n",
    "    select_best.k = k\n",
    "    select_best.fit(np.asarray(X_tr),np.asarray(y_tr, dtype=\"|S100\"))\n",
    "    X_tr_new = select_best.transform(X_tr)\n",
    "    X_te_new = select_best.transform(X_te)\n",
    "    print(\"\\n\")\n",
    "    print(\"Performance for k={}\".format(k))\n",
    "    print(\"Trainng set:\")\n",
    "    lin_scores = cross_val_score(LinearRegression(), X_tr_new, y_tr, scoring=\"neg_mean_squared_error\", cv=4)\n",
    "    lin_rmse_scores = np.sqrt(-lin_scores)\n",
    "    display_scores(lin_rmse_scores)\n",
    "    print(\"Test set:\")\n",
    "    lin_scores = cross_val_score(LinearRegression(), X_te_new, y_te, scoring=\"neg_mean_squared_error\", cv=4)\n",
    "    lin_rmse_scores = np.sqrt(-lin_scores)\n",
    "    display_scores(lin_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Conclusion:__ Best test results are for k=75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick the best : for k=75\n",
    "select_best.k = 75\n",
    "select_best.fit(np.asarray(X_tr),np.asarray(y_tr, dtype=\"|S100\"))\n",
    "X_tr = select_best.transform(X_tr)\n",
    "X_te = select_best.transform(X_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_tr)\n",
    "X_tr = scaler.transform(X_tr)\n",
    "X_te = scaler.transform(X_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature tuning pipeline (using linear regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression and pipeline (to evaluate feature selection and reduction)\n",
    "steps = [('regression',LinearRegression())]\n",
    "pipeline = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an instance of the Model\n",
    "pca = PCA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add to the steps collection\n",
    "pipeline.steps.insert(0,('pca',pca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV\n",
    "parameters = {}\n",
    "grid_search = GridSearchCV(pipeline,parameters, cv=4, scoring='neg_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add corresponding parameters\n",
    "grid_search.param_grid['pca__n_components'] = [0.9,0.91,0.92,0.93,0.94,0.95,0.96,0.97,0.98,0.99,0.999,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "grid_search.fit(X_tr,y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training scores\n",
    "print(\"Best pca parameter is {}\".format(grid_search.best_params_))\n",
    "lin_scores = grid_search.best_score_\n",
    "lin_rmse_scores = np.sqrt(-lin_scores)\n",
    "display_scores(lin_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run best model with test data\n",
    "grid_search_final = grid_search.best_estimator_ \n",
    "grid_search_final.fit(X_te,y_te)\n",
    "lin_scores = cross_val_score(grid_search_final, X_te, y_te, scoring=\"neg_mean_squared_error\", cv=4)\n",
    "lin_rmse_scores = np.sqrt(-lin_scores)\n",
    "display_scores(lin_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Conclusion__: PCA doesn't improve the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tidy up - remove the pca step from the pipeline\n",
    "del pipeline.steps[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering - K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans()\n",
    "\n",
    "# add to the steps collection\n",
    "pipeline.steps.insert(0,('kmeans',kmeans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV\n",
    "parameters = {}\n",
    "grid_search = GridSearchCV(pipeline,parameters, cv=4, scoring='neg_mean_squared_error')\n",
    "\n",
    "# add corresponding parameters\n",
    "grid_search.param_grid['kmeans__n_clusters'] = [2,4,6,8,10,15,20,30,40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "grid_search.fit(X_tr,y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training set scores\n",
    "print(\"Best k-means parameter is {}\".format(grid_search.best_params_))\n",
    "lin_scores = grid_search.best_score_\n",
    "lin_rmse_scores = np.sqrt(-lin_scores)\n",
    "display_scores(lin_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try with test data\n",
    "grid_search_final = grid_search.best_estimator_ \n",
    "grid_search_final.fit(X_te,y_te)\n",
    "lin_scores = cross_val_score(grid_search_final, X_te, y_te, scoring=\"neg_mean_squared_error\", cv=4)\n",
    "lin_rmse_scores = np.sqrt(-lin_scores)\n",
    "display_scores(lin_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Conclusion__: KMeans clustering doesn't improve the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reasons for considering a classification model in addition to the regression model.\n",
    "\n",
    "Box Office profits are a function of production budgets, ticket prices & Marketing/ Distribution costs based on their year of release.\n",
    "\n",
    "\n",
    "Hence, while evaluating historical values, profit calculations without accounting for inflation doesnt always provide the big picture (pun intended). A recommended option is arriving at a revenue to budget ratio (R/B), which offers better insights compared to revenue recognition alone. \n",
    "\n",
    "Further, this ratio is also useful in determining the relative success of a theatrical release. The total cost of movie production is not limited to production budgets but should take into account the distribution and marketing costs which is increasingly becoming important. Accordingly, movie producers and industry watchers now believe that a movie needs to make in excess of 2.5 times its production budget even to be considered a moderate success.\n",
    "\n",
    "Hence, the classifier feature matrix can drop the 'revenue' and 'revenue to budget ratio' as new unseen data ( data on movies that are yet to be released which we want to know whether will be a success or failure) will not have a revenue column. The attempt here is to predict film success using features like genre, production company, month/season of release, cast/crew size, country of production, whether part of a franchise, weighted rating etc. These are parameters that are already known before the movie's release."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg=LogisticRegression()\n",
    "params_logreg={'C':np.logspace(-5, 8, 15)}\n",
    "logreg_cv = GridSearchCV(logreg,params_logreg,cv=4)\n",
    "logreg_cv.fit(X_tr,y_tr_cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy: ',logreg_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest=RandomForestClassifier(random_state=42)\n",
    "params_forest = {'n_estimators': [3, 4, 6, 7, 10, 20, 50, 100]}\n",
    "forest_cv=GridSearchCV(forest, params_forest,cv=4)\n",
    "forest_cv.fit(X_tr,y_tr_cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy: ',forest_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn=KNeighborsClassifier()\n",
    "params_knn = {'n_neighbors': [3, 5, 10, 20]}\n",
    "knn_cv=GridSearchCV(knn, params_knn,cv=4,n_jobs=-1)\n",
    "knn_cv.fit(X_tr,y_tr_cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy:',knn_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier()\n",
    "params_tree = {\"criterion\": [\"gini\", \"entropy\"],\"min_samples_split\": [2, 10, 20],\"max_depth\": [None, 2, 5, 10],\n",
    "              \"min_samples_leaf\": [1, 5, 10],\"max_leaf_nodes\": [None, 5, 10, 20]\n",
    "              }\n",
    "tree_cv=GridSearchCV(tree, params_tree,cv=4,n_jobs=-1)\n",
    "tree_cv.fit(X_tr,y_tr_cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy:',tree_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoostClassifier with DecisionTree as base estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABC= AdaBoostClassifier(base_estimator=tree_cv.best_estimator_,n_estimators=100)\n",
    "np.mean(cross_val_score(ABC, X_tr, y_tr_cl, cv=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [('Logistic Regression', logreg_cv.best_estimator_),('K Nearest Neighbours', knn_cv.best_estimator_),\n",
    "               ('RandomForestClassifier', forest_cv.best_estimator_),('DecisionTreeClassifier',tree_cv.best_estimator_)]\n",
    "\n",
    "vc = VotingClassifier(estimators=classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy: ',np.mean(cross_val_score(vc, X_tr, y_tr_cl, cv=3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg=LinearRegression()\n",
    "lin_scores = cross_val_score(lin_reg,X_tr,y_tr, scoring=\"neg_mean_squared_error\", cv=4)\n",
    "lin_rmse_scores = np.sqrt(-lin_scores)\n",
    "display_scores(lin_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [{'alpha': [0.001,0.01,0.1,1,10,100,1000,1000]}]\n",
    "rr_cv = GridSearchCV(Ridge(), param_grid, cv=4, scoring='neg_mean_squared_error')\n",
    "rr_cv.fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sqrt(-rr_cv.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [{'alpha': [0.001,0.01,0.1,1,10,100,1000,1000]}]\n",
    "lr_cv = GridSearchCV(Lasso(), param_grid, cv=3, scoring='neg_mean_squared_error')\n",
    "lr_cv.fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sqrt(-lr_cv.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data set evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cl_model = logreg_cv.best_estimator_  \n",
    "y_pred_cl = final_cl_model.predict(X_te)\n",
    "\n",
    "print('Accuracy score: ',accuracy_score(y_te_cl,y_pred_cl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Logistic Regression has a train accuracy of __0.769__ and a test accuracy of __0.782__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_reg_model = lin_reg\n",
    "final_reg_model.fit(X_tr,y_tr)\n",
    "\n",
    "y_pred_reg = final_reg_model.predict(X_te)\n",
    "\n",
    "final_mse = mean_squared_error(y_te, y_pred_reg)\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "print(final_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hitmap for the confusion matrix\n",
    "def cm_heatmap(y_test,y_pred):\n",
    "    cm=confusion_matrix(y_test,y_pred)\n",
    "    conf_matrix=pd.DataFrame(data=cm,columns=['Predicted:0','Predicted:1'],index=['Actual:0','Actual:1'])\n",
    "    plt.figure(figsize = (8,5))\n",
    "    sns.heatmap(conf_matrix, annot=True,fmt='d',cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare different models\n",
    "def metrics_comp(y_te_cl,y_pred_cl,y_pred_forest):\n",
    "    metrics=pd.DataFrame(index=['Accuracy','Precision','Recall'],columns=['Logistic Regression','Random Forest'])\n",
    "    metrics.loc['Accuracy','Logistic Regression']=accuracy_score(y_te_cl,y_pred_cl)\n",
    "    metrics.loc['Precision','Logistic Regression']=precision_score(y_te_cl,y_pred_cl)\n",
    "    metrics.loc['Recall','Logistic Regression']=recall_score(y_te_cl,y_pred_cl)\n",
    "    metrics.loc['Accuracy','Random Forest']=accuracy_score(y_te_cl,y_pred_forest)\n",
    "    metrics.loc['Precision','Random Forest']=precision_score(y_te_cl,y_pred_forest)\n",
    "    metrics.loc['Recall','Random Forest']=recall_score(y_te_cl,y_pred_forest)\n",
    "    return(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precison-recall graph\n",
    "def p_r_threshold(thresholds,precision,recall):\n",
    "    fig,ax=plt.subplots(figsize=(8,5))\n",
    "    ax.plot(thresholds_logreg,precision_logreg[1:],label='Precision')\n",
    "    ax.plot(thresholds_logreg,recall_logreg[1:],label='Recall')\n",
    "    ax.set_xlabel('Classification threshold')\n",
    "    ax.set_ylabel('precision,Recall')\n",
    "    ax.set_title('Logistic Regression: Precison Recall')\n",
    "    ax.legend()\n",
    "    ax.grid();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best model - logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_heatmap(y_te_cl,y_pred_cl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC curve and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_te_cl, final_cl_model.predict_proba(X_te)[:,1])\n",
    "plt.plot(fpr,tpr)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.title('ROC curve for RandomForest classifier')\n",
    "plt.xlabel('False positive rate (1-Specificity)')\n",
    "plt.ylabel('Recall')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Area under the curve is \", roc_auc_score(y_te_cl,final_cl_model.predict_proba(X_te)[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluaiton of the 2nd best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data\n",
    "y_pred_forest = forest_cv.predict(X_te)\n",
    "print('Accuracy score: ',accuracy_score(y_te_cl,y_pred_forest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm_heatmap(y_te_cl,y_pred_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_te_cl, y_pred_forest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_te_cl, forest_cv.predict_proba(X_te)[:,1])\n",
    "plt.plot(fpr,tpr)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.title('ROC curve for RandomForest classifier')\n",
    "plt.xlabel('False positive rate (1-Specificity)')\n",
    "plt.ylabel('Recall')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Area under the curve is \", roc_auc_score(y_te_cl,forest_cv.predict_proba(X_te)[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparision of Accuracy, Precision and Recall between Logistic Regression and Random Forest classifiers\n",
    "In the case of movie box office prediction, a high recall translates to missing to identify a film that will be successful and high precision ensures the majority of positively predicted films will be successful.\n",
    "\n",
    "As the average cost involved in producing a major studio film is extremely high and the number of films produced by a production house is relatively low, it is important that the classifier's positive predictions are going to be successful. Failing that will result in huge loss for the production house. Hence a model that has high precision rather than high recall is preferred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare logistic regression and random forrest\n",
    "metrics_comp(y_te_cl,y_pred_cl,y_pred_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(8,6))\n",
    "metrics_comp(y_te_cl,y_pred_cl,y_pred_forest).plot(kind='bar',ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Conclusion__ :Accuracy levels are consistant between both models. However, Logistic regression has higher precision than Random forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tradeoff between precision and recall at different thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_logreg, recall_logreg, thresholds_logreg=precision_recall_curve(y_te_cl,final_cl_model.predict_proba(X_te)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_r_threshold(thresholds_logreg,precision_logreg,recall_logreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Conclusion__: At threshold 0.5 the recall is 0.4 with a very high precision (0.7). Moving the threshold to 0.6 results in a much higher precision (0.8) without a significant drop in recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
