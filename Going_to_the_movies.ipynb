{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Going to the movies.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/itayse10/GoingToMovies/blob/master/Going_to_the_movies.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Nlsdcf8pIo24",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Machine Learning 3253 - Project Assignment - \"Going to the Movies\""
      ]
    },
    {
      "metadata": {
        "id": "LQ9EDhLMIo26",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Team Members\n",
        "    \n",
        "* Craig Barbisan\n",
        "* Nisha Choondassery\n",
        "* Mark Hubbard\n",
        "* Itay Segal"
      ]
    },
    {
      "metadata": {
        "id": "5ImxIgKCIo27",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Project Overview\n",
        "\n",
        "Using the \"Movies Dataset\"  from Kaggle, this project will create an optimal model for predicting a movie's financial success.\n",
        "\n",
        "A set of features that would only be known *prior* to a movies release will be used.  A classifier for predicting success will be developed based on a revenue_to_budget ratio as the threshold.\n",
        "\n",
        "The feature set will be further assessed via an optimal regression algorithm to predict revenue, where a low RMSE will increase confidence in the feature engineering and feature selection for the classifier."
      ]
    },
    {
      "metadata": {
        "id": "2m2YsaRIIo27",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### The \"Movies Dataset\" from Kaggle\n",
        "The dataset for this project is originally sourced from https://www.kaggle.com/rounakbanik/the-movies-dataset.\n",
        "\n",
        "Credit: Rounak Banik\n",
        "\n",
        "This dataset is an ensemble of data collected from TMDB (\"The Movie DataBase) and GroupLens.\n",
        "* The Movie Details (i.e. Metadata), Credits and Keywords have been collected from the TMDB Open API.\n",
        "* The Movie Links and Ratings have been obtained from the Official GroupLens website.\n",
        "\n",
        "The following spreadsheets are used by this project (all from TMDB):\n",
        "\n",
        "* __movies_metadata.csv__: The main Movies Metadata file. Contains information on 45,000 movies featured in the Full MovieLens dataset. Features include posters, backdrops, budget, revenue, release dates, languages, production countries and companies.\n",
        "\n",
        "* __credits.csv__: Consists of Cast and Crew Information for all our movies. Available in the form of a stringified JSON Object.\n",
        "\n",
        "* __keywords.csv__:  Contains the movie plot keywords for our MovieLens movies. Available in the form of a stringified JSON Object."
      ]
    },
    {
      "metadata": {
        "id": "alNA0N2wc5tz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Project Video\n",
        "\n",
        "The following 10 minute video describes the project."
      ]
    },
    {
      "metadata": {
        "id": "Mg7FC1IKxCH5",
        "colab_type": "code",
        "colab": {},
        "cellView": "both"
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import YouTubeVideo\n",
        "\n",
        "YouTubeVideo('c1TbyxPeM4Y', width=600, height=400)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wew4PrsvIo28",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "### The Big Picture (Pun Intended)\n",
        "\n",
        "Profit is the primary measure of a movie's financial success.  \n",
        "\n",
        "The proposed machine learning solution for predicting success is by using a supervised learning classifier with a profit-oriented target and selecting a set of features known prior to a movie's release.\n",
        "\n",
        "Since profit itself is based on a specific currency, and doesn't account for inflation or increased marketing and distribution expenses over time or within a particular country, a better proxy that can be used in any geographic region which remains relatively constant over time and across movie genres is a revenue to budget ratio. A ratio of 2.5 will be used as the target for the classifier.\n",
        "\n",
        "A reasonable model should have a probability of predicting financial success that exceeds a simple coin toss (i.e. 50% probability).  Given that critical success (i.e. how the movie is received by the general viewing audience) is a big factor but less predictable, this project is aiming for a model with a 75% probability of predicting financial success based on the features known prior to creating the movie itself."
      ]
    },
    {
      "metadata": {
        "id": "oeFATEewIo29",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Notebook Contents\n",
        "\n",
        "This notebook will explore the data, evaluate some models and draw conclusions. It is divided into the following main sections:\n",
        "\n",
        "0. Setup the environment - seting up the notebook environment.\n",
        "1. Get the data - loading the data set into the notebook.\n",
        "2. Explore the data - exploring the raw movies data.\n",
        "3. Prepare the data - data cleansing, feature selection\\reduction\\engineering and standardization\n",
        "4. Model - training and testing various models.\n",
        "5. Evaluate the model - analyzing model results.\n",
        "6. Summary - summarizing the observations and conclusions."
      ]
    },
    {
      "metadata": {
        "id": "V-QNmJF5Io29",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 0. Setup the environment"
      ]
    },
    {
      "metadata": {
        "id": "Ma3QE54JIo2-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Initialize libraries"
      ]
    },
    {
      "metadata": {
        "id": "eUBdpGPYIo2_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import the basic libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "import ast\n",
        "import tarfile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vOO53i3WIo3C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# scatter matrix plotting\n",
        "from pandas.plotting import scatter_matrix\n",
        "\n",
        "# enable advanced plots\n",
        "import seaborn as sns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uN_0KKTdIo3E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# for reading and writing ZIP files\n",
        "from zipfile import ZipFile\n",
        "# to retrieve from a url\n",
        "from urllib.request import urlretrieve\n",
        "# to parse URLs into components\n",
        "from urllib.parse import urlparse"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6oAN53FQIo3H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import sklearn libraries\n",
        "\n",
        "# feature extraction and decomposition\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import NMF\n",
        "\n",
        "# feature selection and reduction\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.decomposition import PCA\n",
        "# feature clustering\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# pipeline processing\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import FeatureUnion\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "# data splitting\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# classifier models\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "# regression models\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import ElasticNet\n",
        "\n",
        "# model evaluation\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report \n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CM3SvBx7Io3J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Basic settings"
      ]
    },
    {
      "metadata": {
        "id": "ub2qvW1jIo3J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# make this notebook's output stable across runs\n",
        "SEED = 42\n",
        "np.random.seed(SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O0EtUAmlIo3L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ensure full display for dataframe content\n",
        "pd.set_option('display.max_rows', 100)\n",
        "pd.set_option('display.max_columns', 100)\n",
        "pd.set_option('precision', 5)\n",
        "pd.set_option('large_repr', 'truncate')\n",
        "pd.set_option('display.max_colwidth', -1)\n",
        "pd.set_option('colheader_justify', 'left')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vis77-s7Io3O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# enable basic plots with pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['axes.labelsize'] = 14\n",
        "plt.rcParams['xtick.labelsize'] = 12\n",
        "plt.rcParams['ytick.labelsize'] = 12"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MqZwi2E_Io3R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# advanced plots settings\n",
        "sns.set(style='darkgrid')\n",
        "sns.set(font_scale=1.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6c_oHboPIo3T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# suppress warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XNxhIYxNIo3W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Constants"
      ]
    },
    {
      "metadata": {
        "id": "pj5daBqpIo3W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# specify file names and locations\n",
        "URL_DROP_DOMAIN    = 'https://www.dropbox.com'  # data is stored on dropbox due to size limitations of GitHub\n",
        "URL_DROP_PATH      = '/s/89uv5kntgiolkno/the-movies-dataset.zip?dl=1'\n",
        "\n",
        "URL_GIT_DOMAIN    = 'https://raw.githubusercontent.com'  # GitHub domain\n",
        "URL_GIT_PROJECT_PATH      = '/itayse10/GoingToMovies/master'  # GitHub project path\n",
        "\n",
        "PROJECT_LOCAL_ROOT_DIR = 'movies'\n",
        "PROJECT_LOCAL_DATA_DIR  = os.path.join(PROJECT_LOCAL_ROOT_DIR,'datasets')\n",
        "PROJECT_LOCAL_RESOURCE_DIR  = os.path.join(PROJECT_LOCAL_ROOT_DIR,'resources')\n",
        "PROJECT_LOCAL_CHECKPOINT_DIR  = os.path.join(PROJECT_LOCAL_ROOT_DIR,'checkpoints')\n",
        "\n",
        "PROJECT_OUTPUT_DIR = '/content/movies/output'\n",
        "PROJECT_FILE       = 'the-movies-dataset.zip'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l6lsEiFYIo3a",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1. Get the data"
      ]
    },
    {
      "metadata": {
        "id": "peUwV52NIo3b",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Data retrieval and storage functions"
      ]
    },
    {
      "metadata": {
        "id": "eoQkBWDnIo3b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# function: download files from the internet and optionally unzip them\n",
        "def fetch_data(url, file, local_path, zip=False):\n",
        "    if not os.path.isdir(local_path):\n",
        "        os.makedirs(local_path)\n",
        "    \n",
        "    remote_file = url\n",
        "    local_file  = os.path.join(local_path, file)\n",
        "   \n",
        "    print(remote_file)\n",
        "    \n",
        "    if not os.path.isfile(local_file):\n",
        "        print('Downloading ' + file + '...')\n",
        "        \n",
        "        download_from_Web(remote_file, local_file)\n",
        "\n",
        "        print('Download complete.')\n",
        "        \n",
        "    else:\n",
        "        print('Already downloaded.')\n",
        "\n",
        "    if zip:\n",
        "       unzip_file(local_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2xqkZ62gIo3d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# unzip a file\n",
        "def unzip_file(file):\n",
        " \n",
        "    zip_path = file[:-4]\n",
        "  \n",
        "    if (os.path.isdir(zip_path)):\n",
        "        print('Already extracted.')\n",
        "    else:\n",
        "        print('Extracting...')\n",
        "        zfile = ZipFile(file, 'r')\n",
        "        print(zfile.infolist())\n",
        "        zfile.extractall(zip_path)\n",
        "        zfile.close()\n",
        "        print('Extraction complete.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XBkdXW57Io3e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# download an entire file from a public Web site\n",
        "def download_from_Web(remote_file, local_file):\n",
        "    urlretrieve(remote_file, local_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c69JXNtGIo3g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# save a checkpoint for a dataset locally\n",
        "def save_checkpoint(df, df_name, checkpoint_identifier):\n",
        "    current_checkpoint = 'checkpoint_' + checkpoint_identifier\n",
        "    directory_path = os.path.join(PROJECT_LOCAL_CHECKPOINT_DIR,current_checkpoint)\n",
        "    if not os.path.isdir(directory_path):\n",
        "        os.makedirs(directory_path)\n",
        "        print('Creating new directory: {}'.format(directory_path))\n",
        "    target_file = df_name + '.csv'\n",
        "    file_path = os.path.join(directory_path, target_file)\n",
        "    df.to_csv(file_path, encoding='utf-8', index=False )\n",
        "    print('File {} saved in {}'.format(target_file, directory_path))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n1NYqgKXIo3i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# restore a checkpoint into a dataframe object\n",
        "def restore_checkpoint(df_name,checkpoint_identifier):\n",
        "    current_checkpoint = 'checkpoint_' + checkpoint_identifier\n",
        "    directory_path = os.path.join(PROJECT_LOCAL_CHECKPOINT_DIR,current_checkpoint)\n",
        "    if not os.path.isdir(directory_path):\n",
        "        print('Directory for checkpoint does not exist: {}'.format(directory_path))\n",
        "        exit()\n",
        "    target_file = df_name + '.csv'\n",
        "    file_path = os.path.join(directory_path, target_file)\n",
        "    if not os.path.isfile(file_path):\n",
        "        print('File for checkpoint does not exist: {}'.format(file_path))\n",
        "        exit()\n",
        "    df = pd.read_csv(file_path,   encoding='utf-8'   )\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nQV7kiw-Io3k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Data retrieval - load the data sets"
      ]
    },
    {
      "metadata": {
        "id": "vyHSj890Io3l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# download the dataset file\n",
        "url = URL_DROP_DOMAIN + URL_DROP_PATH\n",
        "fetch_data(url, PROJECT_FILE, PROJECT_LOCAL_DATA_DIR, zip=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EwFlsDRPIo3o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Create initial data frames\n",
        "Create dataframes for each of the spreadsheets.\n",
        "\n",
        "As part of loading the dataframes, convert null values to NaN on the fly (via pd.read_csv).\n",
        "\n",
        "By default the following values are interpreted as NaN: ‘’, ‘#N/A’, ‘#N/A N/A’, ‘#NA’, ‘-1.#IND’, ‘-1.#QNAN’, ‘-NaN’, ‘-nan’, ‘1.#IND’, ‘1.#QNAN’, ‘N/A’, ‘NA’, ‘NULL’, ‘NaN’, ‘n/a’, ‘nan’, ‘null’."
      ]
    },
    {
      "metadata": {
        "id": "pe_aw0FTIo3p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# initialize the dataframes (and convert null fields on the fly)\n",
        "zip_path = os.path.join(PROJECT_LOCAL_DATA_DIR, PROJECT_FILE[:-4])\n",
        "\n",
        "metadata_file = os.path.join(zip_path, 'movies_metadata.csv')\n",
        "credits_file  = os.path.join(zip_path, 'credits.csv')\n",
        "plot_file     = os.path.join(zip_path, 'keywords.csv')\n",
        "\n",
        "# load the metadata dataframe\n",
        "metadata = pd.read_csv(metadata_file,\n",
        "                     dtype = 'unicode',\n",
        "                     na_values = ['no info', '.']\n",
        "                    )\n",
        "\n",
        "# load the credits dataframe\n",
        "credits = pd.read_csv(credits_file,\n",
        "                      dtype = 'unicode',\n",
        "                      na_values = ['no info', '.']\n",
        "                     )\n",
        "\n",
        "# load the plot dataframe\n",
        "plot =  pd.read_csv(plot_file,\n",
        "                    dtype = 'unicode',\n",
        "                    na_values = ['no info', '.']\n",
        "                   )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wqn2C_KNIo3r",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2. Explore the data"
      ]
    },
    {
      "metadata": {
        "id": "DtyA400HIo3r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# make copies of data for EDA\n",
        "metadata_copy = metadata.copy()\n",
        "metadata_copy.name = 'metadata'\n",
        "\n",
        "credits_copy = credits.copy()\n",
        "credits_copy.name = 'credit'\n",
        "\n",
        "plot_copy = plot.copy()\n",
        "plot_copy.name = 'plot'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YmphAykBIo3t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Data exploration functions"
      ]
    },
    {
      "metadata": {
        "id": "WjJVP6opIo3u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# basic schema analysis\n",
        "def quick_schema_analysis(df):\n",
        "    if not hasattr(df, 'name'):\n",
        "        df.name = '' # set an empty name\n",
        "    print(\"Basic Schema Analysis for dataframe=\" + df.name)\n",
        "    print(\"************************************************\")\n",
        "    \n",
        "    print(\"Rows and Columns:\")\n",
        "    print(df.shape)\n",
        "    print(df.info())\n",
        "    print(\"\\n\")\n",
        "    \n",
        "    print(\"Null Values - percentage:\")\n",
        "    print((1 - df.count()/len(df.index)) * 100)\n",
        "    print(\"\\n\")\n",
        "    \n",
        "    print(\"Null Values - count:\")\n",
        "    print(df.isnull().sum())\n",
        "    print(\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hi10wwA_Io3w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# basic data analysis\n",
        "def quick_data_analysis(df):\n",
        "    if not hasattr(df, 'name'):\n",
        "        df.name = '' # set an empty name\n",
        "    print(\"Basic Data Analysis for dataframe=\" + df.name)\n",
        "    print(df.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qj0HmfFDIo3y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# review column results\n",
        "def assess_columns(df, columns, categories=False):\n",
        "    for column in columns:\n",
        "        print('Info for column: {}'.format(column))\n",
        "        num_empty = df[column].isnull().sum()\n",
        "        print('Number of null entries: {}'.format(num_empty))\n",
        "        if categories:\n",
        "            num_unique = df[column].unique()\n",
        "            print('Unique values: {}'.format(num_unique))\n",
        "    print(df[columns].head(10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1anhzvEVBq-1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def count_values(df, column):\n",
        "    value_count = {}\n",
        "    for row in df[column].dropna():\n",
        "        if len(row) > 0:\n",
        "            for key in row:\n",
        "                if key in value_count:\n",
        "                    value_count[key] += 1\n",
        "                else:\n",
        "                    value_count[key] = 1\n",
        "        else:\n",
        "            pass\n",
        "    return value_count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q81C_nG5Io30",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Explore the \"metadata\" data"
      ]
    },
    {
      "metadata": {
        "id": "hObiyxufIo31",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Potential features\n",
        "\n",
        "* __adult__: Indicates if the movie is X-Rated or Adult.\n",
        "* __belongs_to_collection__: A stringified dictionary that gives information on the movie series the particular film belongs to.\n",
        "* __budget__: The budget of the movie in dollars.\n",
        "* __genres__: A stringified list of dictionaries that list out all the genres associated with the movie.\n",
        "* __homepage__: The Official Homepage of the move.\n",
        "* __id__: The ID of the movie.\n",
        "* __imdb_id__: The IMDB ID of the movie.\n",
        "* __original_language__: The language in which the movie was originally shot in.\n",
        "* __original_title__: The original title of the movie.\n",
        "* __overview__: A brief blurb of the movie.\n",
        "* __popularity__: The Popularity Score assigned by TMDB.\n",
        "* __poster_path__: The URL of the poster image.\n",
        "* __production_companies__: A stringified list of production companies involved with the making of the movie.\n",
        "* __production_countries__: A stringified list of countries where the movie was shot/produced in.\n",
        "* __release_date__: Theatrical Release Date of the movie.\n",
        "* __revenue__: The total revenue of the movie in dollars.\n",
        "* __runtime__: The runtime of the movie in minutes.\n",
        "* __spoken_languages__: A stringified list of spoken languages in the film.\n",
        "* __status__: The status of the movie (Released, To Be Released, Announced, etc.)\n",
        "* __tagline__: The tagline of the movie.\n",
        "* __title__: The Official Title of the movie.\n",
        "* __video__: Indicates if there is a video present of the movie with TMDB.\n",
        "* __vote_average__: The average rating of the movie.\n",
        "* __vote_count__: The number of votes by users, as counted by TMDB."
      ]
    },
    {
      "metadata": {
        "id": "bqtByhGYIo31",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# quick review of the metadata data\n",
        "quick_schema_analysis(metadata_copy)\n",
        "quick_data_analysis(metadata_copy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AFZiSNGdIo33",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# examine the first 10 rows\n",
        "metadata_copy.head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rvTvJnsCIo35",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# additional column info - counts, unique values, etc\n",
        "metadata_copy.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qfswFBQPIo37",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Assess columns"
      ]
    },
    {
      "metadata": {
        "id": "_ao4WckaIo38",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "assess_columns(metadata_copy, ['release_date'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3Yt50cE_Io3-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "assess_columns(metadata_copy, ['budget','revenue'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bQfYn6YGIo4A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# asses json columns\n",
        "assess_columns(metadata_copy, ['belongs_to_collection','genres','production_companies','production_countries','spoken_languages'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v_Z2gXmJIo4C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# assess numerical columns\n",
        "assess_columns(metadata_copy, ['runtime','vote_average','vote_count'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AJrVZD24Io4D",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Explore the \"credits\" data"
      ]
    },
    {
      "metadata": {
        "id": "sutUIDA0Io4F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# quick review of the credits data\n",
        "quick_schema_analysis(credits_copy)\n",
        "quick_data_analysis(credits_copy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y2PKrff8Io4H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# examine the first 10 rows\n",
        "credits_copy.head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FolhTdKGIo4K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Assess columns"
      ]
    },
    {
      "metadata": {
        "id": "xUUyI_1wIo4L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "assess_columns(credits_copy, ['cast', 'crew'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RraBjxW1Io4M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Explore the \"plot\" data"
      ]
    },
    {
      "metadata": {
        "id": "uV6ocC0QIo4N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# quick review of the plot data\n",
        "quick_schema_analysis(plot_copy)\n",
        "quick_data_analysis(plot_copy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yQLxCRgPIo4O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# examine the first 10 rows\n",
        "plot_copy.head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "endzvYJ1Io4P",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Assess columns"
      ]
    },
    {
      "metadata": {
        "id": "kpLzN3JvIo4Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "assess_columns(plot_copy,['keywords'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SHhzAenOIo4S",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3. Prepare the data"
      ]
    },
    {
      "metadata": {
        "id": "zgumsEEpIo4U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Merge the 3 raw data sets"
      ]
    },
    {
      "metadata": {
        "id": "uOBN1aDdIo4V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# compare the shapes of all the dataframes\n",
        "print(metadata.shape)\n",
        "print(credits.shape)\n",
        "print(plot.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0x2IaATOIo4W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# initialize the merged dataframe \"movies\"\n",
        "movies = metadata.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t-_ZZIDyIo4c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# merge the other data frames\n",
        "movies = movies.merge(credits, on=[\"id\"])\n",
        "movies = movies.merge(plot, on=['id'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5GFgLn34Io4d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# check the new data shape\n",
        "print(movies.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1nQWTzWgIo4f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# explore the movies data\n",
        "movies.head(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bFSDIc1kIo4i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Create data checkpoint - checkpoint_1\n",
        "Seperate data sets at their raw state"
      ]
    },
    {
      "metadata": {
        "id": "U5f0KzVzIo4j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# save checkpoint of the dataframes\n",
        "save_checkpoint(metadata, 'metadata', '1')\n",
        "save_checkpoint(credits, 'credits', '1')\n",
        "save_checkpoint(plot, 'plot', '1')\n",
        "save_checkpoint(movies, 'movies', '1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f9EMvut4Io4k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create a checkpoint for the movies data set\n",
        "movies.name = 'movies_checkpoint_1'\n",
        "movies_checkpoint_1 = movies.copy()\n",
        "#movies=movies_checkpoint_1.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8_ESBjKhE1UC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "movies_checkpoint_1.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "66B38GYpIo4n",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Data conversion functions"
      ]
    },
    {
      "metadata": {
        "id": "v3uj4XGvIo4n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# convert json to abstract syntax trees (ast)\n",
        "# use ast because json data has single quotes in the csvs\n",
        "# which is invalid for a json object (should be double quotes)\n",
        "def convert_json_to_ast(df, json_columns):\n",
        "    for column in json_columns:\n",
        "        df[column] = df[column].apply(lambda x: np.nan if pd.isnull(x)\n",
        "                                                else ast.literal_eval(str(x)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7LUpgF_CIo4p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# convert the columns that contain the dictionary field with the name value in its ast \n",
        "def get_dict_val_from_ast(df,columns,field_name, fillna_str):\n",
        "    for column in columns:\n",
        "        df[column] = df[column].fillna(fillna_str) # first replace NaN with fillna_str\n",
        "        df[column] = df[column].apply(lambda x: x[field_name] if isinstance(x, dict) else [])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wdJHQC7rIo4r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# convert the columns that contain the list field with the name value in its ast\n",
        "def get_list_val_from_ast(df,columns,field_name, fillna_str=None, new_col_dict=None):\n",
        "    for column in columns:\n",
        "        if(fillna_str):\n",
        "            df[column] = df[column].fillna(fillna_str) # first replace NaN with fillna_str\n",
        "        new_column = column\n",
        "        if(new_col_dict and column in new_col_dict):\n",
        "            new_column = new_col_dict[column]\n",
        "        df[new_column] = df[column].apply(lambda x: [i[field_name] for i in x] if isinstance(x, list) else []) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Fwh3l41vIo4s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# convert to float\n",
        "def cast_to_float(df, columns,d_cast=None):\n",
        "    for column in columns:\n",
        "        if(d_cast):\n",
        "            df[column] = pd.to_numeric(df[column],errors='coerce',downcast=d_cast)\n",
        "        else:\n",
        "            df[column] = pd.to_numeric(df[column],errors='coerce')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7_1KMRU9Io4t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Data conversions \n",
        "Perform the following type conversions:\n",
        "* Convert __release_date__ to datetime\n",
        "* Convert __budget__ and __revenue__ to numerics\n",
        "* Convert __runtime__ to float\n",
        "* Convert __vote_average__ to float\n",
        "* Convert __vote_count__ to integer\n",
        "* Convert all JSON fields to abstract syntax trees"
      ]
    },
    {
      "metadata": {
        "id": "8R_xYzkIIo4u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# convert movies columns to numeric\n",
        "def data_convert(movies_df):\n",
        "    if 'release_date' in movies_df.columns:\n",
        "        movies_df['release_date'] = pd.to_datetime(movies_df['release_date'], errors='coerce')\n",
        "    if 'budget' in movies_df.columns:\n",
        "        movies_df['budget']  = pd.to_numeric(movies_df['budget'],  errors='coerce')\n",
        "        movies_df['budget']  = movies_df['budget'].replace(0, np.nan)\n",
        "    if 'revenue' in movies_df.columns:\n",
        "        movies_df['revenue']  = pd.to_numeric(movies_df['revenue'],  errors='coerce')\n",
        "        movies_df['revenue']  = movies_df['revenue'].replace(0, np.nan)\n",
        "    if 'runtime' in movies_df.columns:\n",
        "        cast_to_float(movies_df,['runtime'])\n",
        "    if 'vote_average' in movies_df.columns:\n",
        "        cast_to_float(movies_df,['vote_average'])\n",
        "    if 'vote_count' in movies_df.columns:\n",
        "        cast_to_float(movies_df,['vote_count'])\n",
        "    if 'popularity' in movies_df.columns:\n",
        "        cast_to_float(movies_df,['popularity'])\n",
        "  \n",
        "    return movies_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S77Yv_crIo4v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "movies = data_convert(movies)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B3RCHH6YIo4w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "__json columns__"
      ]
    },
    {
      "metadata": {
        "id": "tAyFKO6gIo4w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# convert json columns to abstract syntax trees\n",
        "json_columns = ['belongs_to_collection',\n",
        "                'genres',\n",
        "                'production_companies',\n",
        "                'production_countries',\n",
        "                'spoken_languages',\n",
        "                'cast',\n",
        "                'crew',\n",
        "                'keywords']\n",
        "\n",
        "convert_json_to_ast(movies, json_columns)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q1_zpue7Io4x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# convert the columns that contain the dictionary field with the name value\n",
        "get_dict_val_from_ast(movies, ['belongs_to_collection'],'name','')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xHnA-cNWIo4z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# convert the columns that contain the list field with the name value\n",
        "get_list_val_from_ast(movies, ['genres','spoken_languages'],'name','Other')\n",
        "get_list_val_from_ast(movies, ['production_companies','keywords'],'name','')\n",
        "get_list_val_from_ast(movies, ['production_countries'],'iso_3166_1','Other')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MQvdYBotIo41",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Create data checkpoint - checkpoint_2\n",
        "Afer data conversion, before cleaning up empty values"
      ]
    },
    {
      "metadata": {
        "id": "lqm0JPbAIo41",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "save_checkpoint(movies, 'movies', '2')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ApIQ8v0OIo44",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create a checkpoint for the movies data set\n",
        "movies.name = 'movies_checkpoint_2'\n",
        "movies_checkpoint_2 = movies.copy()\n",
        "#movies=movies_checkpoint_2.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BvqRKyFwFGVX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "movies_checkpoint_2.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EKkv4FjdIo47",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Handle empty values"
      ]
    },
    {
      "metadata": {
        "id": "gAuoj6EtIo47",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "__revenue__\n",
        "* As revenue is the target value in the model, we have to clear all rows with empty revenue"
      ]
    },
    {
      "metadata": {
        "id": "NEOtJywWIo49",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# check shape before\n",
        "print(movies.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AfXl6zHCIo4-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# remove empty target values\n",
        "movies = movies[movies['revenue'].notnull()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FpT2XHf6Io5A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# check shape after\n",
        "print(movies.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Df7g6ufRIo5B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# running a quick schema and data analysis after reducing empty revenue items:\n",
        "quick_schema_analysis(movies)\n",
        "quick_data_analysis(movies)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rKK4DseeIo5B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "__budget, runtime__  - replace nan with mean"
      ]
    },
    {
      "metadata": {
        "id": "UtWhI6VUIo5C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "movies['budget'].fillna((movies['budget'].mean()), inplace=True)\n",
        "movies['runtime'].fillna((movies['runtime'].mean()), inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e5JKM-6tIo5D",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "__homepage, overview, poster_path, status, tagline__ - replace nan with empty string"
      ]
    },
    {
      "metadata": {
        "id": "8wcx9dlgIo5E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "movies['homepage'].fillna('',inplace=True)\n",
        "movies['overview'].fillna('',inplace=True)\n",
        "movies['poster_path'].fillna('',inplace=True)\n",
        "movies['status'].fillna('',inplace=True)\n",
        "movies['tagline'].fillna('',inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sx953OtgIo5F",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Examine distribution and correlations"
      ]
    },
    {
      "metadata": {
        "id": "VQ2sRVfBIo5F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# define the collection of numeric columns\n",
        "num_columns = ['budget','popularity','runtime','vote_average','vote_count','revenue']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yZn-9cfYIo5G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# plot histograms\n",
        "movies[num_columns].hist(bins=50, figsize=(11,8))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8tNzTeMqIo5H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# examine correlaiton of numerical columns\n",
        "scatter_matrix(movies[num_columns], figsize=(15, 15))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sH5qnxrjIo5J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Create data checkpoint - checkpoint_3\n",
        "Before removing unnecessary features and adding new features to movies"
      ]
    },
    {
      "metadata": {
        "id": "kCHhQXQIIo5K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "save_checkpoint(movies, 'movies', '3')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wmpswoRnIo5L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create a checkpoint for the movies data set\n",
        "movies.name = 'movies_checkpoint_3'\n",
        "movies_checkpoint_3 = movies.copy()\n",
        "#movies=movies_checkpoint_3.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-oDiyf8WFOUL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "movies_checkpoint_3.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6zXvaqqCIo5M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Feature removal\n",
        "Drop features that don't provide any added value"
      ]
    },
    {
      "metadata": {
        "id": "2ODrlPgjIo5N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "movies.drop(columns = 'poster_path',inplace=True) # textual column with low added value\n",
        "movies.drop(columns = 'imdb_id',inplace=True) # not used in this model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lmVFGDmEIo5N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# assess categorial columns\n",
        "assess_columns(movies,['adult','video'],True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DcFf6P3DIo5O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# drop video and adult as their distinct value is False\n",
        "movies.drop(columns = ['adult','video'],inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QOcydtaaIo5R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# case for dropping original_title\n",
        "compare = ['title', 'original_title']\n",
        "movies[movies['original_title'] != movies['title']][['title', 'original_title']].head(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eKZMhV2dIo5S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# drop original_title (it appears to be the untranslated version of the title)\n",
        "movies.drop(columns='original_title',inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pr0hjOdWIo5U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Feature engineering"
      ]
    },
    {
      "metadata": {
        "id": "zGjQWAY8I3-o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "movies.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qCBiuq6eITz-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# add a primary genre field strictly for use in other feature transformations\n",
        "movies['primary_genre'] = movies['genres'].apply(lambda x: (x and x[0]) or ('Other'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7DlgaGMKIo5U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### New feature - actors (from cast)"
      ]
    },
    {
      "metadata": {
        "id": "cNb4XS9RIo5U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create actors columns based on cast\n",
        "get_list_val_from_ast(df=movies, columns=['cast'],field_name='name',new_col_dict = {'cast' : 'actors'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7b-4DRDnIo5V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "assess_columns(movies, ['actors'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JGUpWZjaIo5W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### New feature - director (from crew)"
      ]
    },
    {
      "metadata": {
        "id": "xaq0vQi0Io5X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# extract the director from the crew field\n",
        "def get_director(x):\n",
        "    for i in x:\n",
        "        if i['job'] == 'Director':\n",
        "            return i['name']\n",
        "    return 'Unknown'\n",
        "  \n",
        "movies['director'] = movies['crew'].apply(get_director)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_VgtdIPBIo5X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "assess_columns(movies, ['director'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RwA9ndtGIo5Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### New features - cast_size and crew_size (from cast and crew)"
      ]
    },
    {
      "metadata": {
        "id": "hr2epBAOIo5Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "movies['cast_size'] = movies['cast'].apply(lambda x: len(x))\n",
        "movies['crew_size'] = movies['crew'].apply(lambda x: len(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m20Cys5jIo5a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "assess_columns(movies, ['cast_size','crew_size'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GLcv0xQ4Io5b",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### New feature - franchise (from belongs_to_collection)"
      ]
    },
    {
      "metadata": {
        "id": "qrkhstfcIo5b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "movies['franchise'] = (movies['belongs_to_collection']\n",
        "                       .apply(lambda x: len(x)>0)\n",
        "                      )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1X2deBslIo5c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "assess_columns(movies, ['franchise'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e_9ZCMh1Io5e",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### New features - season and release_year (from release_date)"
      ]
    },
    {
      "metadata": {
        "id": "mNVpF4sWIo5g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# calculate the season of the release (spring, summer, fall, winter)\n",
        "def season_of_date(date):\n",
        "    if pd.isnull(date):\n",
        "        return 'unknown'\n",
        "    year = str(date.year)\n",
        "    seasons = {'spring': pd.date_range(start='21/03/'+year, end='20/06/'+year),\n",
        "               'summer': pd.date_range(start='21/06/'+year, end='22/09/'+year),\n",
        "               'autumn': pd.date_range(start='23/09/'+year, end='20/12/'+year)}\n",
        "    if date in seasons['spring']:\n",
        "        return 'spring'\n",
        "    if date in seasons['summer']:\n",
        "        return 'summer'\n",
        "    if date in seasons['autumn']:\n",
        "        return 'autumn'\n",
        "    else:\n",
        "        return 'winter'\n",
        "\n",
        "# create a new column    \n",
        "movies['season'] = (movies['release_date']\n",
        "                          .fillna(pd.NaT)\n",
        "                          .apply(lambda x: season_of_date(x))\n",
        "                   )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fjGQnfXPIo5g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# get the year the movie was released\n",
        "def year_of_date(date):\n",
        "    if pd.isnull(date):\n",
        "      return -1\n",
        "    year = date.year\n",
        "    return year\n",
        "\n",
        "# create a new column    \n",
        "movies['release_year'] = (movies['release_date']\n",
        "                          .fillna(pd.NaT)\n",
        "                          .apply(lambda x: year_of_date(x))\n",
        "                   )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EtMmE3c9Io5j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "assess_columns(movies, ['season','release_year'],True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o8opvr7bIo5j",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### New feature -  home_pagedomain (from homepage)"
      ]
    },
    {
      "metadata": {
        "id": "oJ9JlimJIo5k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# get domain from url\n",
        "def get_url_domain(url):\n",
        "    if(not pd.isnull(url)):\n",
        "        parsed_uri = urlparse(url )\n",
        "        return '{uri.netloc}'.format(uri=parsed_uri)\n",
        "    else:\n",
        "        return url"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z3RGdPTBIo5l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# extract the domain from the homepage url\n",
        "movies['homepage_domain'] = movies['homepage'].apply(get_url_domain)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Bx0zOSRYIo5n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "assess_columns(movies, ['homepage_domain'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wDrvy4seIo5o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### New feature - weighted_rating (from vote_average and vote_count)\n",
        "Weighted Rating (WR) = $\\left(\\frac{v}{v+m}\\cdot R\\right) + \\left(\\frac{m}{v+m}\\cdot C\\right)$ where,\n",
        "\n",
        "<li>v is the number of votes for the movie\n",
        "<li>m is the minimum votes required to be listed in the chart\n",
        "<li>R is the average rating of the movie\n",
        "<li>C is the mean vote across the whole report.\n",
        "<br>Source: https://www.kaggle.com/rounakbanik/movie-recommender-systems"
      ]
    },
    {
      "metadata": {
        "id": "T1yBKbiyIo5p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# add a weighted rating feature\n",
        "vote_averages = (movies[movies['vote_average']\n",
        "                 .notnull()]['vote_average'].astype('int')\n",
        "                )\n",
        "\n",
        "vote_counts = (movies[movies['vote_count']\n",
        "               .notnull()]['vote_count'].astype('int')\n",
        "              )\n",
        "\n",
        "C = vote_averages.mean()\n",
        "m = vote_counts.quantile(0.75)\n",
        "\n",
        "def weighted_rating(x):\n",
        "    v = x['vote_count']+1\n",
        "    R = x['vote_average']\n",
        "    return (v/(v+m) * R) + (m/(m+v) * C)\n",
        "\n",
        "movies['weighted_rating'] = movies.apply(weighted_rating, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xMB7NZ7yIo5q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "assess_columns(movies, ['weighted_rating'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3N9BU-s1Io5q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### New feature - revenue_to_budget_ratio (from revenue and budget)"
      ]
    },
    {
      "metadata": {
        "id": "9th3E0BXIo5q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# this new feature can indicate \"success\" or \"failure\"\n",
        "# (depending on whether ration is < 0 or > 0)\n",
        "movies['revenue_to_budget_ratio'] = movies['revenue'] / movies['budget']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wjrThNK9Io5r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "assess_columns(movies, ['revenue_to_budget_ratio'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-L1QJchiIo5s",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Drop columns that are no longer needed\n",
        "Drop columns that were already engineered to generate other columns"
      ]
    },
    {
      "metadata": {
        "id": "-zUdvEUcIo5s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# drop additional columns\n",
        "movies.drop(columns = 'homepage',inplace=True)  #replaced by homepage_domain\n",
        "movies.drop(columns = 'cast',inplace=True)  # parsed into actors\n",
        "movies.drop(columns = 'crew',inplace=True)  # partially expressed in director feature\n",
        "movies.drop(columns = 'release_date',inplace=True)  # can be replaced with season and release_year"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jCPB5zaJIo5u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Examine distribution and correlations - of new features"
      ]
    },
    {
      "metadata": {
        "id": "BQMqBUPOIo5u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# define the collection of new numeric columns\n",
        "new_num_columns = ['cast_size','crew_size','release_year','weighted_rating','revenue_to_budget_ratio']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ugq7WvqcIo5v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# plot histograms\n",
        "movies[new_num_columns].hist(bins=50, figsize=(11,8))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aoI1boVpIo5w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# examine correlaiton of numerical columns\n",
        "if not 'revenue' in new_num_columns:\n",
        "    new_num_columns.append('revenue')\n",
        "scatter_matrix(movies[new_num_columns], figsize=(15, 15))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OOVywrnVIo5w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Remove columns that don't have any correlation with revenue"
      ]
    },
    {
      "metadata": {
        "id": "US-9tKXsIo5x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# drop columns that are not correlated with revenue\n",
        "movies.drop(columns = ['revenue_to_budget_ratio','release_year'],inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jTOjXE0QIo50",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Asses movies data set to apply final data cleansing"
      ]
    },
    {
      "metadata": {
        "id": "UWy1a-lIIo50",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "movies.name = 'movies'\n",
        "quick_schema_analysis(movies)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-SifA_qdIo50",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Create data checkpoint - checkpoint_4\n",
        "After feature engineering and some feature removal"
      ]
    },
    {
      "metadata": {
        "id": "NQAwN6CjIo51",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "save_checkpoint(movies, 'movies', '4')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x5P1PelzpCOk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create a checkpoint for the movies data set\n",
        "movies.name = 'movies_checkpoint_4'\n",
        "movies_checkpoint_4 = movies.copy()\n",
        "#movies=movies_checkpoint_4.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XLFaqNZfFTkx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "movies_checkpoint_4.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oBOg_Z4SIo58",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Handle textual and list origented features"
      ]
    },
    {
      "metadata": {
        "id": "jEZdMBqyIo58",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Get the stopwords file"
      ]
    },
    {
      "metadata": {
        "id": "dNBjmQvyIo58",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# specify file names and locations\n",
        "stop_file_url = URL_GIT_DOMAIN + URL_GIT_PROJECT_PATH + '/stopwords.txt'\n",
        "\n",
        "fetch_data(stop_file_url, 'stopwords.txt', PROJECT_LOCAL_RESOURCE_DIR, zip=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mQm96d-cIo59",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load stop words file\n",
        "def get_stop_words(stop_file_path):\n",
        "    \"\"\"load stop words \"\"\"\n",
        "    \n",
        "    with open(stop_file_path, 'r', encoding=\"utf-8\") as f:\n",
        "        stopwords = f.readlines()\n",
        "        stop_set = set(m.strip() for m in stopwords)\n",
        "        return frozenset(stop_set)\n",
        "\n",
        "#load a set of stop words\n",
        "stopwords=get_stop_words(os.path.join(PROJECT_LOCAL_RESOURCE_DIR,'stopwords.txt'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sLsVjVqsIo5-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Encoded and vectorized feature reduction functions"
      ]
    },
    {
      "metadata": {
        "id": "ZWFCLgvxIo5-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# reduce the encoded features using a threshold\n",
        "def reduce_sparse_encoding(df,threshold):\n",
        "    headers_list = list(df.columns.values)\n",
        "    num_samples = df.shape[0]\n",
        "\n",
        "    for header in headers_list:\n",
        "        col_true_count = len(df[df[header] == 1])\n",
        "        if col_true_count/num_samples < threshold:\n",
        "            df = df.drop(header, axis=1)\n",
        "    \n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I91wTRgyIo6A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# reduce the weighted features using a threshold\n",
        "def reduce_sparse_weights(df,threshold):\n",
        "    headers_list = list(df.columns.values)\n",
        "\n",
        "    for header in headers_list:\n",
        "        col_weight_sum = df[header].sum()\n",
        "        if col_weight_sum < threshold:\n",
        "            df = df.drop(header, axis=1)\n",
        "    \n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tHtmiC20Io6B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### title"
      ]
    },
    {
      "metadata": {
        "id": "PpNa4BliIo6B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# vectorizing the titles - using word counts\n",
        "count_vectorizer = CountVectorizer(max_features=1000, binary=True, max_df=0.8,stop_words=stopwords) \n",
        "titles = movies[\"title\"] \n",
        "titles_transformed = count_vectorizer.fit_transform(titles)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oa94tWLSIo6C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# examine the vectorized titles\n",
        "idx_to_word = np.array(count_vectorizer.get_feature_names())\n",
        "print(idx_to_word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cJfrI8jwIo6C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "title_titles = ['title_' + title for title in idx_to_word]\n",
        "titles_df = pd.DataFrame(titles_transformed.toarray(),columns=title_titles)\n",
        "titles_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xTNgTLwYIo6D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# reduce the features using 0.1% of 1\n",
        "titles_df = reduce_sparse_encoding(titles_df,0.001)\n",
        "titles_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gNi-XXcAIo6D",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### belongs_to_collection"
      ]
    },
    {
      "metadata": {
        "id": "JlbTWHzRIo6E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# replace empty lists with an empty string\n",
        "collections = [''.join(collection).lower().replace('collection','').replace('series','') \n",
        "               for collection in movies['belongs_to_collection'].values]\n",
        "# Vectorizing the collection names - using word counts\n",
        "count_vectorizer = CountVectorizer(max_features=100, stop_words=stopwords) \n",
        "collections_transformed = count_vectorizer.fit_transform(collections)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BHX8zfbEIo6E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# examine the vectorized collections\n",
        "idx_to_word = np.array(count_vectorizer.get_feature_names())\n",
        "print(idx_to_word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b8LfztkpIo6F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create a DataFrame\n",
        "collection_titles = ['coll_' + title for title in idx_to_word]\n",
        "collections_df = pd.DataFrame(collections_transformed.toarray(),columns=collection_titles)\n",
        "collections_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z4VAUDhRIo6G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# reduce the features using 0.1% of 1\n",
        "collections_df = reduce_sparse_encoding(collections_df,0.001)\n",
        "collections_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g3cYivnVIo6H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### keywords"
      ]
    },
    {
      "metadata": {
        "id": "exhUpSGWIo6H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# vectorizing keywords - re-use the vectorizer used for collections\n",
        "keywords = [''.join(keyword).lower() \n",
        "               for keyword in movies['keywords'].values]\n",
        "\n",
        "# Vectorizing the keywords - using word counts\n",
        "count_vectorizer = CountVectorizer(max_features=100, stop_words=stopwords) \n",
        "keywords_transformed = count_vectorizer.fit_transform(keywords)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PAFzTVIzIo6I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# examine the vectorized keywords\n",
        "idx_to_word = np.array(count_vectorizer.get_feature_names())\n",
        "print(idx_to_word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LF6xQmJCIo6J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create a DataFrame\n",
        "keyword_titles = ['key_' + title for title in idx_to_word]\n",
        "keywords_df = pd.DataFrame(keywords_transformed.toarray(),columns=keyword_titles)\n",
        "keywords_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IBeIknHpIo6J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# reduce the features using 0.1% of 1\n",
        "keywords_df = reduce_sparse_encoding(keywords_df,0.001)\n",
        "keywords_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-s48jQjyIo6L",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### tagline"
      ]
    },
    {
      "metadata": {
        "id": "DW_mY-CaIo6L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# vectorizing tagline - using tf-idf weighted term-document matrix\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=1000, max_df=0.8,stop_words=stopwords) \n",
        "taglines = movies['tagline'].replace(np.nan,'')\n",
        "taglines_transformed = tfidf_vectorizer.fit_transform(taglines)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BJyNNXvWIo6L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# examine the vectorized taglines\n",
        "idx_to_word = np.array(tfidf_vectorizer.get_feature_names())\n",
        "print(idx_to_word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EUkfasBXIo6M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# apply NMF\n",
        "nmf = NMF(n_components=100, solver=\"mu\")\n",
        "taglines_nmf = nmf.fit_transform(taglines_transformed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_mRjbrYCIo6N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create a DataFrame for tagline\n",
        "tagline_titles = nmf.components_\n",
        "tagline_titles = ['tagline_' + '_'.join(idx_to_word[title.argsort()[-10:]]) for title in tagline_titles]\n",
        "tagline_df = pd.DataFrame(taglines_nmf,columns=tagline_titles)\n",
        "tagline_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0mDP8Uc4Io6O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# reduce the features using sum weights of 1\n",
        "tagline_df = reduce_sparse_weights(tagline_df,1)\n",
        "tagline_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kIxOUTPPIo6O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### overview"
      ]
    },
    {
      "metadata": {
        "id": "id4_dTPSIo6P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# vectorizing overview - using tf-idf weighted term-document matrix \n",
        "overviews = movies['overview'].replace(np.nan,'')\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=1000, max_df=0.8,stop_words=stopwords) \n",
        "overviews_transformed = tfidf_vectorizer.fit_transform(overviews)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nShDnjouIo6Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# examine the vectorized overviews\n",
        "idx_to_word = np.array(tfidf_vectorizer.get_feature_names())\n",
        "print(idx_to_word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lHNjOAfdIo6R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# apply NMF : re-use the nmf component \n",
        "overviews_nmf = nmf.fit_transform(overviews_transformed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PEcCYYydIo6R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create a DataFrame for overview\n",
        "overview_titles = nmf.components_\n",
        "overview_titles = ['overview_' + '_'.join(idx_to_word[title.argsort()[-10:]]) for title in overview_titles]\n",
        "overview_df = pd.DataFrame(overviews_nmf,columns=overview_titles)\n",
        "overview_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mCeYC-FbIo6S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# reduce the features using sum weights of 1\n",
        "overview_df = reduce_sparse_weights(overview_df,1)\n",
        "overview_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vyg5ZzNNIo6S",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### spoken_languages"
      ]
    },
    {
      "metadata": {
        "id": "5vsjEQhxIo6S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# vectorizing spoken languages - re-use the vectorizer used for collections\n",
        "count_vectorizer = CountVectorizer()\n",
        "spoken_laguages = [','.join(lang).lower() \n",
        "               for lang in movies['spoken_languages'].values]\n",
        "spoken_laguages_transformed = count_vectorizer.fit_transform(spoken_laguages)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RPK9KqXeIo6T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# examine the vectorized spoken languages\n",
        "idx_to_word = np.array(count_vectorizer.get_feature_names())\n",
        "print(idx_to_word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WO6UQI90Io6W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create a DataFrame\n",
        "spoken_languages_titles = ['s_lang_' + lang for lang in idx_to_word]\n",
        "spoken_languages_df = pd.DataFrame(spoken_laguages_transformed.toarray(),columns=spoken_languages_titles)\n",
        "spoken_languages_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q0chMV24Io6W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# reduce the features using 0.1% of 1\n",
        "spoken_languages_df = reduce_sparse_encoding(spoken_languages_df,0.001)\n",
        "spoken_languages_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z4Exb4wVIo6X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### original_language"
      ]
    },
    {
      "metadata": {
        "id": "7YN2USQEIo6X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# vectorizing original language - re-use the vectorizer used for collections\n",
        "count_vectorizer = CountVectorizer()\n",
        "original_languages = movies['original_language'].replace(np.nan,'')\n",
        "original_languages_transformed = count_vectorizer.fit_transform(original_languages)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uhKecAF_Io6Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# examine the vectorized original languages\n",
        "idx_to_word = np.array(count_vectorizer.get_feature_names())\n",
        "print(idx_to_word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vn7wmGHaIo6a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create a DataFrame\n",
        "original_languages_titles = ['o_lang_' + lang for lang in idx_to_word]\n",
        "original_languages_df = pd.DataFrame(original_languages_transformed.toarray(),columns=original_languages_titles)\n",
        "original_languages_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UlRihygiIo6b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# reduce the features using 0.1% of 1\n",
        "original_languages_df = reduce_sparse_encoding(original_languages_df,0.001)\n",
        "original_languages_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Acu6fCaOIo6c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### homepage_domain"
      ]
    },
    {
      "metadata": {
        "id": "MAZHlaAcIo6c",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# vectorizing original language - using ngram vectorizing (to select all 3 parts of the url)\n",
        "ngram_vectorizer = CountVectorizer(max_features=100, binary=True, max_df=0.8,stop_words=stopwords,ngram_range=(3, 3)) \n",
        "homepage_domains = movies['homepage_domain'].replace(np.nan,'')\n",
        "homepage_domains_transformed = ngram_vectorizer.fit_transform(homepage_domains)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aSUXz6j9Io6d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# examine the vectorized original languages\n",
        "idx_to_word = np.array(ngram_vectorizer.get_feature_names())\n",
        "print(idx_to_word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bKzM93uWIo6e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create a DataFrame\n",
        "homepage_domain_titles = ['home_'+ url.replace(' ','.') for url in idx_to_word]\n",
        "homepage_domains_df = pd.DataFrame(homepage_domains_transformed.toarray(),columns=homepage_domain_titles)\n",
        "homepage_domains_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RU-mLu3PIo6g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# reduce the features using 0.1% of 1\n",
        "homepage_domains_df = reduce_sparse_encoding(homepage_domains_df,0.001)\n",
        "homepage_domains_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QKOa_ueEIo6h",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### genres"
      ]
    },
    {
      "metadata": {
        "id": "D61-OonqIo6h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Prepare the data in the column\n",
        "genres = [','.join(gen) for gen in movies['genres'].values]\n",
        "\n",
        "# Vectorizing genres \n",
        "count_vectorizer = CountVectorizer()\n",
        "genres_transformed = count_vectorizer.fit_transform(genres)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r9dWOkXwIo6i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# examine the vectorized production genres\n",
        "idx_to_word = np.array(count_vectorizer.get_feature_names())\n",
        "print(idx_to_word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "76ERIk78Io6j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# set titles and define new DataFrame\n",
        "genre_list = idx_to_word\n",
        "genre_titles = ['gen_' + gen for gen in idx_to_word]\n",
        "genres_df = pd.DataFrame(genres_transformed.toarray(),columns=genre_titles)\n",
        "genres_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1YKigl6Ei4Tj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# show the top 10 genres\n",
        "\n",
        "genres_count = pd.Series(count_values(movies, 'genres'))\n",
        "genres_count.sort_values(ascending = False).head(10).plot(kind = 'bar')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M21E3p9LjKin",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zX5oHOFhDRKs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# show the genre distribution\n",
        "\n",
        "plt.rc('font', weight='bold')\n",
        "f, ax = plt.subplots(figsize=(5,5))\n",
        "genre_count = []\n",
        "for genre in genre_titles:\n",
        "    genre_name = genre[4:]\n",
        "    genre_count.append([genre_name, genres_df[genre].values.sum()])\n",
        "\n",
        "genre_count.sort(key = lambda x:x[1], reverse = True)\n",
        "\n",
        "labels, sizes = zip(*genre_count)\n",
        "labels_selected = [n if v > sum(sizes) * 0.01 else '' for n, v in genre_count]\n",
        "\n",
        "ax.pie(sizes, labels=labels_selected,\n",
        "      autopct = lambda x:'{:2.0f}%'.format(x) if x>1 else '',\n",
        "      shadow = False, startangle=0)\n",
        "ax.axis('equal')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1rmpmOWzjOM-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# explore impact of genre on budget and revenue\n",
        "\n",
        "mean_per_genre = movies[['primary_genre','revenue','budget']].groupby(['primary_genre'], as_index=True).mean()\n",
        "\n",
        "mean_per_genre.rename({'revenue':'mean_revenue', 'budget':'mean_budget'}, axis=1, inplace=True)\n",
        "\n",
        "mean_per_genre"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dbnoFvvxIo6j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# reduce the features using 0.1% of 1\n",
        "genres_df = reduce_sparse_encoding(genres_df,0.001)\n",
        "genres_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OeceE8FxIo6k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### production_companies"
      ]
    },
    {
      "metadata": {
        "id": "jcairQ-ZIo6k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# prepare the data in the column\n",
        "production_companies = [','.join(prod).strip().replace(' ','_') \n",
        "               for prod in movies['production_companies'].values]\n",
        "\n",
        "# Vectorizing production companies \n",
        "count_vectorizer = CountVectorizer(max_features=1000)\n",
        "production_companies_transformed = count_vectorizer.fit_transform(production_companies)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bHII5LS3Io6l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# examine the vectorized production companies\n",
        "idx_to_word = np.array(count_vectorizer.get_feature_names())\n",
        "print(idx_to_word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QvqQSNuBIo6n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# set titles and define new DataFrame\n",
        "production_companies_titles = ['prod_' + prod for prod in idx_to_word]\n",
        "production_companies_df = pd.DataFrame(production_companies_transformed.toarray(),columns=production_companies_titles)\n",
        "production_companies_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0qhlKtCLIo6p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# reduce the features using 0.1% of 1\n",
        "production_companies_df = reduce_sparse_encoding(production_companies_df,0.001)\n",
        "production_companies_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XqluR_PzIo6q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### production_countries"
      ]
    },
    {
      "metadata": {
        "id": "gPVUwciYIo6r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Vectorizing production countries \n",
        "count_vectorizer = CountVectorizer() \n",
        "production_countries = [','.join(country).lower() \n",
        "               for country in movies['production_countries'].values]\n",
        "production_countries_transformed = count_vectorizer.fit_transform(production_countries)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2JUrArhzIo6s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# examine the vectorized production countries\n",
        "idx_to_word = np.array(count_vectorizer.get_feature_names())\n",
        "print(idx_to_word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yOe1I7T0Io6t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create a DataFrame\n",
        "production_countries_titles = ['country_' + country for country in idx_to_word]\n",
        "production_countries_df = pd.DataFrame(production_countries_transformed.toarray(),columns=production_countries_titles)\n",
        "production_countries_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bCXpF4UsIo6t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# reduce the features using 0.1% of 1\n",
        "production_countries_df = reduce_sparse_encoding(production_countries_df,0.001)\n",
        "production_countries_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sYpSzhcMIo6u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### director"
      ]
    },
    {
      "metadata": {
        "id": "F-I4DVxMIo6v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# prepare the data in the column\n",
        "directors = [director.strip().replace(' ','_') \n",
        "               for director in movies['director'].values]\n",
        "\n",
        "# Vectorizing production companies\n",
        "count_vectorizer = CountVectorizer(max_features=100) \n",
        "directors_transformed = count_vectorizer.fit_transform(directors)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "89DIIL05Io6v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# examine the vectorized directors\n",
        "idx_to_word = np.array(count_vectorizer.get_feature_names())\n",
        "print(idx_to_word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EMcvv1bTIo6w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# set titles and define new DataFrame\n",
        "director_titles = ['director_' + director for director in idx_to_word]\n",
        "directors_df = pd.DataFrame(directors_transformed.toarray(),columns=director_titles)\n",
        "directors_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eLTBPftiIo6x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# reduce the features using 0.1% of 1\n",
        "directors_df = reduce_sparse_encoding(directors_df,0.001)\n",
        "directors_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RA7V3jSrIo6y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### actors"
      ]
    },
    {
      "metadata": {
        "id": "-KGsLr6eIo6z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# prepare the data in the column\n",
        "actors = [','.join(actor).strip().replace(' ','_') \n",
        "               for actor in movies['actors'].values]\n",
        "\n",
        "# Vectorizing actors\n",
        "count_vectorizer = CountVectorizer(max_features=1000) \n",
        "actors_transformed = count_vectorizer.fit_transform(actors)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PRPSkb6MIo6z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# examine the vectorized actors\n",
        "idx_to_word = np.array(count_vectorizer.get_feature_names())\n",
        "print(idx_to_word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gAIVWApiIo61",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# set titles and define new DataFrame\n",
        "actor_titles = ['actor_' + actor for actor in idx_to_word]\n",
        "actors_df = pd.DataFrame(actors_transformed.toarray(),columns=actor_titles)\n",
        "actors_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FtH7XzOdIo63",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# reduce the features using 0.1% of 1\n",
        "actors_df = reduce_sparse_encoding(actors_df,0.001)\n",
        "actors_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pHtC3SesIo65",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### One-hot encoding for categorical features"
      ]
    },
    {
      "metadata": {
        "id": "agVwq8JvIo65",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### season"
      ]
    },
    {
      "metadata": {
        "id": "ZTODu6jwIo65",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "season_df = pd.get_dummies(movies[['season']],prefix='season')\n",
        "season_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Gobq1KjKIo65",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# reduce the features using 0.1% of 1\n",
        "season_df = reduce_sparse_encoding(season_df,0.001)\n",
        "season_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0S_mn_MEIo66",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### status"
      ]
    },
    {
      "metadata": {
        "id": "0cgs2a4HIo66",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "status_df = pd.get_dummies(movies[['status']],prefix='status')\n",
        "status_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aasfeZ8KIo67",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# reduce the features using 0.1% of 1\n",
        "status_df = reduce_sparse_encoding(status_df,0.001)\n",
        "status_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vzcc6Vv9Io68",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### franchise"
      ]
    },
    {
      "metadata": {
        "id": "TIJ_QmkmIo68",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "franchise_df = pd.get_dummies(movies[['franchise']],prefix='fran')\n",
        "franchise_df.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-ZlU72ixIo68",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Merge encoded and vectorized sets into movies"
      ]
    },
    {
      "metadata": {
        "id": "c8O-hZAJIo68",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "remove_columns = ['revenue','title', 'belongs_to_collection', 'keywords', 'tagline', 'overview', 'spoken_languages',\n",
        "                  'original_language', 'homepage_domain', 'genres', 'production_companies', 'production_countries', \n",
        "                  'director', 'actors', 'season', 'status', 'franchise']\n",
        "\n",
        "# create the final data set\n",
        "movies_final_arr = np.concatenate((movies[['revenue']].values,movies.drop(remove_columns,axis=1).values,\n",
        "                                 titles_df.values,collections_df.values,\n",
        "                                 keywords_df.values,tagline_df.values,overview_df.values,\n",
        "                                 spoken_languages_df.values,original_languages_df.values,\n",
        "                                 homepage_domains_df.values,genres_df.values,\n",
        "                                 production_companies_df.values,production_countries_df.values,\n",
        "                                 directors_df.values,actors_df.values,season_df.values,\n",
        "                                 status_df.values,franchise_df.values),  axis=1)\n",
        "\n",
        "# set column headers\n",
        "movies_headers_arr = np.concatenate((movies[['revenue']].columns.values,movies.drop(remove_columns,axis=1).columns.values,\n",
        "                                 titles_df.columns.values,collections_df.columns.values,\n",
        "                                 keywords_df.columns.values,tagline_df.columns.values,overview_df.columns.values,\n",
        "                                 spoken_languages_df.columns.values,original_languages_df.columns.values,\n",
        "                                 homepage_domains_df.columns.values,genres_df.columns.values,\n",
        "                                 production_companies_df.columns.values,production_countries_df.columns.values,\n",
        "                                 directors_df.columns.values,actors_df.columns.values,season_df.columns.values,\n",
        "                                 status_df.columns.values,franchise_df.columns.values))\n",
        "\n",
        "# create a DataFrame object\n",
        "movies_final = pd.DataFrame(movies_final_arr,columns=movies_headers_arr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l0KGq3jCIo6-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# check the new schema\n",
        "movies_final.name = 'movies_final'\n",
        "quick_schema_analysis(movies_final)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QZ4kLizYIo6-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# assign back to movies\n",
        "movies = movies_final"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ISznQ3UOIo6_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Create data checkpoint - checkpoint_5\n",
        "After creating the full set of the features "
      ]
    },
    {
      "metadata": {
        "id": "7cFFxCIkIo6_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "save_checkpoint(movies, 'movies', '5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uN__NAt_Io6_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create a checkpoint for the movies data set\n",
        "movies.name = 'movies_checkpoint_5'\n",
        "movies_checkpoint_5 = movies.copy()\n",
        "# movies=movies_checkpoint_5.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6APDXSfxFaPa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "movies_checkpoint_5.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0-NJJPcrIo7A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Feature selction and reduction - continued\n",
        "Once the full feature set has been assembled, we use feature selection and reduction algorithms to come up with a subset of the features\n",
        "\n",
        "The algorithms below is optimized for regression (specifically linear regression). Regardless, further algorithms we'll be used in the model creation section"
      ]
    },
    {
      "metadata": {
        "id": "6bvEDRjiJ0T6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# drop primary_genre since it was only used to assess and calculate other features\n",
        "movies.drop(['primary_genre'], axis=1, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Dwn_g632Io7A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# define target value and features\n",
        "target = 'revenue'\n",
        "features = list(movies.columns)\n",
        "features = [f for f in features if f!=target]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VTqUH8cAIo7B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# define train set and test set\n",
        "train_set, test_set = train_test_split(movies, test_size=0.3)\n",
        "\n",
        "X_tr = train_set[features]\n",
        "y_tr = train_set[[target]]\n",
        "\n",
        "X_te = test_set[features]\n",
        "y_te = test_set[[target]]\n",
        "\n",
        "#add a new target variable for classification \n",
        "y_tr_cl = np.ravel(y_tr)/np.ravel(train_set.budget)>2.50\n",
        "y_te_cl = np.ravel(y_te)/np.ravel(test_set.budget)>2.50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9IbRqiacdXtI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Target\n",
        "\n",
        "The target for our model is revenue.  For the purpose of classifying a movie as a financial success, the classifier specific target uses a revenue/budget ratio of 2.5."
      ]
    },
    {
      "metadata": {
        "id": "2ni9VTwnIo7G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Scoring functions"
      ]
    },
    {
      "metadata": {
        "id": "bvE3-JcqIo7H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# display the score\n",
        "def display_scores(scores):\n",
        "    mean_score = scores.mean()\n",
        "    print(\"Scores:\", scores)\n",
        "    print(\"Mean:\", mean_score)\n",
        "    return(mean_score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JiZ0OSzXIo7H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### SelectKBest with chi square"
      ]
    },
    {
      "metadata": {
        "id": "IZk7IqfpIo7H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# define the select K best model - using chi square\n",
        "select_best = SelectKBest(score_func=chi2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vHozdyLJIo7I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# identify the best hyper parameter\n",
        "k_arr = [20, 30, 40 ,50, 75, 100, 200]\n",
        "\n",
        "best_k = 0\n",
        "best_score = float('inf')\n",
        "\n",
        "for k in k_arr:\n",
        "    select_best.k = k\n",
        "    select_best.fit(np.asarray(X_tr),np.asarray(y_tr, dtype=\"|S100\"))\n",
        "    X_tr_new = select_best.transform(X_tr)\n",
        "    X_te_new = select_best.transform(X_te)\n",
        "    print(\"\\n\")\n",
        "    print(\"Performance for k={}\".format(k))\n",
        "    print(\"Trainng set:\")\n",
        "    lin_scores = cross_val_score(LinearRegression(), X_tr_new, y_tr, scoring=\"neg_mean_squared_error\", cv=4)\n",
        "    lin_rmse_scores = np.sqrt(-lin_scores)\n",
        "    mean_train_score = display_scores(lin_rmse_scores)\n",
        "    print(\"Test set:\")\n",
        "    lin_scores = cross_val_score(LinearRegression(), X_te_new, y_te, scoring=\"neg_mean_squared_error\", cv=4)\n",
        "    lin_rmse_scores = np.sqrt(-lin_scores)\n",
        "    mean_test_score = display_scores(lin_rmse_scores)\n",
        "    \n",
        "    if mean_test_score < best_score:\n",
        "        best_score = mean_test_score\n",
        "        best_k = k"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O24Pu7_ATYl2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print('Best Score = ', best_score)\n",
        "print('Best K     = ', best_k)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y5d_Kui2Io7I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# pick the best k\n",
        "select_best.k = best_k\n",
        "select_best.fit(np.asarray(X_tr),np.asarray(y_tr, dtype=\"|S100\"))\n",
        "X_tr = select_best.transform(X_tr)\n",
        "X_te = select_best.transform(X_te)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pb58zgU7Io7J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Scaling the features"
      ]
    },
    {
      "metadata": {
        "id": "o71b3ilTIo7J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "scaler.fit(X_tr)\n",
        "X_tr = scaler.transform(X_tr)\n",
        "X_te = scaler.transform(X_te)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WigpRh-zIo7K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Feature tuning pipeline (using linear regression)"
      ]
    },
    {
      "metadata": {
        "id": "ja-KvIFYIo7K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Linear regression and pipeline (to evaluate feature selection and reduction)\n",
        "steps = [('regression',LinearRegression())]\n",
        "pipeline = Pipeline(steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xmL2ufh4Io7L",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### PCA"
      ]
    },
    {
      "metadata": {
        "id": "v0qO4fC7Io7L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Make an instance of the Model\n",
        "pca = PCA()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Eh69uAFfIo7L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# add to the steps collection\n",
        "pipeline.steps.insert(0,('pca',pca))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FV28Veg8Io7M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# GridSearchCV\n",
        "parameters = {}\n",
        "grid_search = GridSearchCV(pipeline, parameters, cv=4, scoring='neg_mean_squared_error')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5Am1LdfiIo7M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# add corresponding parameters\n",
        "grid_search.param_grid['pca__n_components'] = [0.9,0.91,0.92,0.93,0.94,0.95,0.96,0.97,0.98,0.99,0.999,1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "to8ZpjCcIo7N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# fit the model\n",
        "grid_search.fit(X_tr,y_tr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A7T7314MIo7O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# training scores\n",
        "print(\"Best pca parameter is {}\".format(grid_search.best_params_))\n",
        "lin_scores = grid_search.best_score_\n",
        "lin_rmse_scores = np.sqrt(-lin_scores)\n",
        "display_scores(lin_rmse_scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7YfgB8uwIo7P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# run best model with test data\n",
        "grid_search_final = grid_search.best_estimator_ \n",
        "grid_search_final.fit(X_te,y_te)\n",
        "lin_scores = cross_val_score(grid_search_final, X_te, y_te, scoring=\"neg_mean_squared_error\", cv=4)\n",
        "lin_rmse_scores = np.sqrt(-lin_scores)\n",
        "display_scores(lin_rmse_scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VUoMG9EAIo7Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# tidy up - remove the pca step from the pipeline\n",
        "del pipeline.steps[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cEHfvUavIo7R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* __Conclusion:__  pca doesn't really improve results"
      ]
    },
    {
      "metadata": {
        "id": "jLYuEiPDIo7R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Clustering - K-means"
      ]
    },
    {
      "metadata": {
        "id": "C7ef3aaXIo7R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "kmeans = KMeans()\n",
        "\n",
        "# add to the steps collection\n",
        "pipeline.steps.insert(0,('kmeans',kmeans))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6Bdb6OwAIo7S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# GridSearchCV\n",
        "parameters = {}\n",
        "grid_search = GridSearchCV(pipeline,parameters, cv=4, scoring='neg_mean_squared_error')\n",
        "\n",
        "# add corresponding parameters\n",
        "grid_search.param_grid['kmeans__n_clusters'] = [2,4,6,8,10,15,20,30,40]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QJpesYsDIo7T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# fit the model\n",
        "grid_search.fit(X_tr,y_tr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6Jk5ACGcIo7T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# training set scores\n",
        "print(\"Best k-means parameter is {}\".format(grid_search.best_params_))\n",
        "lin_scores = grid_search.best_score_\n",
        "lin_rmse_scores = np.sqrt(-lin_scores)\n",
        "display_scores(lin_rmse_scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "teeRJ4LTIo7U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# try with test data\n",
        "grid_search_final = grid_search.best_estimator_ \n",
        "grid_search_final.fit(X_te,y_te)\n",
        "lin_scores = cross_val_score(grid_search_final, X_te, y_te, scoring=\"neg_mean_squared_error\", cv=4)\n",
        "lin_rmse_scores = np.sqrt(-lin_scores)\n",
        "display_scores(lin_rmse_scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1FjKImLsIo7U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* __Conclusion__: KMeans clustering doesn't improve the results"
      ]
    },
    {
      "metadata": {
        "id": "8EQi2mwYIo7U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 4. Model"
      ]
    },
    {
      "metadata": {
        "id": "B7eAE3fMIo7U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Reasons for considering a classification model in addition to the regression model.\n",
        "\n",
        "Box Office profits are a function of production budgets, ticket prices & Marketing/ Distribution costs based on their year of release.\n",
        "\n",
        "\n",
        "Hence, while evaluating historical values, profit calculations without accounting for inflation do not always provide the big picture (pun intended). A recommended option is arriving at a revenue to budget ratio (R/B), which offers better insights compared to revenue recognition alone. \n",
        "\n",
        "Furthermore, this ratio is also useful for determining the relative success of a theatrical release. The total cost of movie production is not limited to production budgets and consequently, should take into account the distribution and marketing costs which are increasingly  important to a movie's success. Accordingly, movie producers and industry watchers now believe that a movie needs to make in excess of 2.5 times its production budget to even be considered a moderate success.\n",
        "\n",
        "Since the model is predicting success based on the revenue to budget ratio , the feature matrix drops 'revenue' and 'revenue to budget ratio' as new unseen data (i.e. data not available for movies that are yet to be released which we want to predict as being a success or failure). The attempt here is to predict film success using features like genre, production company, month/season of release, cast/crew size, country of production, whether part of a franchise, weighted rating, budget etc. These are parameters that are already known before the movie's release."
      ]
    },
    {
      "metadata": {
        "id": "gZUzMhCNIo7U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Classification"
      ]
    },
    {
      "metadata": {
        "id": "3e7UzdndIo7V",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Logistic regression"
      ]
    },
    {
      "metadata": {
        "id": "eWzMlsNyIo7V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "logreg=LogisticRegression()\n",
        "params_logreg={'C':np.logspace(-5, 8, 15)}\n",
        "logreg_cv = GridSearchCV(logreg,params_logreg,cv=4)\n",
        "logreg_cv.fit(X_tr,y_tr_cl)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T4ZpQpupIo7V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print('Accuracy: ',logreg_cv.best_score_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NAR4lYQ9Io7W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Random forest"
      ]
    },
    {
      "metadata": {
        "id": "KpPydrsBIo7W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "forest=RandomForestClassifier(random_state=42)\n",
        "params_forest = {'n_estimators': [3, 4, 6, 7, 10, 20, 50, 100]}\n",
        "forest_cv=GridSearchCV(forest, params_forest,cv=4)\n",
        "forest_cv.fit(X_tr,y_tr_cl)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iq97_WnWIo7W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print('Accuracy: ',forest_cv.best_score_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jmziOvOeIo7Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### KNN"
      ]
    },
    {
      "metadata": {
        "id": "Ecr39nLKIo7Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "knn=KNeighborsClassifier()\n",
        "params_knn = {'n_neighbors': [3, 5, 10, 20]}\n",
        "knn_cv=GridSearchCV(knn, params_knn,cv=4,n_jobs=-1)\n",
        "knn_cv.fit(X_tr,y_tr_cl)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nBasFQ0uIo7Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print('Accuracy:',knn_cv.best_score_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "siD-yAtXIo7Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Decision tree"
      ]
    },
    {
      "metadata": {
        "id": "7FfneRDXIo7Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tree = DecisionTreeClassifier()\n",
        "params_tree = {\"criterion\": [\"gini\", \"entropy\"],\"min_samples_split\": [2, 10, 20],\"max_depth\": [None, 2, 5, 10],\n",
        "              \"min_samples_leaf\": [1, 5, 10],\"max_leaf_nodes\": [None, 5, 10, 20]\n",
        "              }\n",
        "tree_cv=GridSearchCV(tree, params_tree,cv=4,n_jobs=-1)\n",
        "tree_cv.fit(X_tr,y_tr_cl)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bvJzBlE-Io7Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print('Accuracy:',tree_cv.best_score_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oHK61tCZIo7a",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### AdaBoostClassifier with DecisionTree as base estimator"
      ]
    },
    {
      "metadata": {
        "id": "Jvuu963WIo7a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ABC= AdaBoostClassifier(base_estimator=tree_cv.best_estimator_,n_estimators=100)\n",
        "np.mean(cross_val_score(ABC, X_tr, y_tr_cl, cv=3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tVtFhn_JIo7b",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Voting classifier"
      ]
    },
    {
      "metadata": {
        "id": "k_Yddl8DIo7b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "classifiers = [('Logistic Regression', logreg_cv.best_estimator_),('K Nearest Neighbours', knn_cv.best_estimator_),\n",
        "               ('RandomForestClassifier', forest_cv.best_estimator_),('DecisionTreeClassifier',tree_cv.best_estimator_)]\n",
        "\n",
        "vc = VotingClassifier(estimators=classifiers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Hkgj8gH9Io7d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print('Accuracy: ',np.mean(cross_val_score(vc, X_tr, y_tr_cl, cv=3)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6klnBK3IIo7d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Regression"
      ]
    },
    {
      "metadata": {
        "id": "hcI8LVydIo7e",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Linear regression"
      ]
    },
    {
      "metadata": {
        "id": "Nnr1FjQPIo7e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lin_reg=LinearRegression()\n",
        "lin_scores = cross_val_score(lin_reg,X_tr,y_tr, scoring=\"neg_mean_squared_error\", cv=4)\n",
        "lin_rmse_scores = np.sqrt(-lin_scores)\n",
        "display_scores(lin_rmse_scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cSmtjs4JIo7f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Ridge regression"
      ]
    },
    {
      "metadata": {
        "id": "EjGatAQ4Io7f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "param_grid = [{'alpha': [0.001,0.01,0.1,1,10,100,1000,1000]}]\n",
        "rr_cv = GridSearchCV(Ridge(), param_grid, cv=4, scoring='neg_mean_squared_error')\n",
        "rr_cv.fit(X_tr, y_tr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8bFDzs7VIo7g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(np.sqrt(-rr_cv.best_score_))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pVt1y9XLIo7h",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Lasso regression"
      ]
    },
    {
      "metadata": {
        "id": "tylFKLMFIo7h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "param_grid = [{'alpha': [0.001,0.01,0.1,1,10,100,1000,1000]}]\n",
        "lr_cv = GridSearchCV(Lasso(), param_grid, cv=3, scoring='neg_mean_squared_error')\n",
        "lr_cv.fit(X_tr, y_tr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n2klQjGBIo7h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(np.sqrt(-lr_cv.best_score_))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dzUbA46rplUJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Elastic Net"
      ]
    },
    {
      "metadata": {
        "id": "TEKAGyj-pqEZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# run grid search with \n",
        "param_grid = [{'alpha': [0.001,0.01,0.1,1,10,100,1000,1000], 'l1_ratio': [0.2, 0.4, 0.6, 0.8]}]\n",
        "enr_cv = GridSearchCV(ElasticNet(), param_grid, cv=3,scoring='neg_mean_squared_error', verbose=2)\n",
        "enr_cv.fit(X_tr, y_tr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H9hHomtBpqtv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print('Best parameters: {}'.format(enr_cv.best_params_))\n",
        "print('Best regression result: {}'.format(np.sqrt(-enr_cv.best_score_)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mllvbUn3Io7i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Test data set evaluation"
      ]
    },
    {
      "metadata": {
        "id": "JabBH5fRIo7i",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Classification"
      ]
    },
    {
      "metadata": {
        "id": "S-GT98mSIo7i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "final_cl_model = forest_cv.best_estimator_  \n",
        "y_pred_cl = final_cl_model.predict(X_te)\n",
        "\n",
        "print('Accuracy score: ',accuracy_score(y_te_cl,y_pred_cl))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VLqzYVa6Io7k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* Random Forest has a train accuracy of __0.8080__ and a test accuracy of __0.8068__"
      ]
    },
    {
      "metadata": {
        "id": "rRrnh8YoIo7l",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Regression"
      ]
    },
    {
      "metadata": {
        "id": "rIRq-DGpIo7l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "final_reg_model = enr_cv.best_estimator_\n",
        "final_reg_model.fit(X_tr,y_tr)\n",
        "\n",
        "y_pred_reg = final_reg_model.predict(X_te)\n",
        "\n",
        "final_mse = mean_squared_error(y_te, y_pred_reg)\n",
        "final_rmse = np.sqrt(final_mse)\n",
        "print(final_rmse)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CZ4HPeTsIo7l",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 5. Evaluate the model"
      ]
    },
    {
      "metadata": {
        "id": "-_TxJNdIIo7n",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Best Classifer - Random Forest\n",
        "### Best Regressor - ElasticNet (with l1_ratio=0.6)"
      ]
    },
    {
      "metadata": {
        "id": "jpz0OuthIo7m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Evaluation functions"
      ]
    },
    {
      "metadata": {
        "id": "cvopTq_iIo7m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# heatmap for the confusion matrix\n",
        "def cm_heatmap(y_test,y_pred):\n",
        "    cm=confusion_matrix(y_test,y_pred)\n",
        "    conf_matrix=pd.DataFrame(data=cm,columns=['Predicted:0','Predicted:1'],index=['Actual:0','Actual:1'])\n",
        "    plt.figure(figsize = (8,5))\n",
        "    sns.heatmap(conf_matrix, annot=True,fmt='d',cmap=\"YlGnBu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SjGr-WcaIo7m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# compare different models\n",
        "def metrics_comp(y_te_cl,y_pred_cl,y_pred_tree):\n",
        "    metrics=pd.DataFrame(index=['Accuracy','Precision','Recall'],columns=['Random Forest','Decision Tree'])\n",
        "    metrics.loc['Accuracy','Random Forest']=accuracy_score(y_te_cl,y_pred_cl)\n",
        "    metrics.loc['Precision','Random Forest']=precision_score(y_te_cl,y_pred_cl)\n",
        "    metrics.loc['Recall','Random Forest']=recall_score(y_te_cl,y_pred_cl)\n",
        "    metrics.loc['Accuracy','Decision Tree']=accuracy_score(y_te_cl,y_pred_tree)\n",
        "    metrics.loc['Precision','Decision Tree']=precision_score(y_te_cl,y_pred_tree)\n",
        "    metrics.loc['Recall','Decision Tree']=recall_score(y_te_cl,y_pred_tree)\n",
        "    return(metrics)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7HIjrgaIIo7n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# precison-recall graph\n",
        "def p_r_threshold(thresholds,precision,recall):\n",
        "    fig,ax=plt.subplots(figsize=(8,5))\n",
        "    ax.plot(thresholds,precision[1:],label='Precision')\n",
        "    ax.plot(thresholds,recall[1:],label='Recall')\n",
        "    ax.set_xlabel('Classification threshold')\n",
        "    ax.set_ylabel('Precision,Recall')\n",
        "    ax.set_title('Random Forest: Precison Recall')\n",
        "    ax.legend()\n",
        "    ax.grid();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "12s4eKXmVIL8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Plots"
      ]
    },
    {
      "metadata": {
        "id": "Mn6lB35aIo7o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Confusion Matrix"
      ]
    },
    {
      "metadata": {
        "id": "BycgSra4Io7o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cm_heatmap(y_te_cl,y_pred_cl)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4J2ixup8Io7p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### ROC Curve and AUC"
      ]
    },
    {
      "metadata": {
        "id": "BZkSaHtsIo7p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fpr, tpr, thresholds = roc_curve(y_te_cl, final_cl_model.predict_proba(X_te)[:,1])\n",
        "plt.plot(fpr,tpr)\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.0])\n",
        "plt.title('ROC curve for RandomForest classifier')\n",
        "plt.xlabel('False positive rate (1-Specificity)')\n",
        "plt.ylabel('Recall')\n",
        "plt.grid(True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "opR9ILQpIo7p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print (\"Area under the curve is \", roc_auc_score(y_te_cl,final_cl_model.predict_proba(X_te)[:,1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Tp8OgKXOWVOy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Classification Report"
      ]
    },
    {
      "metadata": {
        "id": "CefinIl2RxBO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(classification_report(y_te_cl, y_pred_cl))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3KjmPpn4Io7q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Evaluation of the 2nd best classifier model (Decision Tree)"
      ]
    },
    {
      "metadata": {
        "id": "Yi-72JzrIo7q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Test data\n",
        "y_pred_tree = tree_cv.predict(X_te)\n",
        "print('Accuracy score: ',accuracy_score(y_te_cl,y_pred_tree))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pce2Ve4mIo7q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Confusion matrix\n",
        "cm_heatmap(y_te_cl,y_pred_tree)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CZ-lt2S4Io7r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(classification_report(y_te_cl, y_pred_tree))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b-m6lqFyIo7r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fpr, tpr, thresholds = roc_curve(y_te_cl, tree_cv.predict_proba(X_te)[:,1])\n",
        "plt.plot(fpr,tpr)\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.0])\n",
        "plt.title('ROC curve for Decision Tree Classifier')\n",
        "plt.xlabel('False positive rate (1-Specificity)')\n",
        "plt.ylabel('Recall')\n",
        "plt.grid(True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "45sLLwesIo7s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print (\"Area under the curve is \", roc_auc_score(y_te_cl,tree_cv.predict_proba(X_te)[:,1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "reMZgPr4Io7t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Comparision of Accuracy, Precision and Recall between Random Forest and Decision Tree classifiers\n",
        "In the case of movie box office prediction, a high recall translates to missing to identify a film that will be successful and high precision ensures the majority of positively predicted films will be successful.\n",
        "\n",
        "As the average cost involved in producing a major studio film is extremely high and the number of films produced by a production house is relatively low, it is important that the classifier's positive predictions are going to be successful. Failing that will result in huge loss for the production house. Hence a model that has high precision rather than high recall is preferred."
      ]
    },
    {
      "metadata": {
        "id": "12k79l7eIo7t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# compare random forest and decision tree\n",
        "metrics_comp(y_te_cl,y_pred_cl,y_pred_tree)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XCJRDOWTIo7t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fig,ax=plt.subplots(figsize=(8,6))\n",
        "metrics_comp(y_te_cl,y_pred_cl,y_pred_tree).plot(kind='bar',ax=ax)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VNcHshpKIo7u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* __Conclusion__ :Accuracy is relatively close when comparing both models, although Random Forest has a slight advantage. However, Random Forest has higher precision than Decision Tree."
      ]
    },
    {
      "metadata": {
        "id": "rWKLcy0jIo7u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Tradeoff between precision and recall at different thresholds"
      ]
    },
    {
      "metadata": {
        "id": "MIN4xT6IIo7u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "precision_forest, recall_forest, thresholds_forest=precision_recall_curve(y_te_cl,final_cl_model.predict_proba(X_te)[:,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o3iSYGAwIo7u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "p_r_threshold(thresholds_forest,precision_forest,recall_forest)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "THfpEhx3Io7v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* __Conclusion__: At threshold 0.5 the recall is 0.4 with a very high precision (0.7). Moving the threshold to 0.6 results in a much higher precision (0.8) without a significant drop in recall."
      ]
    },
    {
      "metadata": {
        "id": "TyCm0P20Io7v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 6. Summary\n",
        "\n",
        "### Conclusions\n",
        "For this particular problem definition (\"movie success\") and dataset (from TMDB), the best classifier model was a **Random Forest**. \n",
        "\n",
        "This classifier produced the highest AUC and had the highest precision of all the models, where a higher precision can be obtained with a small reduction in recall by adjusting the threshold.\n",
        "- AUC  **0.87**\n",
        "- Precision **0.7**\n",
        "\n",
        "Confidence in the feature set and classifier model was supported by a regression model that predicted revenue with an **RMSE** of roughly **$81M**.  Automatic feature selection using PCA or KMeans clustering did not improve the model.\n",
        "\n",
        "As the average cost involved in producing a major studio film is extremely high and the number of films produced by a production house is relatively low, it is important that the classifier's positive predictions are going to be successful. Failing that will result in huge loss for the production house. Hence a model that has high precision rather than high recall is preferred.\n",
        "\n",
        "### Recommendations\n",
        "The majority of movies in this dataset with revenue and budget values are from the US.  This model could be used in other geographic markets, in particular for domestic releases, if values for revenue and budget were available.\n",
        "\n",
        "Analysis of the feature set indicates that further model improvement is possible.  In particular, given the revenue variation by \"genre\", new features based on a *primary_genre* would be a next step:\n",
        "- **revenue_mean_by_genre**\n",
        "- **budget_mean_by_genre**\n",
        "- **popularity_mean_by_genre**\n",
        "\n",
        "Furthermore, the impact of directors and actors on movie success could be explored, by generating a rating formula based on the revenue of other movies in which they were involved (where genre should also be factored in):\n",
        "- **director_rating_by_genre**\n",
        "- **actor_rating_by_genre**"
      ]
    }
  ]
}